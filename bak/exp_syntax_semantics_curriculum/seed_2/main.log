train: 11170 val: 4900 test: 48910
Add 4277 samples for class 0, acc 0.88.
Add 3211 samples for class 1, acc 0.84.
Add 2946 samples for class 2, acc 0.92.
Add 6217 samples for class 3, acc 0.95.
Add 4438 samples for class 4, acc 0.58.
Add 4467 samples for class 5, acc 0.96.
Add 6085 samples for class 6, acc 0.99.
Add 3530 samples for class 7, acc 0.80.
Add 5701 samples for class 8, acc 0.95.
Add 3792 samples for class 9, acc 0.98.
Add 4241 samples for class 10, acc 0.86.
Add 17097 samples for class 11, acc 0.84.
Add 12715 samples for class 12, acc 0.99.
Add 12436 samples for class 13, acc 0.92.
Add 18720 samples for class 14, acc 0.86.
Add 3156 samples for class 15, acc 0.85.
Namespace(curriculum=True, epochs=100, epochs_eval=5, excludes='!', output_dir='./outputs/exp_syntax_semantics_curriculum/seed_2/', perception=False, perception_pretrain='data/perception-pretrain/model.pth.tar_78.2_match', resume=None, seed=2, semantics=True, syntax=True)
ClusteringModel(
  (backbone): ResNet(
    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (cluster_head): ModuleList(
    (0): Linear(in_features=512, out_features=16, bias=True)
  )
)
use ground-truth syntax.
use ground-truth semantics.
Curriculum: [(0, 1), (1, 3), (20, 7), (40, 11), (60, 15), (80, inf)]
              precision    recall  f1-score   support

           0       0.86      0.84      0.85      4016
           1       0.69      0.47      0.56      5142
           2       0.72      0.59      0.65      5321
           3       0.87      0.95      0.91      5241
           4       0.50      0.55      0.52      5279
           5       0.93      0.80      0.86      5383
           6       0.93      0.97      0.95      5427
           7       0.53      0.63      0.58      5462
           8       0.91      0.89      0.90      5453
           9       0.94      0.64      0.76      5476
           +       0.84      0.57      0.68     13199
           -       0.70      1.00      0.83     10734
           *       0.98      1.00      0.99     13491
           /       0.81      0.86      0.84      9876
           (       0.71      0.97      0.82     21081
           )       0.84      0.61      0.70     21081

    accuracy                           0.79    141662
   macro avg       0.80      0.77      0.77    141662
weighted avg       0.80      0.79      0.78    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  237    0    0    0    0    4    6    0   32    0    0    0    0    0     0    0
1    0  169    0    0    5    0    0    0    0    0    0    0    0    0    43  142
2    7   14  222    6    0    4    1    1    0    8    0    0    2  103     0    0
3    0    0    6  350    4    4    0    0    0    1    0    0    0    0     0    0
4    0    1    0    0  204    0    0   65    0    0   85   12    0    0     0    0
5   12    2   27   10    0  302    2    0    0    2    0    0    0   19     0    0
6    0    0    0    0    0    7  370    2    0    2    0    0    0    0     0    0
7    0   39    7    2    0    0    0  244    0    0   16   42   13   10     0    7
8    0    0    5   30    0    0    0    2  344    0    0    0    0    0     2    0
9    0   14    0    2  116    2    0    0    0  248    2    0    0    0     0    0
+    0    2    0    0    0    0    0  149    0    0  530  243    3    1     0    0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/   16    0    0    0   64    0    0    0    0    0    0   16    0  599     0    0
(    2    0    8    0    0    0   12    0    0    0    0    2    0    0  1444   18
)    0    0   29    0   12    0    4    0    0    0    0    0    0    0   541  900
result accuracy by length:
1 ( 2%) 73.00
3 ( 2%) 47.00
5 ( 2%) 37.98
7 ( 4%) 35.81
9 ( 4%) 23.12
11 ( 3%) 25.57
13 ( 4%) 14.35
15 ( 4%) 13.86
17 ( 4%) 13.11
19 ( 4%)  6.86
21 ( 4%)  9.60
23 ( 4%)  9.76
25 ( 4%)  5.50
27 ( 4%)  6.90
29 ( 3%)  3.66
31 ( 3%)  5.95
33 ( 2%)  5.00
35 ( 2%)  2.74
37 ( 2%)  4.27
39 ( 3%)  0.66
41 ( 3%)  2.68
43 ( 2%)  2.90
45 ( 2%)  0.89
47 ( 2%)  1.52
49 ( 2%)  1.41
51 ( 2%)  0.76
53 ( 2%)  4.48
55 ( 2%)  1.68
57 ( 2%)  0.00
59 ( 2%)  2.80
61 ( 1%)  1.56
63 ( 0%)  0.00
65 ( 0%)  0.00
67 ( 0%)  0.00
result accuracy by symbol:
( (91%)  8.48
) (91%)  8.48
* (87%)  8.81
+ (84%)  6.16
- (77%)  8.32
/ (76%)  7.38
0 (52%)  7.58
1 (60%)  5.35
2 (61%)  6.11
3 (62%)  8.39
4 (61%)  6.07
5 (62%)  8.01
6 (62%)  7.87
7 (63%)  6.78
8 (64%)  7.96
9 (63%)  6.96
result accuracy by digit:
0 ( 0%) 80.00
1 ( 0%) 50.00
2 ( 0%) 50.00
3 ( 0%) 100.00
4 ( 0%) 60.00
5 ( 0%) 60.00
6 ( 0%) 100.00
7 ( 0%) 90.00
8 ( 0%) 100.00
9 ( 0%) 40.00
result accuracy by result:
0 (21%) 19.24
1 (10%) 11.05
2 ( 4%)  9.60
3 ( 2%) 20.00
4 ( 2%) 15.04
5 ( 2%) 16.00
6 ( 2%) 21.74
7 ( 2%) 15.93
8 ( 2%) 15.38
9 ( 1%) 13.95
result accuracy by generalization:
1 (22.45%) 23.45
2 (22.96%) 16.00
3 (22.53%)  9.15
4 (15.82%)  2.32
5 (16.24%)  1.13
error cases:
7 + [-1] [-1] 7 None
1 ) [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
1 ( [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
0 8 [-1] [-1] 0 8
0 8 [-1] [-1] 0 8
4 + [-1] [-1] 4 None
4 7 [-1] [-1] 4 7
val (Perception Acc=78.81, Head Acc=100.00, Result Acc=11.55)
------------------------------
Epoch 0/99 (max_len=1, data=1000)
Train acc: 72.97 (abduce 100.00)
Hit samples:  1000  Ave length:  1.0
Symbols:  10 [(0, 100), (1, 100), (2, 100), (3, 100), (4, 100), (5, 100), (6, 100), (7, 100), (8, 100), (9, 100)]
Head:  [((-1,), 1000)]
Learn perception with 1000 samples for 100 iterations, 1.0, 0.926875, 3200, 16 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 1/99 (max_len=3, data=2170)
Train acc: 85.04 (abduce 98.99)
Hit samples:  2148  Ave length:  2.07
Symbols:  15 [(0, 308), (1, 334), (2, 334), (3, 330), (4, 329), (5, 334), (6, 334), (7, 331), (8, 327), (9, 333), (10, 259), (11, 323), (12, 304), (13, 263), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1148)]
Learn perception with 2148 samples for 100 iterations, 0.9808730873087309, 0.9717117489159611, 4843, 11 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 2/99 (max_len=3, data=2170)
Train acc: 97.61 (abduce 99.95)
Hit samples:  2169  Ave length:  2.08
Symbols:  15 [(0, 310), (1, 337), (2, 336), (3, 334), (4, 336), (5, 338), (6, 338), (7, 337), (8, 329), (9, 341), (10, 279), (11, 320), (12, 302), (13, 269), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1169)]
Learn perception with 2169 samples for 100 iterations, 0.9826935877523851, 0.9722788422339992, 4906, 11 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 3/99 (max_len=3, data=2170)
Train acc: 98.90 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 334), (3, 334), (4, 338), (5, 337), (6, 339), (7, 337), (8, 330), (9, 340), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9831485587583149, 0.9702587084946017, 4909, 11 epochs, take 28 sec.
Epoch time: 0m 29s
------------------------------
Epoch 4/99 (max_len=3, data=2170)
Train acc: 99.54 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 334), (3, 334), (4, 338), (5, 336), (6, 339), (7, 337), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9727031982073742, 4909, 11 epochs, take 29 sec.
              precision    recall  f1-score   support

           0       0.97      1.00      0.99      4016
           1       0.65      0.86      0.74      5142
           2       0.96      0.95      0.96      5321
           3       0.97      0.98      0.97      5241
           4       0.99      0.97      0.98      5279
           5       0.99      0.98      0.98      5383
           6       0.96      0.99      0.97      5427
           7       0.96      0.96      0.96      5462
           8       0.99      0.97      0.98      5453
           9       0.99      0.99      0.99      5476
           +       0.99      0.98      0.99     13199
           -       0.96      0.99      0.97     10734
           *       1.00      1.00      1.00     13491
           /       0.99      0.98      0.98      9876
           (       0.71      0.95      0.82     21081
           )       0.96      0.56      0.70     21081

    accuracy                           0.91    141662
   macro avg       0.94      0.94      0.94    141662
weighted avg       0.93      0.91      0.91    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  313    0    0    1    0    0    2    0    0    0    0    0    1    13   29
2    0    0  357    2    1    0    2    2    0    3    0    0    0    0     0    0
3    1    0    1  360    0    2    0    0    0    1    0    0    0    0     0    0
4    0    2    0    0  361    0    0    0    0    0    2    1    0    0     0    0
5    0    0    0    0    0  371    2    2    0    0    0    0    0    0     4    0
6    0    0    0    0    0    0  380    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    2  369    0    0    2    0    0    0     0    2
8    0    0    2    7    0    0    0    2  372    0    0    0    0    0     0    0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0    0
+    0    1    0    0    0    0    0    1    0    0  916   10    0    0     0    0
-    3    0    0    0    0    0    0    0    0    0    0  749    0    1     1    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0   16    0  680     0    0
(    0   56    2    0    0    0    6    0    0    0    0    2    0    0  1419    2
)    2  101    4    0    0    0    2    2    0    0    0    0    0    2   547  826
result accuracy by length:
1 ( 2%) 97.00
3 ( 2%) 96.00
5 ( 2%) 92.25
7 ( 4%) 82.97
9 ( 4%) 78.39
11 ( 3%) 68.75
13 ( 4%) 68.06
15 ( 4%) 63.86
17 ( 4%) 65.05
19 ( 4%) 55.39
21 ( 4%) 58.59
23 ( 4%) 49.27
25 ( 4%) 48.00
27 ( 4%) 47.78
29 ( 3%) 46.07
31 ( 3%) 47.62
33 ( 2%) 31.43
35 ( 2%) 35.62
37 ( 2%) 37.61
39 ( 3%) 38.82
41 ( 3%) 38.26
43 ( 2%) 31.16
45 ( 2%) 29.46
47 ( 2%) 29.55
49 ( 2%) 22.54
51 ( 2%) 23.48
53 ( 2%) 26.87
55 ( 2%) 20.17
57 ( 2%) 25.17
59 ( 2%) 14.95
61 ( 1%) 28.12
63 ( 0%) 14.29
65 ( 0%) 44.44
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 46.17
) (91%) 46.17
* (87%) 46.06
+ (84%) 44.51
- (77%) 44.44
/ (76%) 43.83
0 (52%) 42.70
1 (60%) 39.99
2 (61%) 42.16
3 (62%) 43.74
4 (61%) 42.45
5 (62%) 43.23
6 (62%) 44.20
7 (63%) 43.36
8 (64%) 43.76
9 (63%) 44.19
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 80.00
2 ( 0%) 100.00
3 ( 0%) 90.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 53.71
1 (10%) 47.19
2 ( 4%) 57.07
3 ( 2%) 51.85
4 ( 2%) 47.37
5 ( 2%) 53.00
6 ( 2%) 64.35
7 ( 2%) 57.52
8 ( 2%) 57.26
9 ( 1%) 67.44
result accuracy by generalization:
1 (22.45%) 69.36
2 (22.96%) 58.31
3 (22.53%) 54.44
4 (15.82%) 29.55
5 (16.24%) 25.63
error cases:
1 ( [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
3 9 [-1] [-1] 3 9
5-0 6-0 [1, -1, 1] [1, -1, 1] 5 6
3*3 3*5 [1, -1, 1] [1, -1, 1] 9 15
9+7 977 [1, -1, 1] [1, -1, 1] 16 None
5+5 5+7 [1, -1, 1] [1, -1, 1] 10 12
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
9-(8-0) 9-18-0( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
val (Perception Acc=91.00, Head Acc=100.00, Result Acc=50.06)
Epoch time: 0m 47s
------------------------------
Epoch 5/99 (max_len=3, data=2170)
Train acc: 99.72 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9727031982073742, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 31s
------------------------------
Epoch 6/99 (max_len=3, data=2170)
Train acc: 99.86 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9729069056834386, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 7/99 (max_len=3, data=2170)
Train acc: 99.81 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9718883683031168, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 31s
------------------------------
Epoch 8/99 (max_len=3, data=2170)
Train acc: 99.72 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9724994907313098, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 9/99 (max_len=3, data=2170)
Train acc: 99.68 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9710735383988592, 4909, 11 epochs, take 29 sec.
              precision    recall  f1-score   support

           0       0.97      1.00      0.99      4016
           1       0.65      0.84      0.73      5142
           2       0.95      0.96      0.95      5321
           3       0.98      0.97      0.97      5241
           4       0.99      0.97      0.98      5279
           5       0.98      0.99      0.98      5383
           6       0.97      0.99      0.98      5427
           7       0.96      0.96      0.96      5462
           8       0.99      0.97      0.98      5453
           9       0.98      0.99      0.99      5476
           +       0.99      0.98      0.99     13199
           -       0.96      0.99      0.98     10734
           *       1.00      1.00      1.00     13491
           /       0.99      0.98      0.98      9876
           (       0.74      0.97      0.84     21081
           )       0.95      0.58      0.72     21081

    accuracy                           0.92    141662
   macro avg       0.94      0.95      0.94    141662
weighted avg       0.93      0.92      0.91    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  303    1    0    1    0    0    2    0    0    0    0    0    0    16   37
2    0    0  359    2    1    0    1    1    0    3    0    0    0    0     0    0
3    2    0    2  358    0    1    0    0    0    1    0    0    0    0     0    0
4    0    2    0    0  359    0    0    0    0    0    2    1    0    0     0    0
5    0    0    0    0    0  375    2    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  380    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    2  369    0    0    2    0    0    0     0    2
8    0    0    2    5    0    2    0    2  372    0    0    0    0    0     0    0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0    0
+    0    2    0    0    0    0    0    1    0    0  916   11    0    0     0    0
-    2    0    0    0    0    0    0    0    0    0    0  752    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0   16    0  680     0    0
(    0   33    2    0    0    0    4    0    0    0    0    2    0    0  1444    2
)    2  118    8    0    0    2    0    4    0    0    0    0    0    6   479  867
result accuracy by length:
1 ( 2%) 97.00
3 ( 2%) 95.00
5 ( 2%) 91.47
7 ( 4%) 82.10
9 ( 4%) 77.39
11 ( 3%) 70.45
13 ( 4%) 71.30
15 ( 4%) 60.40
17 ( 4%) 60.19
19 ( 4%) 55.88
21 ( 4%) 53.54
23 ( 4%) 52.68
25 ( 4%) 49.00
27 ( 4%) 47.29
29 ( 3%) 47.64
31 ( 3%) 45.83
33 ( 2%) 36.43
35 ( 2%) 40.41
37 ( 2%) 38.46
39 ( 3%) 36.84
41 ( 3%) 34.90
43 ( 2%) 28.99
45 ( 2%) 28.57
47 ( 2%) 28.03
49 ( 2%) 26.06
51 ( 2%) 24.24
53 ( 2%) 32.84
55 ( 2%) 17.65
57 ( 2%) 23.78
59 ( 2%) 21.50
61 ( 1%) 20.31
63 ( 0%) 20.00
65 ( 0%) 22.22
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 46.17
) (91%) 46.17
* (87%) 46.13
+ (84%) 44.75
- (77%) 44.38
/ (76%) 43.33
0 (52%) 42.38
1 (60%) 39.26
2 (61%) 42.43
3 (62%) 43.48
4 (61%) 42.85
5 (62%) 43.07
6 (62%) 44.59
7 (63%) 43.30
8 (64%) 43.63
9 (63%) 44.99
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 80.00
2 ( 0%) 100.00
3 ( 0%) 90.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 55.14
1 (10%) 46.25
2 ( 4%) 57.58
3 ( 2%) 54.81
4 ( 2%) 50.38
5 ( 2%) 51.00
6 ( 2%) 57.39
7 ( 2%) 61.06
8 ( 2%) 51.28
9 ( 1%) 61.63
result accuracy by generalization:
1 (22.45%) 69.00
2 (22.96%) 59.11
3 (22.53%) 54.08
4 (15.82%) 29.68
5 (16.24%) 25.13
error cases:
1 ( [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
3 9 [-1] [-1] 3 9
5-0 6-0 [1, -1, 1] [1, -1, 1] 5 6
1+8 (+8 [1, -1, 1] [1, -1, 1] 9 None
3*3 3*5 [1, -1, 1] [1, -1, 1] 9 15
9+7 977 [1, -1, 1] [1, -1, 1] 16 None
1-1 1-) [1, -1, 1] [1, -1, 1] 0 None
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
val (Perception Acc=91.62, Head Acc=100.00, Result Acc=50.02)
Epoch time: 0m 48s
------------------------------
Epoch 10/99 (max_len=3, data=2170)
Train acc: 99.82 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9716846608270524, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 31s
------------------------------
Epoch 11/99 (max_len=3, data=2170)
Train acc: 99.91 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9724994907313098, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 12/99 (max_len=3, data=2170)
Train acc: 99.77 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9739254430637604, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 13/99 (max_len=3, data=2170)
Train acc: 99.68 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9733143206355673, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 31s
------------------------------
Epoch 14/99 (max_len=3, data=2170)
Train acc: 99.54 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 334), (4, 338), (5, 336), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.983370288248337, 0.9757588103483398, 4909, 11 epochs, take 29 sec.
              precision    recall  f1-score   support

           0       0.97      1.00      0.98      4016
           1       0.64      0.83      0.72      5142
           2       0.96      0.96      0.96      5321
           3       0.98      0.98      0.98      5241
           4       0.99      0.97      0.98      5279
           5       0.99      0.98      0.99      5383
           6       0.98      0.99      0.98      5427
           7       0.97      0.97      0.97      5462
           8       0.99      0.97      0.98      5453
           9       0.99      0.99      0.99      5476
           +       0.99      0.99      0.99     13199
           -       0.96      0.99      0.98     10734
           *       1.00      1.00      1.00     13491
           /       0.99      0.98      0.98      9876
           (       0.73      0.97      0.84     21081
           )       0.95      0.57      0.71     21081

    accuracy                           0.91    141662
   macro avg       0.94      0.95      0.94    141662
weighted avg       0.93      0.91      0.91    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  282    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  299    0    0    0    0    0    1    0    0    0    0    0    0    16   42
2    0    0  359    2    1    0    1    1    0    3    0    0    1    0     0    0
3    1    0    1  361    0    1    0    0    0    0    0    0    0    0     0    0
4    0    3    0    0  359    0    0    0    0    0    2    1    0    0     0    0
5    0    0    0    0    0  373    2    0    0    0    0    0    0    0     4    0
6    0    0    0    0    0    0  380    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    0  372    0    0    2    0    0    0     0    2
8    0    0    2    5    0    0    0    2  374    0    0    0    0    0     0    0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0    0
+    0    0    0    0    0    0    0    1    0    0  920    8    0    0     0    0
-    3    0    0    0    0    0    0    0    0    0    1  749    0    1     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0   16    0  680     0    0
(    0   33    0    0    0    0    4    0    0    0    0    2    0    0  1448    0
)    2  126    6    0    0    0    0    2    0    0    0    0    0    2   506  842
result accuracy by length:
1 ( 2%) 98.00
3 ( 2%) 96.00
5 ( 2%) 93.02
7 ( 4%) 82.53
9 ( 4%) 75.88
11 ( 3%) 70.45
13 ( 4%) 71.76
15 ( 4%) 62.38
17 ( 4%) 62.14
19 ( 4%) 53.43
21 ( 4%) 56.57
23 ( 4%) 48.29
25 ( 4%) 49.50
27 ( 4%) 45.81
29 ( 3%) 44.50
31 ( 3%) 44.64
33 ( 2%) 36.43
35 ( 2%) 36.99
37 ( 2%) 39.32
39 ( 3%) 38.82
41 ( 3%) 36.91
43 ( 2%) 27.54
45 ( 2%) 33.04
47 ( 2%) 29.55
49 ( 2%) 23.24
51 ( 2%) 28.03
53 ( 2%) 28.36
55 ( 2%) 14.29
57 ( 2%) 19.58
59 ( 2%) 19.63
61 ( 1%) 21.88
63 ( 0%) 22.86
65 ( 0%) 33.33
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 45.75
) (91%) 45.75
* (87%) 45.66
+ (84%) 44.34
- (77%) 43.75
/ (76%) 43.33
0 (52%) 42.34
1 (60%) 38.32
2 (61%) 41.73
3 (62%) 43.25
4 (61%) 42.82
5 (62%) 42.42
6 (62%) 43.81
7 (63%) 43.07
8 (64%) 43.69
9 (63%) 44.16
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 90.00
2 ( 0%) 100.00
3 ( 0%) 90.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 53.43
1 (10%) 48.13
2 ( 4%) 58.08
3 ( 2%) 57.78
4 ( 2%) 52.63
5 ( 2%) 50.00
6 ( 2%) 56.52
7 ( 2%) 61.95
8 ( 2%) 48.72
9 ( 1%) 61.63
result accuracy by generalization:
1 (22.45%) 68.27
2 (22.96%) 58.40
3 (22.53%) 54.53
4 (15.82%) 28.65
5 (16.24%) 25.75
error cases:
1 ) [-1] [-1] 1 None
3 9 [-1] [-1] 3 9
5-0 6-0 [1, -1, 1] [1, -1, 1] 5 6
1+8 (+8 [1, -1, 1] [1, -1, 1] 9 None
3*3 3*5 [1, -1, 1] [1, -1, 1] 9 15
9+7 977 [1, -1, 1] [1, -1, 1] 16 None
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
9-(8-0) 9-18-0( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
val (Perception Acc=91.43, Head Acc=100.00, Result Acc=49.73)
Epoch time: 0m 48s
------------------------------
Epoch 15/99 (max_len=3, data=2170)
Train acc: 99.86 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 333), (4, 338), (5, 337), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9831485587583149, 0.9700550010185374, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 31s
------------------------------
Epoch 16/99 (max_len=3, data=2170)
Train acc: 99.72 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 333), (4, 338), (5, 337), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9831485587583149, 0.9720920757791811, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 17/99 (max_len=3, data=2170)
Train acc: 99.68 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 333), (4, 338), (5, 337), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9831485587583149, 0.9727031982073742, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 18/99 (max_len=3, data=2170)
Train acc: 99.82 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 333), (4, 338), (5, 337), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9831485587583149, 0.9724994907313098, 4909, 11 epochs, take 29 sec.
Epoch time: 0m 30s
------------------------------
Epoch 19/99 (max_len=3, data=2170)
Train acc: 99.91 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 311), (1, 338), (2, 333), (3, 333), (4, 338), (5, 337), (6, 339), (7, 338), (8, 330), (9, 341), (10, 280), (11, 318), (12, 302), (13, 271), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9831485587583149, 0.9724994907313098, 4909, 11 epochs, take 29 sec.
              precision    recall  f1-score   support

           0       0.95      1.00      0.97      4016
           1       0.59      0.86      0.70      5142
           2       0.97      0.96      0.97      5321
           3       0.98      0.97      0.98      5241
           4       0.98      0.95      0.97      5279
           5       0.98      0.98      0.98      5383
           6       0.97      0.99      0.98      5427
           7       0.97      0.96      0.96      5462
           8       0.99      0.97      0.98      5453
           9       0.98      0.99      0.99      5476
           +       0.99      0.98      0.99     13199
           -       0.96      0.99      0.97     10734
           *       1.00      1.00      1.00     13491
           /       0.98      0.98      0.98      9876
           (       0.74      0.96      0.83     21081
           )       0.96      0.55      0.70     21081

    accuracy                           0.91    141662
   macro avg       0.94      0.94      0.93    141662
weighted avg       0.93      0.91      0.91    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  282    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  313    0    0    0    0    0    1    0    0    0    0    0    0    12   32
2    0    1  359    2    1    0    2    1    0    2    0    0    1    0     0    0
3    1    0    1  360    0    2    0    0    0    1    0    0    0    0     0    0
4    0    5    0    0  355    0    0    0    0    1    3    1    0    0     0    0
5    0    0    0    0    0  373    2    0    0    0    0    0    0    0     4    0
6    0    0    0    0    2    0  378    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    2  369    0    0    2    0    0    0     0    2
8    0    0    2    5    0    2    0    2  372    0    0    0    0    0     0    0
9    2    0    0    0    0    2    0    0    0  382    0    0    0    0     0    0
+    0    0    0    0    0    0    0    3    0    0  915   11    0    0     0    0
-    3    0    0    0    0    0    0    0    0    0    1  749    0    1     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0   16    0  680     0    0
(    4   48    0    0    0    0    4    0    0    0    0    2    0    0  1427    2
)    2  156    2    0    0    0    0    2    0    0    0    0    0    8   493  823
result accuracy by length:
1 ( 2%) 98.00
3 ( 2%) 96.00
5 ( 2%) 92.25
7 ( 4%) 79.91
9 ( 4%) 76.38
11 ( 3%) 63.64
13 ( 4%) 68.06
15 ( 4%) 58.91
17 ( 4%) 55.83
19 ( 4%) 46.08
21 ( 4%) 52.02
23 ( 4%) 45.37
25 ( 4%) 42.50
27 ( 4%) 42.86
29 ( 3%) 41.36
31 ( 3%) 43.45
33 ( 2%) 32.86
35 ( 2%) 33.56
37 ( 2%) 30.77
39 ( 3%) 32.24
41 ( 3%) 28.86
43 ( 2%) 26.09
45 ( 2%) 25.00
47 ( 2%) 24.24
49 ( 2%) 19.01
51 ( 2%) 18.18
53 ( 2%) 28.36
55 ( 2%) 12.61
57 ( 2%) 20.28
59 ( 2%) 20.56
61 ( 1%) 18.75
63 ( 0%)  5.71
65 ( 0%) 33.33
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 41.50
) (91%) 41.50
* (87%) 41.71
+ (84%) 40.18
- (77%) 39.82
/ (76%) 39.20
0 (52%) 38.05
1 (60%) 35.84
2 (61%) 38.34
3 (62%) 39.15
4 (61%) 38.47
5 (62%) 38.77
6 (62%) 40.22
7 (63%) 38.68
8 (64%) 39.36
9 (63%) 39.97
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 90.00
2 ( 0%) 100.00
3 ( 0%) 90.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 49.43
1 (10%) 44.57
2 ( 4%) 53.54
3 ( 2%) 48.15
4 ( 2%) 48.12
5 ( 2%) 50.00
6 ( 2%) 52.17
7 ( 2%) 60.18
8 ( 2%) 49.57
9 ( 1%) 60.47
result accuracy by generalization:
1 (22.45%) 66.18
2 (22.96%) 54.13
3 (22.53%) 49.73
4 (15.82%) 25.55
5 (16.24%) 20.35
error cases:
1 ) [-1] [-1] 1 None
3 9 [-1] [-1] 3 9
5-0 6-0 [1, -1, 1] [1, -1, 1] 5 6
3*3 5*5 [1, -1, 1] [1, -1, 1] 9 25
9+7 977 [1, -1, 1] [1, -1, 1] 16 None
1-1 1-) [1, -1, 1] [1, -1, 1] 0 None
4-(0+8) 4-(0+81 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
val (Perception Acc=90.97, Head Acc=100.00, Result Acc=45.84)
Epoch time: 0m 47s
------------------------------
Epoch 20/99 (max_len=7, data=3387)
Train acc: 93.62 (abduce 99.82)
Hit samples:  3381  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 718), (3, 741), (4, 742), (5, 716), (6, 722), (7, 757), (8, 712), (9, 715), (10, 972), (11, 1029), (12, 934), (13, 886), (14, 713), (15, 312)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 376), ((2, 2, 5, 2, 2, -1, 5), 141), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 87), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3381 samples for 100 iterations, 0.9684980467126589, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 21/99 (max_len=7, data=3387)
Train acc: 98.55 (abduce 99.97)
Hit samples:  3386  Ave length:  3.56
Symbols:  16 [(0, 613), (1, 749), (2, 720), (3, 746), (4, 744), (5, 716), (6, 723), (7, 758), (8, 715), (9, 717), (10, 975), (11, 1031), (12, 935), (13, 890), (14, 718), (15, 316)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 379), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3386 samples for 100 iterations, 0.9685894248301011, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 22/99 (max_len=7, data=3387)
Train acc: 99.30 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 749), (2, 720), (3, 746), (4, 742), (5, 716), (6, 724), (7, 760), (8, 715), (9, 718), (10, 977), (11, 1030), (12, 935), (13, 891), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.968607636875673, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 23/99 (max_len=7, data=3387)
Train acc: 99.03 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 722), (3, 747), (4, 740), (5, 716), (6, 723), (7, 761), (8, 715), (9, 718), (10, 977), (11, 1030), (12, 935), (13, 891), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9684419779673652, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 24/99 (max_len=7, data=3387)
Train acc: 99.47 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 723), (3, 744), (4, 742), (5, 716), (6, 723), (7, 759), (8, 717), (9, 718), (10, 977), (11, 1030), (12, 935), (13, 891), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9688561252381347, 5 epochs, take 29 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.77      0.92      0.84      5142
           2       0.97      0.98      0.98      5321
           3       1.00      0.98      0.99      5241
           4       0.99      0.98      0.98      5279
           5       0.99      0.99      0.99      5383
           6       0.99      0.99      0.99      5427
           7       0.99      0.98      0.98      5462
           8       0.99      0.99      0.99      5453
           9       0.99      0.99      0.99      5476
           +       1.00      0.99      1.00     13199
           -       0.99      0.99      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.73      0.96      0.83     21081
           )       0.99      0.62      0.76     21081

    accuracy                           0.93    141662
   macro avg       0.96      0.96      0.96    141662
weighted avg       0.94      0.93      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  335    1    0    0    0    0    1    0    0    0    0    0    1    11   11
2    0    0  368    0    1    0    0    0    0    1    0    0    0    0     0    0
3    0    0    2  364    0    1    0    0    1    0    0    0    0    0     0    0
4    0    2    0    0  363    0    0    3    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    2    0    0    0    0    0  378    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    0  377    0    0    0    0    0    0     0    0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0    0
9    2    0    0    0    0    2    0    0    0  382    0    0    0    0     0    0
+    0    1    0    0    0    0    0    0    0    0  925    4    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  753    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   47    0    0    0    0    4    0    0    0    0    2    0    0  1431    2
)    0   41    0    0    0    0    0    0    0    0    0    0    0   12   506  927
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 98.00
5 ( 2%) 96.90
7 ( 4%) 89.08
9 ( 4%) 87.44
11 ( 3%) 81.82
13 ( 4%) 80.09
15 ( 4%) 81.19
17 ( 4%) 80.10
19 ( 4%) 74.51
21 ( 4%) 75.76
23 ( 4%) 68.29
25 ( 4%) 67.00
27 ( 4%) 66.01
29 ( 3%) 67.02
31 ( 3%) 65.48
33 ( 2%) 61.43
35 ( 2%) 55.48
37 ( 2%) 57.26
39 ( 3%) 55.92
41 ( 3%) 58.39
43 ( 2%) 58.70
45 ( 2%) 56.25
47 ( 2%) 46.97
49 ( 2%) 47.18
51 ( 2%) 55.30
53 ( 2%) 50.75
55 ( 2%) 46.22
57 ( 2%) 45.45
59 ( 2%) 35.51
61 ( 1%) 43.75
63 ( 0%) 45.71
65 ( 0%) 66.67
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 65.13
) (91%) 65.13
* (87%) 65.05
+ (84%) 64.34
- (77%) 63.52
/ (76%) 63.14
0 (52%) 62.73
1 (60%) 59.97
2 (61%) 62.69
3 (62%) 63.77
4 (61%) 62.26
5 (62%) 62.96
6 (62%) 63.54
7 (63%) 63.29
8 (64%) 63.09
9 (63%) 63.67
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 69.90
1 (10%) 67.42
2 ( 4%) 71.72
3 ( 2%) 68.15
4 ( 2%) 70.68
5 ( 2%) 75.00
6 ( 2%) 79.13
7 ( 2%) 75.22
8 ( 2%) 70.94
9 ( 1%) 73.26
result accuracy by generalization:
1 (22.45%) 81.91
2 (22.96%) 74.04
3 (22.53%) 72.01
4 (15.82%) 54.58
5 (16.24%) 46.73
error cases:
3*3 3*5 [1, -1, 1] [1, -1, 1] 9 15
0+6 0+0 [1, -1, 1] [1, -1, 1] 6 0
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
9-(8-0) 9-18-0( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
6+(2-1) 6+(2-11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 7 None
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
val (Perception Acc=93.02, Head Acc=100.00, Result Acc=67.84)
Epoch time: 0m 49s
------------------------------
Epoch 25/99 (max_len=7, data=3387)
Train acc: 99.50 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 722), (3, 744), (4, 741), (5, 716), (6, 723), (7, 759), (8, 718), (9, 719), (10, 977), (11, 1030), (12, 935), (13, 891), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9688561252381347, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 26/99 (max_len=7, data=3387)
Train acc: 99.56 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 722), (3, 744), (4, 742), (5, 716), (6, 723), (7, 758), (8, 718), (9, 719), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9690217841464425, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 27/99 (max_len=7, data=3387)
Train acc: 99.53 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 613), (1, 748), (2, 722), (3, 744), (4, 743), (5, 716), (6, 723), (7, 758), (8, 718), (9, 719), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9689389546922885, 5 epochs, take 30 sec.
Epoch time: 0m 32s
------------------------------
Epoch 28/99 (max_len=7, data=3387)
Train acc: 99.73 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 613), (1, 748), (2, 721), (3, 744), (4, 744), (5, 716), (6, 723), (7, 758), (8, 719), (9, 718), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9691046136005964, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 29/99 (max_len=7, data=3387)
Train acc: 99.71 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 722), (3, 744), (4, 742), (5, 716), (6, 723), (7, 758), (8, 719), (9, 718), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9691046136005964, 5 epochs, take 29 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.78      0.92      0.84      5142
           2       0.97      0.98      0.98      5321
           3       0.99      0.98      0.99      5241
           4       1.00      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      0.99      0.99      5427
           7       0.99      0.98      0.98      5462
           8       0.99      0.99      0.99      5453
           9       0.99      0.99      0.99      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.73      0.96      0.83     21081
           )       0.99      0.62      0.76     21081

    accuracy                           0.93    141662
   macro avg       0.96      0.96      0.96    141662
weighted avg       0.94      0.93      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  335    1    0    0    0    0    1    0    0    0    0    0    0    11   11
2    0    0  368    1    1    0    1    0    0    1    0    0    0    0     0    0
3    0    0    2  364    0    1    0    0    0    0    0    0    0    0     0    0
4    0    2    0    0  363    0    0    3    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    2    0    0    0    0    0  378    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    0  377    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    2    0    0    0    0    2    0    0    0  382    0    0    0    0     0    0
+    0    1    0    0    0    0    0    0    0    0  925    4    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  754    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   45    0    0    0    0    4    0    0    0    0    2    0    0  1433    2
)    0   41    0    0    0    0    0    0    0    0    0    0    0   12   506  927
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 98.00
5 ( 2%) 97.67
7 ( 4%) 89.52
9 ( 4%) 86.93
11 ( 3%) 80.68
13 ( 4%) 81.02
15 ( 4%) 81.68
17 ( 4%) 81.07
19 ( 4%) 75.00
21 ( 4%) 75.76
23 ( 4%) 67.80
25 ( 4%) 67.00
27 ( 4%) 65.52
29 ( 3%) 69.63
31 ( 3%) 65.48
33 ( 2%) 61.43
35 ( 2%) 57.53
37 ( 2%) 58.12
39 ( 3%) 55.92
41 ( 3%) 58.39
43 ( 2%) 57.25
45 ( 2%) 56.25
47 ( 2%) 46.97
49 ( 2%) 48.59
51 ( 2%) 53.03
53 ( 2%) 51.49
55 ( 2%) 46.22
57 ( 2%) 46.15
59 ( 2%) 38.32
61 ( 1%) 43.75
63 ( 0%) 45.71
65 ( 0%) 66.67
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 65.42
) (91%) 65.42
* (87%) 65.31
+ (84%) 64.63
- (77%) 63.86
/ (76%) 63.44
0 (52%) 62.89
1 (60%) 60.31
2 (61%) 62.96
3 (62%) 64.00
4 (61%) 62.65
5 (62%) 63.38
6 (62%) 63.84
7 (63%) 63.58
8 (64%) 63.22
9 (63%) 63.95
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 70.67
1 (10%) 68.16
2 ( 4%) 72.22
3 ( 2%) 68.89
4 ( 2%) 69.17
5 ( 2%) 75.00
6 ( 2%) 79.13
7 ( 2%) 74.34
8 ( 2%) 71.79
9 ( 1%) 73.26
result accuracy by generalization:
1 (22.45%) 82.09
2 (22.96%) 74.58
3 (22.53%) 72.37
4 (15.82%) 54.84
5 (16.24%) 46.73
error cases:
3*3 3*5 [1, -1, 1] [1, -1, 1] 9 15
0+6 0+0 [1, -1, 1] [1, -1, 1] 6 0
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
6+(2-1) 6+(2-11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 7 None
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
val (Perception Acc=93.02, Head Acc=100.00, Result Acc=68.12)
Epoch time: 0m 49s
------------------------------
Epoch 30/99 (max_len=7, data=3387)
Train acc: 99.56 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 613), (1, 748), (2, 722), (3, 744), (4, 742), (5, 716), (6, 723), (7, 759), (8, 719), (9, 718), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9689389546922885, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 31/99 (max_len=7, data=3387)
Train acc: 99.73 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 613), (1, 748), (2, 721), (3, 744), (4, 744), (5, 716), (6, 723), (7, 758), (8, 719), (9, 718), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9691046136005964, 5 epochs, take 30 sec.
Epoch time: 0m 32s
------------------------------
Epoch 32/99 (max_len=7, data=3387)
Train acc: 99.56 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 721), (3, 744), (4, 743), (5, 716), (6, 723), (7, 758), (8, 719), (9, 718), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9691874430547502, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 33/99 (max_len=7, data=3387)
Train acc: 99.59 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 721), (3, 744), (4, 742), (5, 716), (6, 723), (7, 759), (8, 719), (9, 718), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9691046136005964, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 34/99 (max_len=7, data=3387)
Train acc: 99.71 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 721), (3, 744), (4, 742), (5, 716), (6, 723), (7, 758), (8, 719), (9, 719), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9690217841464425, 5 epochs, take 30 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.78      0.93      0.85      5142
           2       0.97      0.98      0.98      5321
           3       0.99      0.98      0.99      5241
           4       1.00      0.98      0.99      5279
           5       1.00      0.99      1.00      5383
           6       0.99      0.99      0.99      5427
           7       0.99      0.98      0.98      5462
           8       0.99      0.99      0.99      5453
           9       0.99      0.99      0.99      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.73      0.96      0.83     21081
           )       0.99      0.62      0.76     21081

    accuracy                           0.93    141662
   macro avg       0.96      0.96      0.96    141662
weighted avg       0.94      0.93      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  336    1    0    0    0    0    1    0    0    0    0    0    0    11   10
2    0    0  368    0    1    0    0    0    0    1    0    0    0    0     0    0
3    0    0    2  363    0    1    0    0    0    1    0    0    0    0     0    0
4    0    1    0    0  364    0    0    3    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    2    0    0    0    0    0  378    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    0  377    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    2    0    0    0    0    0    0    0    0  384    0    0    0    0     0    0
+    0    1    0    0    0    0    0    0    0    0  926    3    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  754    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   43    0    0    0    0    4    0    0    0    0    2    0    0  1436    2
)    0   41    0    0    0    0    0    0    0    0    0    0    0   12   510  923
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 98.00
5 ( 2%) 97.67
7 ( 4%) 90.39
9 ( 4%) 87.44
11 ( 3%) 81.82
13 ( 4%) 82.41
15 ( 4%) 81.19
17 ( 4%) 81.55
19 ( 4%) 75.00
21 ( 4%) 76.77
23 ( 4%) 68.29
25 ( 4%) 69.00
27 ( 4%) 66.50
29 ( 3%) 69.63
31 ( 3%) 64.29
33 ( 2%) 64.29
35 ( 2%) 56.85
37 ( 2%) 58.97
39 ( 3%) 56.58
41 ( 3%) 59.73
43 ( 2%) 57.97
45 ( 2%) 56.25
47 ( 2%) 48.48
49 ( 2%) 50.00
51 ( 2%) 52.27
53 ( 2%) 50.75
55 ( 2%) 47.06
57 ( 2%) 48.25
59 ( 2%) 41.12
61 ( 1%) 43.75
63 ( 0%) 48.57
65 ( 0%) 66.67
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 66.13
) (91%) 66.13
* (87%) 66.05
+ (84%) 65.30
- (77%) 64.78
/ (76%) 64.10
0 (52%) 63.36
1 (60%) 61.08
2 (61%) 63.72
3 (62%) 64.56
4 (61%) 63.35
5 (62%) 64.06
6 (62%) 64.65
7 (63%) 64.19
8 (64%) 63.95
9 (63%) 64.85
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 71.24
1 (10%) 68.73
2 ( 4%) 72.73
3 ( 2%) 69.63
4 ( 2%) 68.42
5 ( 2%) 76.00
6 ( 2%) 79.13
7 ( 2%) 75.22
8 ( 2%) 71.79
9 ( 1%) 74.42
result accuracy by generalization:
1 (22.45%) 83.00
2 (22.96%) 75.02
3 (22.53%) 72.74
4 (15.82%) 55.61
5 (16.24%) 47.74
error cases:
3*3 3*5 [1, -1, 1] [1, -1, 1] 9 15
0+6 0+0 [1, -1, 1] [1, -1, 1] 6 0
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
6+(2-1) 6+(2-11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 7 None
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
val (Perception Acc=93.04, Head Acc=100.00, Result Acc=68.80)
Epoch time: 0m 49s
------------------------------
Epoch 35/99 (max_len=7, data=3387)
Train acc: 99.71 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 720), (3, 745), (4, 742), (5, 716), (6, 723), (7, 759), (8, 718), (9, 719), (10, 977), (11, 1029), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9689389546922885, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 36/99 (max_len=7, data=3387)
Train acc: 99.59 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 721), (3, 744), (4, 742), (5, 716), (6, 723), (7, 758), (8, 719), (9, 719), (10, 978), (11, 1028), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9691046136005964, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 37/99 (max_len=7, data=3387)
Train acc: 99.46 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 613), (1, 748), (2, 721), (3, 745), (4, 744), (5, 716), (6, 723), (7, 757), (8, 718), (9, 719), (10, 978), (11, 1028), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9690217841464425, 5 epochs, take 30 sec.
Epoch time: 0m 32s
------------------------------
Epoch 38/99 (max_len=7, data=3387)
Train acc: 99.65 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 614), (1, 748), (2, 721), (3, 745), (4, 742), (5, 716), (6, 723), (7, 758), (8, 718), (9, 719), (10, 978), (11, 1028), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9690217841464425, 5 epochs, take 29 sec.
Epoch time: 0m 32s
------------------------------
Epoch 39/99 (max_len=7, data=3387)
Train acc: 99.68 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 613), (1, 748), (2, 721), (3, 744), (4, 743), (5, 716), (6, 723), (7, 758), (8, 719), (9, 719), (10, 978), (11, 1028), (12, 935), (13, 892), (14, 717), (15, 319)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9690217841464425, 5 epochs, take 29 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.79      0.92      0.85      5142
           2       0.97      0.98      0.98      5321
           3       0.99      0.99      0.99      5241
           4       0.99      0.98      0.98      5279
           5       1.00      0.99      1.00      5383
           6       0.99      0.99      0.99      5427
           7       0.99      0.98      0.98      5462
           8       0.99      0.99      0.99      5453
           9       0.99      0.99      0.99      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.73      0.97      0.84     21081
           )       0.99      0.62      0.76     21081

    accuracy                           0.93    141662
   macro avg       0.96      0.96      0.96    141662
weighted avg       0.94      0.93      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  282    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  335    1    0    0    0    0    1    0    0    0    0    0    0    12   11
2    0    0  368    0    1    0    0    0    0    1    0    0    0    0     0    0
3    0    0    2  365    0    0    0    0    0    0    0    0    0    0     0    0
4    0    2    0    0  363    0    0    3    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    2    0    0    0    0    0  378    0    2    0    0    0    0    0     0    0
7    0    5    2    0    0    0    0  377    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    2    0    0    0    0    0    0    0    0  384    0    0    0    0     0    0
+    0    1    0    0    0    0    0    0    0    0  925    4    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  754    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   39    0    0    0    0    2    0    0    0    0    2    0    0  1442    2
)    0   41    0    0    0    0    0    0    0    0    0    0    0   12   508  925
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 98.00
5 ( 2%) 98.45
7 ( 4%) 90.83
9 ( 4%) 86.93
11 ( 3%) 81.82
13 ( 4%) 83.80
15 ( 4%) 81.68
17 ( 4%) 81.55
19 ( 4%) 75.49
21 ( 4%) 78.28
23 ( 4%) 69.27
25 ( 4%) 68.50
27 ( 4%) 67.98
29 ( 3%) 70.68
31 ( 3%) 66.67
33 ( 2%) 64.29
35 ( 2%) 59.59
37 ( 2%) 58.12
39 ( 3%) 57.24
41 ( 3%) 61.07
43 ( 2%) 58.70
45 ( 2%) 58.04
47 ( 2%) 50.76
49 ( 2%) 52.11
51 ( 2%) 53.03
53 ( 2%) 53.73
55 ( 2%) 47.06
57 ( 2%) 48.95
59 ( 2%) 41.12
61 ( 1%) 45.31
63 ( 0%) 45.71
65 ( 0%) 55.56
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 66.98
) (91%) 66.98
* (87%) 66.94
+ (84%) 66.15
- (77%) 65.62
/ (76%) 65.06
0 (52%) 64.22
1 (60%) 61.85
2 (61%) 64.72
3 (62%) 65.74
4 (61%) 64.28
5 (62%) 64.94
6 (62%) 65.50
7 (63%) 65.10
8 (64%) 64.97
9 (63%) 65.71
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 71.81
1 (10%) 69.66
2 ( 4%) 75.25
3 ( 2%) 69.63
4 ( 2%) 70.68
5 ( 2%) 76.00
6 ( 2%) 79.13
7 ( 2%) 75.22
8 ( 2%) 71.79
9 ( 1%) 74.42
result accuracy by generalization:
1 (22.45%) 83.55
2 (22.96%) 75.56
3 (22.53%) 73.64
4 (15.82%) 56.65
5 (16.24%) 48.87
error cases:
3*3 3*5 [1, -1, 1] [1, -1, 1] 9 15
0+6 0+0 [1, -1, 1] [1, -1, 1] 6 0
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
6+(2-1) 6+(2-11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 7 None
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
val (Perception Acc=93.10, Head Acc=100.00, Result Acc=69.59)
Epoch time: 0m 49s
------------------------------
Epoch 40/99 (max_len=11, data=4683)
Train acc: 96.17 (abduce 99.91)
Hit samples:  4679  Ave length:  5.33
Symbols:  16 [(0, 1111), (1, 1345), (2, 1330), (3, 1353), (4, 1305), (5, 1278), (6, 1290), (7, 1367), (8, 1257), (9, 1272), (10, 2193), (11, 2180), (12, 1915), (13, 1969), (14, 2574), (15, 1220)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 113), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 104)]
Learn perception with 4679 samples for 100 iterations, 0.9615369205497015, 3 epochs, take 35 sec.
Epoch time: 0m 40s
------------------------------
Epoch 41/99 (max_len=11, data=4683)
Train acc: 97.42 (abduce 99.96)
Hit samples:  4681  Ave length:  5.34
Symbols:  16 [(0, 1110), (1, 1344), (2, 1334), (3, 1355), (4, 1306), (5, 1279), (6, 1291), (7, 1368), (8, 1257), (9, 1271), (10, 2196), (11, 2183), (12, 1915), (13, 1973), (14, 2591), (15, 1206)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 104)]
Learn perception with 4681 samples for 100 iterations, 0.9612074142279515, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 42/99 (max_len=11, data=4683)
Train acc: 99.01 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1109), (1, 1341), (2, 1335), (3, 1355), (4, 1310), (5, 1278), (6, 1293), (7, 1371), (8, 1262), (9, 1269), (10, 2200), (11, 2182), (12, 1918), (13, 1973), (14, 2594), (15, 1207)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613553626435172, 3 epochs, take 36 sec.
Epoch time: 0m 40s
------------------------------
Epoch 43/99 (max_len=11, data=4683)
Train acc: 99.18 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1110), (1, 1337), (2, 1338), (3, 1355), (4, 1305), (5, 1276), (6, 1295), (7, 1374), (8, 1261), (9, 1272), (10, 2200), (11, 2183), (12, 1918), (13, 1973), (14, 2592), (15, 1208)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613953674440933, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 44/99 (max_len=11, data=4683)
Train acc: 99.35 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1336), (3, 1354), (4, 1304), (5, 1278), (6, 1291), (7, 1376), (8, 1265), (9, 1271), (10, 2200), (11, 2182), (12, 1918), (13, 1973), (14, 2590), (15, 1210)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9617154058487019, 3 epochs, take 35 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.85      0.95      0.90      5142
           2       0.98      0.98      0.98      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.98      0.99      0.98      5462
           8       0.99      0.99      0.99      5453
           9       0.99      0.99      0.99      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.73      0.97      0.83     21081
           )       0.99      0.63      0.77     21081

    accuracy                           0.93    141662
   macro avg       0.97      0.97      0.96    141662
weighted avg       0.95      0.93      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  343    0    0    0    0    0    0    0    0    0    0    0    0     8    7
2    0    0  368    1    0    0    0    0    0    1    0    0    1    0     0    0
3    1    0    1  366    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  364    0    0    4    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    2    2    0    0    0    0  380    0    0    0    0    0    0     0    0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0    0
9    0    0    0    0    0    2    0    0    2  382    0    0    0    0     0    0
+    0    0    0    0    0    0    0    1    0    0  925    3    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   31    0    0    0    0    2    0    0    0    2    2    0    0  1442    6
)    0   24    0    0    0    0    0    0    0    0    0    0    0   14   514  934
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 99.00
5 ( 2%) 98.45
7 ( 4%) 93.45
9 ( 4%) 89.45
11 ( 3%) 86.36
13 ( 4%) 86.57
15 ( 4%) 86.14
17 ( 4%) 81.55
19 ( 4%) 82.84
21 ( 4%) 83.84
23 ( 4%) 79.02
25 ( 4%) 73.00
27 ( 4%) 72.91
29 ( 3%) 76.44
31 ( 3%) 73.21
33 ( 2%) 69.29
35 ( 2%) 67.12
37 ( 2%) 64.96
39 ( 3%) 63.82
41 ( 3%) 67.11
43 ( 2%) 67.39
45 ( 2%) 58.93
47 ( 2%) 61.36
49 ( 2%) 57.75
51 ( 2%) 65.91
53 ( 2%) 67.91
55 ( 2%) 49.58
57 ( 2%) 60.14
59 ( 2%) 51.40
61 ( 1%) 57.81
63 ( 0%) 51.43
65 ( 0%) 66.67
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 73.19
) (91%) 73.19
* (87%) 73.12
+ (84%) 72.42
- (77%) 71.63
/ (76%) 71.34
0 (52%) 71.37
1 (60%) 69.08
2 (61%) 71.66
3 (62%) 71.51
4 (61%) 71.04
5 (62%) 71.48
6 (62%) 71.77
7 (63%) 71.55
8 (64%) 71.11
9 (63%) 71.84
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 76.67
1 (10%) 73.41
2 ( 4%) 78.79
3 ( 2%) 70.37
4 ( 2%) 81.20
5 ( 2%) 80.00
6 ( 2%) 80.00
7 ( 2%) 84.07
8 ( 2%) 74.36
9 ( 1%) 77.91
result accuracy by generalization:
1 (22.45%) 85.00
2 (22.96%) 81.78
3 (22.53%) 79.26
4 (15.82%) 64.65
5 (16.24%) 57.54
error cases:
7*9 7*8 [1, -1, 1] [1, -1, 1] 63 56
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
val (Perception Acc=93.40, Head Acc=100.00, Result Acc=75.29)
Epoch time: 0m 57s
------------------------------
Epoch 45/99 (max_len=11, data=4683)
Train acc: 99.18 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1110), (1, 1338), (2, 1334), (3, 1354), (4, 1305), (5, 1279), (6, 1291), (7, 1376), (8, 1266), (9, 1271), (10, 2199), (11, 2183), (12, 1919), (13, 1972), (14, 2580), (15, 1220)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613553626435172, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 46/99 (max_len=11, data=4683)
Train acc: 99.35 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1110), (1, 1338), (2, 1332), (3, 1353), (4, 1306), (5, 1276), (6, 1293), (7, 1377), (8, 1267), (9, 1272), (10, 2199), (11, 2183), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613553626435172, 3 epochs, take 36 sec.
Epoch time: 0m 40s
------------------------------
Epoch 47/99 (max_len=11, data=4683)
Train acc: 99.39 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1332), (3, 1353), (4, 1306), (5, 1276), (6, 1293), (7, 1377), (8, 1267), (9, 1271), (10, 2198), (11, 2184), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613953674440933, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 48/99 (max_len=11, data=4683)
Train acc: 99.37 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1332), (3, 1353), (4, 1306), (5, 1276), (6, 1293), (7, 1377), (8, 1267), (9, 1271), (10, 2199), (11, 2183), (12, 1919), (13, 1972), (14, 2577), (15, 1223)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613953674440933, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 49/99 (max_len=11, data=4683)
Train acc: 99.46 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1332), (3, 1353), (4, 1306), (5, 1276), (6, 1293), (7, 1377), (8, 1266), (9, 1272), (10, 2199), (11, 2183), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9614753770452454, 3 epochs, take 35 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.86      0.94      0.90      5142
           2       0.98      0.98      0.98      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.98      0.99      0.98      5462
           8       0.99      0.99      0.99      5453
           9       1.00      0.99      0.99      5476
           +       1.00      0.99      0.99     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.73      0.97      0.83     21081
           )       0.98      0.63      0.77     21081

    accuracy                           0.93    141662
   macro avg       0.97      0.97      0.96    141662
weighted avg       0.95      0.93      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  341    0    0    0    0    0    0    0    0    0    0    0    0    11    8
2    0    0  369    1    0    0    0    0    0    0    0    0    1    0     0    0
3    1    0    2  365    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  364    0    0    4    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    2    2    0    0    0    0  380    0    0    0    0    0    0     0    0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0    0
9    0    0    0    0    0    2    0    2    0  382    0    0    0    0     0    0
+    0    0    0    0    0    0    0    1    0    0  925    4    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   31    0    0    0    0    2    0    0    0    2    2    0    0  1442    6
)    0   20    0    0    0    0    0    0    0    0    0    0    0   14   512  940
result accuracy by length:
1 ( 2%) 99.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 92.14
9 ( 4%) 90.95
11 ( 3%) 88.64
13 ( 4%) 86.57
15 ( 4%) 86.63
17 ( 4%) 82.04
19 ( 4%) 80.88
21 ( 4%) 83.33
23 ( 4%) 77.56
25 ( 4%) 75.00
27 ( 4%) 75.86
29 ( 3%) 75.39
31 ( 3%) 73.81
33 ( 2%) 71.43
35 ( 2%) 69.18
37 ( 2%) 64.10
39 ( 3%) 61.18
41 ( 3%) 67.11
43 ( 2%) 66.67
45 ( 2%) 59.82
47 ( 2%) 58.33
49 ( 2%) 59.15
51 ( 2%) 64.39
53 ( 2%) 67.91
55 ( 2%) 57.14
57 ( 2%) 60.14
59 ( 2%) 51.40
61 ( 1%) 51.56
63 ( 0%) 42.86
65 ( 0%) 55.56
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 73.32
) (91%) 73.32
* (87%) 73.31
+ (84%) 72.45
- (77%) 71.71
/ (76%) 71.56
0 (52%) 71.48
1 (60%) 68.91
2 (61%) 71.93
3 (62%) 71.80
4 (61%) 71.08
5 (62%) 71.29
6 (62%) 71.97
7 (63%) 71.52
8 (64%) 71.15
9 (63%) 71.81
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 90.00
result accuracy by result:
0 (21%) 77.52
1 (10%) 73.03
2 ( 4%) 79.29
3 ( 2%) 71.85
4 ( 2%) 82.71
5 ( 2%) 82.00
6 ( 2%) 79.13
7 ( 2%) 83.19
8 ( 2%) 76.92
9 ( 1%) 79.07
result accuracy by generalization:
1 (22.45%) 85.45
2 (22.96%) 82.49
3 (22.53%) 79.17
4 (15.82%) 62.58
5 (16.24%) 58.67
error cases:
9 7 [-1] [-1] 9 7
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
6+(2+9) 6+12+9) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 17 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
val (Perception Acc=93.44, Head Acc=100.00, Result Acc=75.39)
Epoch time: 0m 56s
------------------------------
Epoch 50/99 (max_len=11, data=4683)
Train acc: 99.54 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1332), (3, 1353), (4, 1306), (5, 1276), (6, 1293), (7, 1377), (8, 1266), (9, 1272), (10, 2199), (11, 2183), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9614753770452454, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 51/99 (max_len=11, data=4683)
Train acc: 99.58 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1333), (3, 1353), (4, 1305), (5, 1276), (6, 1293), (7, 1377), (8, 1266), (9, 1272), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9614753770452454, 3 epochs, take 35 sec.
Epoch time: 0m 40s
------------------------------
Epoch 52/99 (max_len=11, data=4683)
Train acc: 99.70 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1332), (3, 1353), (4, 1306), (5, 1276), (6, 1293), (7, 1377), (8, 1266), (9, 1272), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9615153818458215, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 53/99 (max_len=11, data=4683)
Train acc: 99.46 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1332), (3, 1353), (4, 1306), (5, 1276), (6, 1293), (7, 1377), (8, 1266), (9, 1272), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9615153818458215, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 54/99 (max_len=11, data=4683)
Train acc: 99.56 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1333), (3, 1353), (4, 1305), (5, 1275), (6, 1293), (7, 1378), (8, 1266), (9, 1272), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9614353722446694, 3 epochs, take 35 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.86      0.94      0.90      5142
           2       0.98      0.98      0.98      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.98      0.99      0.98      5462
           8       0.99      0.99      0.99      5453
           9       1.00      0.99      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.74      0.97      0.84     21081
           )       0.99      0.64      0.77     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.96    141662
weighted avg       0.95      0.94      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  342    0    0    0    0    0    0    0    0    0    0    0    0    10    8
2    0    0  368    1    0    0    0    0    0    0    0    0    1    0     0    0
3    1    0    1  366    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  364    0    0    4    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    2    2    0    0    0    0  380    0    0    0    0    0    0     0    0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0    0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0    0
+    0    0    0    0    0    0    0    1    0    0  925    3    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   31    0    0    0    0    2    0    0    0    2    2    0    0  1442    6
)    0   20    0    0    0    0    0    0    0    0    0    0    0   14   504  948
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 92.58
9 ( 4%) 90.95
11 ( 3%) 88.07
13 ( 4%) 86.57
15 ( 4%) 87.13
17 ( 4%) 81.55
19 ( 4%) 81.86
21 ( 4%) 83.84
23 ( 4%) 78.05
25 ( 4%) 75.00
27 ( 4%) 75.86
29 ( 3%) 75.39
31 ( 3%) 75.00
33 ( 2%) 72.14
35 ( 2%) 70.55
37 ( 2%) 64.96
39 ( 3%) 61.84
41 ( 3%) 69.13
43 ( 2%) 67.39
45 ( 2%) 62.50
47 ( 2%) 58.33
49 ( 2%) 59.15
51 ( 2%) 66.67
53 ( 2%) 68.66
55 ( 2%) 57.14
57 ( 2%) 60.14
59 ( 2%) 50.47
61 ( 1%) 51.56
63 ( 0%) 42.86
65 ( 0%) 55.56
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 73.77
) (91%) 73.77
* (87%) 73.82
+ (84%) 72.93
- (77%) 72.13
/ (76%) 72.01
0 (52%) 72.15
1 (60%) 69.44
2 (61%) 72.39
3 (62%) 72.43
4 (61%) 71.44
5 (62%) 71.78
6 (62%) 72.53
7 (63%) 72.01
8 (64%) 71.56
9 (63%) 72.38
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 77.81
1 (10%) 73.22
2 ( 4%) 79.80
3 ( 2%) 72.59
4 ( 2%) 82.71
5 ( 2%) 82.00
6 ( 2%) 80.00
7 ( 2%) 84.07
8 ( 2%) 76.92
9 ( 1%) 80.23
result accuracy by generalization:
1 (22.45%) 85.64
2 (22.96%) 82.84
3 (22.53%) 79.62
4 (15.82%) 63.23
5 (16.24%) 59.42
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
6+(2+9) 6+12+9) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 17 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
val (Perception Acc=93.56, Head Acc=100.00, Result Acc=75.84)
Epoch time: 0m 56s
------------------------------
Epoch 55/99 (max_len=11, data=4683)
Train acc: 99.64 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1338), (2, 1333), (3, 1353), (4, 1304), (5, 1275), (6, 1293), (7, 1378), (8, 1266), (9, 1273), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613953674440933, 3 epochs, take 35 sec.
Epoch time: 0m 38s
------------------------------
Epoch 56/99 (max_len=11, data=4683)
Train acc: 99.51 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1110), (1, 1338), (2, 1332), (3, 1353), (4, 1305), (5, 1276), (6, 1293), (7, 1378), (8, 1266), (9, 1273), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613953674440933, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 57/99 (max_len=11, data=4683)
Train acc: 99.46 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1110), (1, 1338), (2, 1333), (3, 1353), (4, 1305), (5, 1276), (6, 1293), (7, 1377), (8, 1266), (9, 1273), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613953674440933, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 58/99 (max_len=11, data=4683)
Train acc: 99.58 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1111), (1, 1339), (2, 1333), (3, 1352), (4, 1305), (5, 1273), (6, 1293), (7, 1377), (8, 1266), (9, 1275), (10, 2200), (11, 2182), (12, 1919), (13, 1972), (14, 2578), (15, 1222)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9613553626435172, 3 epochs, take 35 sec.
Epoch time: 0m 39s
------------------------------
Epoch 59/99 (max_len=11, data=4683)
Train acc: 98.92 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1112), (1, 1337), (2, 1334), (3, 1351), (4, 1306), (5, 1274), (6, 1293), (7, 1377), (8, 1265), (9, 1275), (10, 2198), (11, 2181), (12, 1922), (13, 1972), (14, 2577), (15, 1223)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.961235348241789, 3 epochs, take 35 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.80      0.94      0.87      5142
           2       0.98      0.98      0.98      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.97      0.97      0.97      5462
           8       0.99      0.99      0.99      5453
           9       0.99      0.99      0.99      5476
           +       1.00      0.99      0.99     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.73      0.95      0.83     21081
           )       0.98      0.63      0.76     21081

    accuracy                           0.93    141662
   macro avg       0.96      0.96      0.96    141662
weighted avg       0.94      0.93      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  342    0    0    0    0    0    1    0    0    0    0    0    0     9    7
2    0    0  368    0    0    0    0    1    0    0    0    0    0    0     0    0
3    0    0    1  365    0    0    0    0    0    1    0    0    0    0     0    0
4    0    0    0    0  364    0    0    4    0    0    0    1    0    0     0    0
5    0    0    0    0    0  377    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    7    2    0    0    0    0  374    0    0    0    0    0    0     0    0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0    0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0    0
+    0    0    0    0    1    0    0    2    0    0  921    4    1    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   50    0    0    0    0    2    0    0    0    0    2    0    0  1419   12
)    0   26    0    0    0    0    0    0    0    0    0    0    0   14   512  934
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 96.90
7 ( 4%) 92.14
9 ( 4%) 86.43
11 ( 3%) 88.07
13 ( 4%) 81.02
15 ( 4%) 83.17
17 ( 4%) 77.18
19 ( 4%) 75.98
21 ( 4%) 79.80
23 ( 4%) 72.68
25 ( 4%) 67.50
27 ( 4%) 68.47
29 ( 3%) 70.16
31 ( 3%) 66.67
33 ( 2%) 63.57
35 ( 2%) 64.38
37 ( 2%) 52.99
39 ( 3%) 53.95
41 ( 3%) 64.43
43 ( 2%) 60.87
45 ( 2%) 56.25
47 ( 2%) 54.55
49 ( 2%) 50.00
51 ( 2%) 56.82
53 ( 2%) 58.21
55 ( 2%) 44.54
57 ( 2%) 53.15
59 ( 2%) 46.73
61 ( 1%) 54.69
63 ( 0%) 42.86
65 ( 0%) 66.67
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 67.94
) (91%) 67.94
* (87%) 67.80
+ (84%) 66.89
- (77%) 66.14
/ (76%) 65.97
0 (52%) 65.82
1 (60%) 63.62
2 (61%) 65.75
3 (62%) 66.36
4 (61%) 65.37
5 (62%) 65.69
6 (62%) 66.45
7 (63%) 65.77
8 (64%) 65.83
9 (63%) 66.41
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 73.05
1 (10%) 68.73
2 ( 4%) 73.74
3 ( 2%) 68.15
4 ( 2%) 72.93
5 ( 2%) 78.00
6 ( 2%) 78.26
7 ( 2%) 77.88
8 ( 2%) 68.38
9 ( 1%) 74.42
result accuracy by generalization:
1 (22.45%) 82.09
2 (22.96%) 77.07
3 (22.53%) 74.46
4 (15.82%) 58.19
5 (16.24%) 51.01
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
4*(0-0) 4*10-0( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
val (Perception Acc=93.08, Head Acc=100.00, Result Acc=70.39)
Epoch time: 0m 57s
------------------------------
Epoch 60/99 (max_len=15, data=6058)
Train acc: 95.21 (abduce 99.87)
Hit samples:  6050  Ave length:  7.3
Symbols:  16 [(0, 1753), (1, 2155), (2, 2178), (3, 2199), (4, 2082), (5, 2076), (6, 2074), (7, 2186), (8, 2028), (9, 2057), (10, 3905), (11, 3895), (12, 3422), (13, 3563), (14, 5799), (15, 2786)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6050 samples for 100 iterations, 0.9524434983468454, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 61/99 (max_len=15, data=6058)
Train acc: 96.56 (abduce 99.80)
Hit samples:  6046  Ave length:  7.3
Symbols:  16 [(0, 1755), (1, 2142), (2, 2177), (3, 2191), (4, 2078), (5, 2076), (6, 2077), (7, 2187), (8, 2029), (9, 2055), (10, 3904), (11, 3889), (12, 3414), (13, 3558), (14, 5617), (15, 2957)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6046 samples for 100 iterations, 0.9560830725978325, 2 epochs, take 42 sec.
Epoch time: 0m 48s
------------------------------
Epoch 62/99 (max_len=15, data=6058)
Train acc: 97.44 (abduce 99.88)
Hit samples:  6051  Ave length:  7.3
Symbols:  16 [(0, 1755), (1, 2145), (2, 2179), (3, 2194), (4, 2084), (5, 2078), (6, 2078), (7, 2190), (8, 2033), (9, 2060), (10, 3909), (11, 3894), (12, 3419), (13, 3563), (14, 5583), (15, 3009)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6051 samples for 100 iterations, 0.9569193851447717, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 63/99 (max_len=15, data=6058)
Train acc: 97.98 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1758), (1, 2148), (2, 2183), (3, 2192), (4, 2087), (5, 2080), (6, 2082), (7, 2191), (8, 2037), (9, 2061), (10, 3912), (11, 3898), (12, 3422), (13, 3571), (14, 5470), (15, 3122)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9584294567331615, 2 epochs, take 41 sec.
Epoch time: 0m 47s
------------------------------
Epoch 64/99 (max_len=15, data=6058)
Train acc: 98.21 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1759), (1, 2147), (2, 2185), (3, 2189), (4, 2085), (5, 2083), (6, 2082), (7, 2189), (8, 2039), (9, 2061), (10, 3914), (11, 3895), (12, 3422), (13, 3571), (14, 5446), (15, 3147)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9582485185687791, 2 epochs, take 41 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      0.99      4016
           1       0.90      0.95      0.92      5142
           2       0.98      0.99      0.99      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      1.00      1.00      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       0.99      0.99      0.99      5453
           9       1.00      0.99      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.97      1.00      0.98      9876
           (       0.77      0.97      0.86     21081
           )       0.97      0.70      0.81     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  345    0    0    0    0    0    0    0    0    0    0    0    0    10     4
2    0    0  371    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    1  364    0    0    0    0    0    1    0    0    0    0     0     0
4    0    0    0    0  366    0    0    1    0    0    0    1    0    0     0     0
5    0    0    0    0    0  379    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    2    0    2    0    0  380    0    0    0    0    0    0     0     0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0     0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  925    4    1    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    2   16    0    0    0    0    2    0    0    0    0    2    0    0  1438    26
)    0   22    0    0    0    0    0    0    0    0    0    0    0   20   408  1035
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 97.67
7 ( 4%) 95.63
9 ( 4%) 91.46
11 ( 3%) 89.20
13 ( 4%) 92.13
15 ( 4%) 87.62
17 ( 4%) 86.41
19 ( 4%) 83.33
21 ( 4%) 87.88
23 ( 4%) 83.90
25 ( 4%) 80.50
27 ( 4%) 77.83
29 ( 3%) 79.06
31 ( 3%) 77.38
33 ( 2%) 82.86
35 ( 2%) 72.60
37 ( 2%) 66.67
39 ( 3%) 69.08
41 ( 3%) 77.18
43 ( 2%) 74.64
45 ( 2%) 63.39
47 ( 2%) 65.91
49 ( 2%) 66.90
51 ( 2%) 79.55
53 ( 2%) 68.66
55 ( 2%) 61.34
57 ( 2%) 67.13
59 ( 2%) 65.42
61 ( 1%) 65.62
63 ( 0%) 54.29
65 ( 0%) 66.67
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 78.54
) (91%) 78.54
* (87%) 78.49
+ (84%) 77.69
- (77%) 77.43
/ (76%) 77.07
0 (52%) 76.99
1 (60%) 75.20
2 (61%) 76.91
3 (62%) 77.18
4 (61%) 76.95
5 (62%) 77.18
6 (62%) 77.23
7 (63%) 77.17
8 (64%) 76.88
9 (63%) 77.78
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 82.48
1 (10%) 80.34
2 ( 4%) 83.84
3 ( 2%) 72.59
4 ( 2%) 90.23
5 ( 2%) 84.00
6 ( 2%) 80.87
7 ( 2%) 84.96
8 ( 2%) 76.07
9 ( 1%) 80.23
result accuracy by generalization:
1 (22.45%) 89.00
2 (22.96%) 85.42
3 (22.53%) 82.79
4 (15.82%) 70.71
5 (16.24%) 66.71
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
(4+8)/8 (4+81/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
9+2/5 9*2/5 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 10 9
(0+7)*4 (0-71*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
6*(3*6) 6*(3*61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 108 None
val (Perception Acc=94.48, Head Acc=100.00, Result Acc=80.27)
Epoch time: 1m 5s
------------------------------
Epoch 65/99 (max_len=15, data=6058)
Train acc: 98.47 (abduce 99.92)
Hit samples:  6053  Ave length:  7.3
Symbols:  16 [(0, 1756), (1, 2142), (2, 2182), (3, 2191), (4, 2084), (5, 2084), (6, 2082), (7, 2191), (8, 2037), (9, 2058), (10, 3915), (11, 3894), (12, 3419), (13, 3580), (14, 5446), (15, 3138)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6053 samples for 100 iterations, 0.9590488472589878, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 66/99 (max_len=15, data=6058)
Train acc: 98.58 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1759), (1, 2143), (2, 2182), (3, 2192), (4, 2081), (5, 2082), (6, 2081), (7, 2192), (8, 2038), (9, 2064), (10, 3918), (11, 3891), (12, 3422), (13, 3583), (14, 5410), (15, 3176)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.959130592120143, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 67/99 (max_len=15, data=6058)
Train acc: 98.73 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1761), (1, 2143), (2, 2184), (3, 2190), (4, 2080), (5, 2080), (6, 2082), (7, 2195), (8, 2040), (9, 2064), (10, 3923), (11, 3885), (12, 3421), (13, 3580), (14, 5382), (15, 3204)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9589044194146651, 2 epochs, take 41 sec.
Epoch time: 0m 47s
------------------------------
Epoch 68/99 (max_len=15, data=6058)
Train acc: 98.76 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1758), (1, 2141), (2, 2181), (3, 2189), (4, 2078), (5, 2080), (6, 2084), (7, 2195), (8, 2045), (9, 2063), (10, 3925), (11, 3886), (12, 3422), (13, 3577), (14, 5386), (15, 3204)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9587687157913783, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 69/99 (max_len=15, data=6058)
Train acc: 98.84 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1760), (1, 2139), (2, 2179), (3, 2191), (4, 2078), (5, 2080), (6, 2082), (7, 2196), (8, 2044), (9, 2062), (10, 3924), (11, 3886), (12, 3423), (13, 3576), (14, 5394), (15, 3200)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9590853575790473, 2 epochs, take 41 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.87      0.95      0.91      5142
           2       0.98      0.99      0.98      5321
           3       0.99      0.98      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       0.99      0.99      0.99      5453
           9       1.00      0.99      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.78      0.96      0.86     21081
           )       0.97      0.70      0.81     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  345    0    0    0    0    0    0    0    0    0    0    0    0     8     7
2    0    0  371    1    0    0    0    0    0    0    0    0    0    0     0     0
3    1    0    1  363    0    0    0    0    0    1    0    0    0    0     0     0
4    0    0    0    0  365    0    0    2    0    0    0    1    0    0     0     0
5    0    0    2    0    0  377    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    2    0    2    0    0  380    0    0    0    0    0    0     0     0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0     0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  925    5    1    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    2   24    0    0    0    0    2    0    0    0    0    2    0    0  1427    29
)    0   26    0    0    0    2    0    0    0    0    0    0    0   16   402  1039
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 95.35
7 ( 4%) 94.76
9 ( 4%) 89.45
11 ( 3%) 87.50
13 ( 4%) 88.43
15 ( 4%) 86.14
17 ( 4%) 86.41
19 ( 4%) 79.90
21 ( 4%) 84.85
23 ( 4%) 82.44
25 ( 4%) 76.00
27 ( 4%) 74.88
29 ( 3%) 75.39
31 ( 3%) 72.02
33 ( 2%) 76.43
35 ( 2%) 68.49
37 ( 2%) 66.67
39 ( 3%) 61.84
41 ( 3%) 72.48
43 ( 2%) 71.74
45 ( 2%) 60.71
47 ( 2%) 64.39
49 ( 2%) 59.86
51 ( 2%) 73.48
53 ( 2%) 63.43
55 ( 2%) 53.78
57 ( 2%) 65.03
59 ( 2%) 57.01
61 ( 1%) 60.94
63 ( 0%) 40.00
65 ( 0%) 66.67
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 74.93
) (91%) 74.93
* (87%) 74.82
+ (84%) 74.01
- (77%) 73.67
/ (76%) 73.40
0 (52%) 72.66
1 (60%) 71.49
2 (61%) 72.89
3 (62%) 73.51
4 (61%) 72.80
5 (62%) 73.11
6 (62%) 73.60
7 (63%) 73.33
8 (64%) 72.96
9 (63%) 73.98
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 78.57
1 (10%) 76.22
2 ( 4%) 83.33
3 ( 2%) 71.11
4 ( 2%) 81.95
5 ( 2%) 84.00
6 ( 2%) 80.00
7 ( 2%) 84.96
8 ( 2%) 72.65
9 ( 1%) 77.91
result accuracy by generalization:
1 (22.45%) 86.55
2 (22.96%) 82.49
3 (22.53%) 80.53
4 (15.82%) 65.42
5 (16.24%) 61.68
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
8-4+9 8-4-9 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 13 0
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
(4+8)/8 (4+81/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
9+2/5 9*2/5 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 10 9
(0+7)*4 (0-71*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 None
8/2/1 8/2/( [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 4 None
val (Perception Acc=94.37, Head Acc=100.00, Result Acc=76.88)
Epoch time: 1m 5s
------------------------------
Epoch 70/99 (max_len=15, data=6058)
Train acc: 98.81 (abduce 99.92)
Hit samples:  6053  Ave length:  7.3
Symbols:  16 [(0, 1760), (1, 2140), (2, 2175), (3, 2189), (4, 2082), (5, 2079), (6, 2084), (7, 2192), (8, 2045), (9, 2063), (10, 3922), (11, 3887), (12, 3420), (13, 3578), (14, 5385), (15, 3202)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6053 samples for 100 iterations, 0.9590751758930389, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 71/99 (max_len=15, data=6058)
Train acc: 98.91 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1758), (1, 2141), (2, 2174), (3, 2192), (4, 2083), (5, 2080), (6, 2084), (7, 2196), (8, 2046), (9, 2060), (10, 3921), (11, 3889), (12, 3423), (13, 3578), (14, 5376), (15, 3213)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9587913330619261, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 72/99 (max_len=15, data=6058)
Train acc: 98.78 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1759), (1, 2141), (2, 2176), (3, 2190), (4, 2086), (5, 2079), (6, 2083), (7, 2193), (8, 2046), (9, 2061), (10, 3923), (11, 3887), (12, 3423), (13, 3580), (14, 5372), (15, 3215)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9588365676030217, 2 epochs, take 41 sec.
Epoch time: 0m 47s
------------------------------
Epoch 73/99 (max_len=15, data=6058)
Train acc: 99.02 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1758), (1, 2140), (2, 2177), (3, 2190), (4, 2085), (5, 2079), (6, 2081), (7, 2192), (8, 2046), (9, 2063), (10, 3926), (11, 3886), (12, 3422), (13, 3579), (14, 5371), (15, 3219)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9589948884968562, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 74/99 (max_len=15, data=6058)
Train acc: 98.99 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1758), (1, 2143), (2, 2176), (3, 2191), (4, 2084), (5, 2080), (6, 2081), (7, 2192), (8, 2046), (9, 2063), (10, 3925), (11, 3886), (12, 3422), (13, 3579), (14, 5370), (15, 3218)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9590627403084996, 2 epochs, take 41 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.88      0.95      0.91      5142
           2       0.98      0.99      0.98      5321
           3       0.99      0.98      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       0.99      0.99      0.99      5453
           9       1.00      0.99      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.97      1.00      0.99      9876
           (       0.78      0.96      0.86     21081
           )       0.96      0.71      0.82     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  343    0    0    0    0    0    0    0    0    0    0    0    0     8     8
2    0    0  370    1    1    0    0    0    0    0    0    0    0    0     0     0
3    1    0    1  363    0    0    0    0    0    1    0    0    0    0     0     0
4    0    0    0    0  366    0    0    1    0    0    0    1    0    0     0     0
5    0    0    2    0    0  377    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    2    0    2    0    0  380    0    0    0    0    0    0     0     0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0     0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  925    4    1    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    2   26    0    0    0    0    2    0    0    0    0    2    0    0  1423    31
)    0   20    0    0    0    0    0    0    0    0    0    0    0   18   394  1054
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 96.12
7 ( 4%) 95.63
9 ( 4%) 89.95
11 ( 3%) 85.23
13 ( 4%) 89.81
15 ( 4%) 86.63
17 ( 4%) 86.41
19 ( 4%) 81.86
21 ( 4%) 85.35
23 ( 4%) 80.98
25 ( 4%) 78.00
27 ( 4%) 79.31
29 ( 3%) 75.92
31 ( 3%) 77.38
33 ( 2%) 77.14
35 ( 2%) 67.81
37 ( 2%) 65.81
39 ( 3%) 61.18
41 ( 3%) 72.48
43 ( 2%) 72.46
45 ( 2%) 63.39
47 ( 2%) 64.39
49 ( 2%) 61.27
51 ( 2%) 75.76
53 ( 2%) 65.67
55 ( 2%) 57.14
57 ( 2%) 64.34
59 ( 2%) 59.81
61 ( 1%) 62.50
63 ( 0%) 48.57
65 ( 0%) 55.56
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 76.00
) (91%) 76.00
* (87%) 75.80
+ (84%) 75.21
- (77%) 74.86
/ (76%) 74.49
0 (52%) 74.18
1 (60%) 72.26
2 (61%) 74.12
3 (62%) 74.62
4 (61%) 74.30
5 (62%) 74.74
6 (62%) 74.94
7 (63%) 74.43
8 (64%) 74.24
9 (63%) 74.90
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 79.71
1 (10%) 78.28
2 ( 4%) 82.83
3 ( 2%) 72.59
4 ( 2%) 84.21
5 ( 2%) 81.00
6 ( 2%) 80.87
7 ( 2%) 82.30
8 ( 2%) 71.79
9 ( 1%) 83.72
result accuracy by generalization:
1 (22.45%) 87.36
2 (22.96%) 83.56
3 (22.53%) 81.16
4 (15.82%) 65.81
5 (16.24%) 63.94
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
8-4+9 8-4-9 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 13 0
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
(4+8)/8 (4+81/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
9+2/5 9*2/5 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 10 9
(0+7)*4 (0-71*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
val (Perception Acc=94.46, Head Acc=100.00, Result Acc=77.88)
Epoch time: 1m 5s
------------------------------
Epoch 75/99 (max_len=15, data=6058)
Train acc: 99.07 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1758), (1, 2143), (2, 2177), (3, 2191), (4, 2084), (5, 2080), (6, 2081), (7, 2194), (8, 2046), (9, 2060), (10, 3926), (11, 3885), (12, 3422), (13, 3579), (14, 5367), (15, 3221)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.959017505767404, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 76/99 (max_len=15, data=6058)
Train acc: 99.10 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1758), (1, 2141), (2, 2176), (3, 2191), (4, 2082), (5, 2080), (6, 2080), (7, 2195), (8, 2046), (9, 2062), (10, 3928), (11, 3885), (12, 3421), (13, 3579), (14, 5338), (15, 3252)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9597864929660289, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 77/99 (max_len=15, data=6058)
Train acc: 98.50 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1759), (1, 2142), (2, 2175), (3, 2190), (4, 2082), (5, 2079), (6, 2080), (7, 2196), (8, 2047), (9, 2061), (10, 3930), (11, 3886), (12, 3420), (13, 3578), (14, 5316), (15, 3273)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9602614556475324, 2 epochs, take 41 sec.
Epoch time: 0m 48s
------------------------------
Epoch 78/99 (max_len=15, data=6058)
Train acc: 98.94 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1757), (1, 2142), (2, 2175), (3, 2191), (4, 2082), (5, 2081), (6, 2080), (7, 2193), (8, 2046), (9, 2063), (10, 3929), (11, 3886), (12, 3421), (13, 3582), (14, 5313), (15, 3273)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.9602840729180803, 2 epochs, take 42 sec.
Epoch time: 0m 49s
------------------------------
Epoch 79/99 (max_len=15, data=6058)
Train acc: 99.04 (abduce 99.93)
Hit samples:  6054  Ave length:  7.3
Symbols:  16 [(0, 1757), (1, 2142), (2, 2175), (3, 2191), (4, 2081), (5, 2081), (6, 2080), (7, 2194), (8, 2046), (9, 2063), (10, 3927), (11, 3888), (12, 3421), (13, 3581), (14, 5310), (15, 3277)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6054 samples for 100 iterations, 0.960306690188628, 2 epochs, take 41 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.88      0.95      0.92      5142
           2       0.98      0.99      0.98      5321
           3       0.99      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       0.99      0.99      0.99      5453
           9       1.00      0.99      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.97      1.00      0.99      9876
           (       0.78      0.96      0.86     21081
           )       0.97      0.71      0.82     21081

    accuracy                           0.95    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.95      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  345    0    0    0    0    0    0    0    0    0    0    0    0     7     8
2    0    0  371    1    0    0    0    0    0    0    0    0    0    0     0     0
3    1    0    1  364    0    0    0    0    0    1    0    0    0    0     0     0
4    0    0    0    0  365    0    0    2    0    0    0    1    0    0     0     0
5    0    0    2    0    0  377    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    2    0    2    0    0  380    0    0    0    0    0    0     0     0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0     0
9    0    0    0    0    0    2    0    0    0  384    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  926    4    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    2   24    0    0    0    0    2    0    0    0    0    2    0    0  1427    29
)    0   20    0    0    0    0    0    0    0    0    0    0    0   18   390  1058
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 96.90
7 ( 4%) 95.63
9 ( 4%) 91.46
11 ( 3%) 86.93
13 ( 4%) 88.43
15 ( 4%) 87.13
17 ( 4%) 87.86
19 ( 4%) 83.82
21 ( 4%) 84.85
23 ( 4%) 82.93
25 ( 4%) 77.00
27 ( 4%) 78.33
29 ( 3%) 78.01
31 ( 3%) 73.81
33 ( 2%) 76.43
35 ( 2%) 71.92
37 ( 2%) 70.94
39 ( 3%) 63.82
41 ( 3%) 73.83
43 ( 2%) 72.46
45 ( 2%) 58.04
47 ( 2%) 65.91
49 ( 2%) 64.79
51 ( 2%) 75.00
53 ( 2%) 68.66
55 ( 2%) 59.66
57 ( 2%) 63.64
59 ( 2%) 57.94
61 ( 1%) 59.38
63 ( 0%) 45.71
65 ( 0%) 88.89
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 76.62
) (91%) 76.62
* (87%) 76.54
+ (84%) 75.84
- (77%) 75.28
/ (76%) 75.21
0 (52%) 74.73
1 (60%) 72.62
2 (61%) 74.82
3 (62%) 75.31
4 (61%) 74.73
5 (62%) 75.10
6 (62%) 75.47
7 (63%) 74.91
8 (64%) 74.78
9 (63%) 75.57
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 80.76
1 (10%) 77.34
2 ( 4%) 83.33
3 ( 2%) 73.33
4 ( 2%) 86.47
5 ( 2%) 85.00
6 ( 2%) 83.48
7 ( 2%) 83.19
8 ( 2%) 74.36
9 ( 1%) 83.72
result accuracy by generalization:
1 (22.45%) 87.09
2 (22.96%) 84.18
3 (22.53%) 82.61
4 (15.82%) 67.35
5 (16.24%) 63.69
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) 7-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
8-4+9 8-4-9 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 13 0
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
(4+8)/8 (4+81/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
(0+7)*4 (0-71*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
6*5*6 6*2*6 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 180 72
val (Perception Acc=94.57, Head Acc=100.00, Result Acc=78.49)
Epoch time: 1m 5s
------------------------------
Epoch 80/99 (max_len=inf, data=11170)
Train acc: 91.86 (abduce 99.74)
Hit samples:  11141  Ave length:  14.85
Symbols:  16 [(0, 5677), (1, 7108), (2, 6958), (3, 6838), (4, 6682), (5, 6687), (6, 6589), (7, 6664), (8, 6615), (9, 6480), (10, 14796), (11, 14450), (12, 12832), (13, 13198), (14, 27159), (15, 16670)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11141 samples for 100 iterations, 0.9499888151968223, 1 epochs, take 76 sec.
Epoch time: 1m 44s
------------------------------
Epoch 81/99 (max_len=inf, data=11170)
Train acc: 88.07 (abduce 99.67)
Hit samples:  11133  Ave length:  14.84
Symbols:  16 [(0, 5690), (1, 7156), (2, 6954), (3, 6796), (4, 6689), (5, 6702), (6, 6568), (7, 6645), (8, 6601), (9, 6530), (10, 14793), (11, 14422), (12, 12809), (13, 13214), (14, 26608), (15, 17060)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11133 samples for 100 iterations, 0.9517601989869097, 1 epochs, take 77 sec.
Epoch time: 1m 43s
------------------------------
Epoch 82/99 (max_len=inf, data=11170)
Train acc: 89.27 (abduce 99.69)
Hit samples:  11135  Ave length:  14.85
Symbols:  16 [(0, 5695), (1, 7148), (2, 6950), (3, 6820), (4, 6704), (5, 6687), (6, 6569), (7, 6643), (8, 6621), (9, 6497), (10, 14831), (11, 14423), (12, 12794), (13, 13238), (14, 26624), (15, 17063)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 378), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11135 samples for 100 iterations, 0.9521556860870986, 1 epochs, take 77 sec.
Epoch time: 1m 42s
------------------------------
Epoch 83/99 (max_len=inf, data=11170)
Train acc: 90.65 (abduce 99.77)
Hit samples:  11144  Ave length:  14.85
Symbols:  16 [(0, 5676), (1, 7138), (2, 6952), (3, 6848), (4, 6717), (5, 6704), (6, 6565), (7, 6654), (8, 6637), (9, 6481), (10, 14821), (11, 14437), (12, 12811), (13, 13300), (14, 26714), (15, 16997)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11144 samples for 100 iterations, 0.9523789376979426, 1 epochs, take 77 sec.
Epoch time: 1m 41s
------------------------------
Epoch 84/99 (max_len=inf, data=11170)
Train acc: 92.17 (abduce 99.78)
Hit samples:  11145  Ave length:  14.85
Symbols:  16 [(0, 5653), (1, 7087), (2, 6943), (3, 6872), (4, 6695), (5, 6716), (6, 6555), (7, 6649), (8, 6625), (9, 6495), (10, 14846), (11, 14440), (12, 12822), (13, 13329), (14, 26646), (15, 17134)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11145 samples for 100 iterations, 0.9530412610946969, 1 epochs, take 78 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.94      0.98      0.96      5142
           2       1.00      0.99      0.99      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      1.00      1.00      5383
           6       0.99      1.00      1.00      5427
           7       1.00      1.00      1.00      5462
           8       0.99      1.00      1.00      5453
           9       0.99      0.99      0.99      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      1.00     10734
           *       1.00      1.00      1.00     13491
           /       0.96      1.00      0.98      9876
           (       0.79      0.96      0.87     21081
           )       0.97      0.73      0.83     21081

    accuracy                           0.95    141662
   macro avg       0.97      0.98      0.97    141662
weighted avg       0.96      0.95      0.95    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  355    0    0    0    0    0    0    0    0    0    0    0    0     1     3
2    0    0  372    0    0    0    0    0    1    0    0    0    0    0     0     0
3    0    0    0  365    0    0    0    0    1    1    0    0    0    0     0     0
4    0    0    0    0  366    0    0    0    0    1    0    1    0    0     0     0
5    0    0    0    0    0  379    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    2    2    0    0    0  382    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  931    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    4   14    0    0    0    0    2    0    0    0    0    2    0    4  1425    35
)    0    6    0    0    0    0    0    0    0    0    0    0    0   27   367  1087
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 99.22
7 ( 4%) 98.25
9 ( 4%) 93.97
11 ( 3%) 96.59
13 ( 4%) 92.13
15 ( 4%) 92.08
17 ( 4%) 95.63
19 ( 4%) 90.20
21 ( 4%) 91.41
23 ( 4%) 91.71
25 ( 4%) 87.50
27 ( 4%) 85.22
29 ( 3%) 90.05
31 ( 3%) 86.90
33 ( 2%) 90.00
35 ( 2%) 86.30
37 ( 2%) 81.20
39 ( 3%) 78.95
41 ( 3%) 86.58
43 ( 2%) 86.23
45 ( 2%) 80.36
47 ( 2%) 85.61
49 ( 2%) 76.76
51 ( 2%) 83.33
53 ( 2%) 85.82
55 ( 2%) 77.31
57 ( 2%) 79.02
59 ( 2%) 72.90
61 ( 1%) 81.25
63 ( 0%) 65.71
65 ( 0%) 88.89
67 ( 0%) 100.00
result accuracy by symbol:
( (91%) 87.41
) (91%) 87.41
* (87%) 87.40
+ (84%) 86.75
- (77%) 86.59
/ (76%) 86.84
0 (52%) 86.25
1 (60%) 85.64
2 (61%) 86.68
3 (62%) 86.95
4 (61%) 86.40
5 (62%) 86.65
6 (62%) 86.02
7 (63%) 86.92
8 (64%) 86.50
9 (63%) 86.59
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 90.48
1 (10%) 88.76
2 ( 4%) 89.39
3 ( 2%) 87.41
4 ( 2%) 90.23
5 ( 2%) 93.00
6 ( 2%) 88.70
7 ( 2%) 90.27
8 ( 2%) 89.74
9 ( 1%) 89.53
result accuracy by generalization:
1 (22.45%) 92.82
2 (22.96%) 92.00
3 (22.53%) 90.76
4 (15.82%) 82.84
5 (16.24%) 79.40
error cases:
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
4+(1+8) 4+11+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 None
7*9*3 7*4*3 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 189 84
5*(9*7) 5*)9*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
1*(6+2)-6 )*(6+2(-6 [1, 7, 4, 4, 1, 4, 4, -1, 7] [1, 7, 4, 4, 1, 4, 4, -1, 7] 2 None
6/(6/5-1) 6/16/5-1) [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 6 None
2*7-(2+5) 8*7-(2+5) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 7 49
7/(4+5-1) 7/(4+5-() [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 1 None
5+(6-2)*4 5+(6-2(*9 [1, -1, 4, 4, 7, 4, 4, 1, 7] [1, -1, 4, 4, 7, 4, 4, 1, 7] 21 41
4*((8+8)/6) -*((8+8)/6) [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] 12 None
val (Perception Acc=95.10, Head Acc=100.00, Result Acc=88.41)
Epoch time: 1m 58s
------------------------------
Epoch 85/99 (max_len=inf, data=11170)
Train acc: 94.14 (abduce 99.94)
Hit samples:  11163  Ave length:  14.86
Symbols:  16 [(0, 5674), (1, 7092), (2, 6948), (3, 6886), (4, 6717), (5, 6721), (6, 6567), (7, 6673), (8, 6636), (9, 6501), (10, 14887), (11, 14491), (12, 12855), (13, 13431), (14, 26696), (15, 17118)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11163 samples for 100 iterations, 0.9530721609712285, 1 epochs, take 77 sec.
Epoch time: 1m 39s
------------------------------
Epoch 86/99 (max_len=inf, data=11170)
Train acc: 94.41 (abduce 99.94)
Hit samples:  11163  Ave length:  14.86
Symbols:  16 [(0, 5677), (1, 7102), (2, 6933), (3, 6886), (4, 6726), (5, 6737), (6, 6576), (7, 6677), (8, 6643), (9, 6499), (10, 14894), (11, 14481), (12, 12850), (13, 13523), (14, 26549), (15, 17136)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11163 samples for 100 iterations, 0.9529203262422463, 1 epochs, take 78 sec.
Epoch time: 1m 40s
------------------------------
Epoch 87/99 (max_len=inf, data=11170)
Train acc: 92.33 (abduce 99.89)
Hit samples:  11158  Ave length:  14.86
Symbols:  16 [(0, 5668), (1, 7154), (2, 6931), (3, 6869), (4, 6730), (5, 6730), (6, 6563), (7, 6670), (8, 6640), (9, 6491), (10, 14894), (11, 14476), (12, 12842), (13, 13526), (14, 26213), (15, 17401)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 91), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11158 samples for 100 iterations, 0.9530452719574422, 1 epochs, take 78 sec.
Epoch time: 1m 40s
------------------------------
Epoch 88/99 (max_len=inf, data=11170)
Train acc: 94.44 (abduce 99.95)
Hit samples:  11164  Ave length:  14.86
Symbols:  16 [(0, 5674), (1, 7107), (2, 6931), (3, 6882), (4, 6737), (5, 6732), (6, 6570), (7, 6679), (8, 6636), (9, 6496), (10, 14914), (11, 14472), (12, 12868), (13, 13556), (14, 26210), (15, 17460)]
Head:  [((-1,), 1000), ((1, -1, 1), 1169), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11164 samples for 100 iterations, 0.9530929823292592, 1 epochs, take 77 sec.
Epoch time: 1m 39s
------------------------------
Epoch 89/99 (max_len=inf, data=11170)
Train acc: 94.44 (abduce 99.89)
Hit samples:  11158  Ave length:  14.86
Symbols:  16 [(0, 5664), (1, 7115), (2, 6931), (3, 6873), (4, 6717), (5, 6736), (6, 6562), (7, 6671), (8, 6629), (9, 6492), (10, 14890), (11, 14450), (12, 12852), (13, 13718), (14, 25616), (15, 17838)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11158 samples for 100 iterations, 0.9527130566984808, 1 epochs, take 78 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.94      0.98      0.96      5142
           2       1.00      0.99      1.00      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.99      0.99      5279
           5       0.99      1.00      1.00      5383
           6       1.00      1.00      1.00      5427
           7       1.00      1.00      1.00      5462
           8       0.99      1.00      1.00      5453
           9       1.00      0.99      0.99      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      1.00     10734
           *       1.00      1.00      1.00     13491
           /       0.93      1.00      0.97      9876
           (       0.80      0.95      0.87     21081
           )       0.96      0.74      0.84     21081

    accuracy                           0.95    141662
   macro avg       0.97      0.98      0.97    141662
weighted avg       0.96      0.95      0.95    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  282    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  354    0    0    0    0    0    0    0    0    0    0    0    0     1     5
2    0    0  373    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  366    0    0    0    0    2    0    0    0    0    0     0     0
4    0    0    0    0  368    0    0    0    0    0    0    1    0    0     0     0
5    0    0    0    0    0  379    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    2    2    0    0    0  382    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  931    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    1  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    4   16    0    0    0    0    0    0    0    0    0    2    0   14  1413    37
)    0    6    0    0    0    0    0    0    0    0    0    0    0   35   342  1104
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 98.25
9 ( 4%) 93.97
11 ( 3%) 95.45
13 ( 4%) 91.67
15 ( 4%) 92.08
17 ( 4%) 95.63
19 ( 4%) 90.69
21 ( 4%) 92.93
23 ( 4%) 93.17
25 ( 4%) 87.00
27 ( 4%) 87.68
29 ( 3%) 90.58
31 ( 3%) 82.14
33 ( 2%) 87.14
35 ( 2%) 83.56
37 ( 2%) 85.47
39 ( 3%) 84.21
41 ( 3%) 85.23
43 ( 2%) 86.23
45 ( 2%) 76.79
47 ( 2%) 87.88
49 ( 2%) 73.24
51 ( 2%) 83.33
53 ( 2%) 85.07
55 ( 2%) 80.67
57 ( 2%) 78.32
59 ( 2%) 76.64
61 ( 1%) 78.12
63 ( 0%) 77.14
65 ( 0%) 100.00
67 ( 0%) 100.00
result accuracy by symbol:
( (91%) 87.52
) (91%) 87.52
* (87%) 87.49
+ (84%) 87.04
- (77%) 86.88
/ (76%) 87.03
0 (52%) 85.82
1 (60%) 85.81
2 (61%) 86.61
3 (62%) 87.21
4 (61%) 86.47
5 (62%) 86.69
6 (62%) 86.54
7 (63%) 87.08
8 (64%) 86.85
9 (63%) 86.75
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 91.05
1 (10%) 89.14
2 ( 4%) 87.37
3 ( 2%) 86.67
4 ( 2%) 90.98
5 ( 2%) 90.00
6 ( 2%) 89.57
7 ( 2%) 86.73
8 ( 2%) 92.31
9 ( 1%) 90.70
result accuracy by generalization:
1 (22.45%) 93.00
2 (22.96%) 92.53
3 (22.53%) 89.76
4 (15.82%) 81.94
5 (16.24%) 81.41
error cases:
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
3*(9/1) 3*19/1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 27 None
5/6*3 5/6*8 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 3 8
7*9*3 7*4*3 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 189 84
5*(9*7) 5*)9*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
1*(6+2)-6 )*(6+2(-6 [1, 7, 4, 4, 1, 4, 4, -1, 7] [1, 7, 4, 4, 1, 4, 4, -1, 7] 2 None
(6+8)/3-4 /6+81/3-4 [2, 2, 5, 2, 2, 7, 5, -1, 7] [2, 2, 5, 2, 2, 7, 5, -1, 7] 1 None
6/(6/5-1) 6/16/5-1) [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 6 None
2*7-(2+5) 8*7-(2+5) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 7 49
8-1*(4/4) 8-1*13/4( [1, -1, 3, 1, 6, 6, 3, 6, 6] [1, -1, 3, 1, 6, 6, 3, 6, 6] 7 None
val (Perception Acc=95.17, Head Acc=100.00, Result Acc=88.53)
Epoch time: 1m 58s
------------------------------
Epoch 90/99 (max_len=inf, data=11170)
Train acc: 95.12 (abduce 99.93)
Hit samples:  11162  Ave length:  14.86
Symbols:  16 [(0, 5673), (1, 7115), (2, 6930), (3, 6890), (4, 6715), (5, 6743), (6, 6562), (7, 6675), (8, 6637), (9, 6492), (10, 14893), (11, 14472), (12, 12864), (13, 13909), (14, 25203), (15, 18101)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11162 samples for 100 iterations, 0.9525302337919144, 1 epochs, take 77 sec.
Epoch time: 1m 40s
------------------------------
Epoch 91/99 (max_len=inf, data=11170)
Train acc: 95.38 (abduce 99.96)
Hit samples:  11165  Ave length:  14.86
Symbols:  16 [(0, 5662), (1, 7088), (2, 6925), (3, 6897), (4, 6739), (5, 6745), (6, 6576), (7, 6672), (8, 6629), (9, 6493), (10, 14892), (11, 14490), (12, 12870), (13, 14163), (14, 24849), (15, 18251)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11165 samples for 100 iterations, 0.9509464207157966, 1 epochs, take 78 sec.
Epoch time: 1m 40s
------------------------------
Epoch 92/99 (max_len=inf, data=11170)
Train acc: 96.04 (abduce 99.96)
Hit samples:  11165  Ave length:  14.86
Symbols:  16 [(0, 5671), (1, 7098), (2, 6928), (3, 6905), (4, 6733), (5, 6746), (6, 6579), (7, 6678), (8, 6599), (9, 6490), (10, 14898), (11, 14497), (12, 12865), (13, 14434), (14, 24618), (15, 18190)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11165 samples for 100 iterations, 0.9495627647969915, 1 epochs, take 78 sec.
Epoch time: 1m 40s
------------------------------
Epoch 93/99 (max_len=inf, data=11170)
Train acc: 95.90 (abduce 99.94)
Hit samples:  11163  Ave length:  14.86
Symbols:  16 [(0, 5676), (1, 7089), (2, 6926), (3, 6901), (4, 6730), (5, 6750), (6, 6578), (7, 6679), (8, 6598), (9, 6480), (10, 14890), (11, 14481), (12, 12860), (13, 15010), (14, 24162), (15, 18077)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11163 samples for 100 iterations, 0.9480730858958206, 1 epochs, take 78 sec.
Epoch time: 1m 40s
------------------------------
Epoch 94/99 (max_len=inf, data=11170)
Train acc: 95.09 (abduce 99.91)
Hit samples:  11160  Ave length:  14.86
Symbols:  16 [(0, 5671), (1, 7097), (2, 6926), (3, 6899), (4, 6734), (5, 6745), (6, 6572), (7, 6672), (8, 6602), (9, 6490), (10, 14879), (11, 14478), (12, 12859), (13, 15450), (14, 23634), (15, 18100)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 364), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11160 samples for 100 iterations, 0.9443332046704622, 1 epochs, take 77 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.92      0.98      0.95      5142
           2       0.99      0.99      0.99      5321
           3       1.00      0.99      1.00      5241
           4       0.99      0.99      0.99      5279
           5       0.99      1.00      1.00      5383
           6       0.99      1.00      1.00      5427
           7       0.99      1.00      0.99      5462
           8       1.00      1.00      1.00      5453
           9       1.00      0.99      0.99      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      1.00     10734
           *       1.00      1.00      1.00     13491
           /       0.85      1.00      0.92      9876
           (       0.83      0.92      0.87     21081
           )       0.94      0.74      0.83     21081

    accuracy                           0.95    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.95      0.95    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  282    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  354    0    0    0    0    0    0    0    0    0    0    0    0     1     5
2    0    0  372    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  367    0    0    0    0    0    0    0    0    0    0     0     0
4    0    0    0    0  367    0    0    1    0    0    0    1    0    0     0     0
5    0    0    0    0    0  379    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    2    2    0    0    0  382    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  931    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    6   24    0    0    0    0    2    0    0    0    0    2    0   20  1367    64
)    0    4    2    0    0    0    0    2    0    0    0    0    0  101   278  1100
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 99.22
7 ( 4%) 98.25
9 ( 4%) 93.97
11 ( 3%) 93.18
13 ( 4%) 89.81
15 ( 4%) 90.59
17 ( 4%) 92.72
19 ( 4%) 89.71
21 ( 4%) 89.90
23 ( 4%) 89.76
25 ( 4%) 84.00
27 ( 4%) 82.27
29 ( 3%) 87.43
31 ( 3%) 79.17
33 ( 2%) 82.86
35 ( 2%) 80.14
37 ( 2%) 82.05
39 ( 3%) 79.61
41 ( 3%) 81.88
43 ( 2%) 80.43
45 ( 2%) 68.75
47 ( 2%) 81.06
49 ( 2%) 72.54
51 ( 2%) 81.82
53 ( 2%) 76.12
55 ( 2%) 69.75
57 ( 2%) 74.83
59 ( 2%) 72.90
61 ( 1%) 73.44
63 ( 0%) 62.86
65 ( 0%) 55.56
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 83.88
) (91%) 83.88
* (87%) 83.84
+ (84%) 83.24
- (77%) 82.91
/ (76%) 83.25
0 (52%) 81.99
1 (60%) 81.96
2 (61%) 82.72
3 (62%) 83.15
4 (61%) 82.62
5 (62%) 82.98
6 (62%) 82.42
7 (63%) 83.14
8 (64%) 82.87
9 (63%) 82.38
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 87.33
1 (10%) 84.46
2 ( 4%) 87.37
3 ( 2%) 84.44
4 ( 2%) 85.71
5 ( 2%) 92.00
6 ( 2%) 86.09
7 ( 2%) 86.73
8 ( 2%) 86.32
9 ( 1%) 84.88
result accuracy by generalization:
1 (22.45%) 92.18
2 (22.96%) 89.96
3 (22.53%) 86.50
4 (15.82%) 76.52
5 (16.24%) 75.63
error cases:
9/(9-2) 9/)5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
(9+0)*3 (9+02*3 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 27 None
7*9*3 7*4*3 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 189 84
5*(9*7) 5*)9*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
(3-3)*(2-2) 13-3/*(2-2) [2, 2, 5, 2, 2, -1, 8, 8, 5, 8, 8] [2, 2, 5, 2, 2, -1, 8, 8, 5, 8, 8] 0 None
6/(6/5-1) 6/16/5-1) [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 6 None
2*7-(2+5) 8*7-(2+5) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 7 49
8-1*(4/4) 8-1*13/4( [1, -1, 3, 1, 6, 6, 3, 6, 6] [1, -1, 3, 1, 6, 6, 3, 6, 6] 7 None
7/(4+5-1) 7/(4+5-() [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 1 None
4*((8+8)/6) -*((8+8)/6) [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] 12 None
val (Perception Acc=94.66, Head Acc=100.00, Result Acc=85.22)
Epoch time: 1m 57s
------------------------------
Epoch 95/99 (max_len=inf, data=11170)
Train acc: 94.50 (abduce 99.93)
Hit samples:  11162  Ave length:  14.86
Symbols:  16 [(0, 5685), (1, 7120), (2, 6926), (3, 6903), (4, 6737), (5, 6742), (6, 6578), (7, 6666), (8, 6600), (9, 6494), (10, 14881), (11, 14488), (12, 12868), (13, 15716), (14, 22758), (15, 18692)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11162 samples for 100 iterations, 0.9424795301892025, 1 epochs, take 78 sec.
Epoch time: 1m 41s
------------------------------
Epoch 96/99 (max_len=inf, data=11170)
Train acc: 94.35 (abduce 99.93)
Hit samples:  11162  Ave length:  14.86
Symbols:  16 [(0, 5693), (1, 7092), (2, 6934), (3, 6903), (4, 6731), (5, 6755), (6, 6586), (7, 6665), (8, 6601), (9, 6496), (10, 14883), (11, 14497), (12, 12869), (13, 15943), (14, 22226), (15, 19000)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11162 samples for 100 iterations, 0.9407381506444651, 1 epochs, take 77 sec.
Epoch time: 1m 40s
------------------------------
Epoch 97/99 (max_len=inf, data=11170)
Train acc: 94.63 (abduce 99.95)
Hit samples:  11164  Ave length:  14.86
Symbols:  16 [(0, 5710), (1, 7095), (2, 6936), (3, 6900), (4, 6722), (5, 6760), (6, 6588), (7, 6671), (8, 6599), (9, 6492), (10, 14893), (11, 14521), (12, 12867), (13, 16399), (14, 21616), (15, 19135)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11164 samples for 100 iterations, 0.9379942617417302, 1 epochs, take 77 sec.
Epoch time: 1m 40s
------------------------------
Epoch 98/99 (max_len=inf, data=11170)
Train acc: 93.96 (abduce 99.89)
Hit samples:  11158  Ave length:  14.86
Symbols:  16 [(0, 5706), (1, 7126), (2, 6941), (3, 6887), (4, 6708), (5, 6755), (6, 6592), (7, 6672), (8, 6595), (9, 6493), (10, 14876), (11, 14532), (12, 12869), (13, 16772), (14, 21810), (15, 18442)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11158 samples for 100 iterations, 0.9375904835440595, 1 epochs, take 75 sec.
Epoch time: 1m 37s
------------------------------
Epoch 99/99 (max_len=inf, data=11170)
Train acc: 93.74 (abduce 99.96)
Hit samples:  11165  Ave length:  14.86
Symbols:  16 [(0, 5716), (1, 7122), (2, 6945), (3, 6894), (4, 6721), (5, 6756), (6, 6594), (7, 6683), (8, 6607), (9, 6493), (10, 14885), (11, 14545), (12, 12879), (13, 17348), (14, 21487), (15, 18242)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11165 samples for 100 iterations, 0.9355882760657437, 1 epochs, take 72 sec.
              precision    recall  f1-score   support

           0       0.97      1.00      0.99      4016
           1       0.93      0.98      0.95      5142
           2       1.00      1.00      1.00      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      0.99      5427
           7       0.99      1.00      0.99      5462
           8       0.99      1.00      1.00      5453
           9       1.00      0.99      0.99      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.74      1.00      0.85      9876
           (       0.87      0.91      0.89     21081
           )       0.95      0.73      0.83     21081

    accuracy                           0.94    141662
   macro avg       0.96      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  282    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  354    0    0    0    0    0    0    0    0    0    0    0    0     1     4
2    0    0  373    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  367    0    0    0    0    0    0    0    0    0    0     0     0
4    0    0    0    0  365    0    2    0    0    0    0    1    0    0     0     0
5    0    0    0    0    0  377    0    2    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    2    2    0    0    0  382    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  930    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    4   22    0    0    0    0    2    0    0    0    0    6    0   52  1350    49
)    2    4    0    0    0    0    0    0    0    0    0    0    0  188   205  1087
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 97.82
9 ( 4%) 93.97
11 ( 3%) 93.75
13 ( 4%) 90.28
15 ( 4%) 90.59
17 ( 4%) 94.17
19 ( 4%) 88.24
21 ( 4%) 90.40
23 ( 4%) 89.76
25 ( 4%) 84.00
27 ( 4%) 85.22
29 ( 3%) 90.05
31 ( 3%) 81.55
33 ( 2%) 85.00
35 ( 2%) 83.56
37 ( 2%) 85.47
39 ( 3%) 81.58
41 ( 3%) 81.21
43 ( 2%) 80.43
45 ( 2%) 67.86
47 ( 2%) 81.82
49 ( 2%) 74.65
51 ( 2%) 81.06
53 ( 2%) 84.33
55 ( 2%) 71.43
57 ( 2%) 74.13
59 ( 2%) 73.83
61 ( 1%) 75.00
63 ( 0%) 62.86
65 ( 0%) 88.89
67 ( 0%) 100.00
result accuracy by symbol:
( (91%) 85.04
) (91%) 85.04
* (87%) 84.98
+ (84%) 84.56
- (77%) 84.25
/ (76%) 84.42
0 (52%) 83.16
1 (60%) 83.37
2 (61%) 84.12
3 (62%) 84.46
4 (61%) 83.78
5 (62%) 84.24
6 (62%) 84.25
7 (63%) 84.66
8 (64%) 84.14
9 (63%) 83.72
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 88.48
1 (10%) 86.14
2 ( 4%) 90.91
3 ( 2%) 85.93
4 ( 2%) 87.97
5 ( 2%) 90.00
6 ( 2%) 87.83
7 ( 2%) 92.04
8 ( 2%) 86.32
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 93.09
2 (22.96%) 90.31
3 (22.53%) 87.77
4 (15.82%) 78.71
5 (16.24%) 76.26
error cases:
1*8+5 1*8+7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 13 15
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
(9+0)*3 19+0)*3 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 27 None
(8+9)/4 )8+9)/6 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 5 3
7*9*3 7*4*3 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 189 84
5*(9*7) 5*)9*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
6/(6/5-1) 6/16/5-1) [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 6 None
2*7-(2+5) 8*7-(2+5) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 7 49
8-1*(4/4) 8-1*13/4( [1, -1, 3, 1, 6, 6, 3, 6, 6] [1, -1, 3, 1, 6, 6, 3, 6, 6] 7 None
5+(6-2)*4 5+(6-2/*8 [1, -1, 4, 4, 7, 4, 4, 1, 7] [1, -1, 4, 4, 7, 4, 4, 1, 7] 21 37
val (Perception Acc=94.33, Head Acc=100.00, Result Acc=86.24)
Epoch time: 1m 50s
------------------------------
Evaluate on test set...
              precision    recall  f1-score   support

           0       0.99      1.00      0.99     39465
           1       0.93      0.98      0.96     51797
           2       0.99      0.99      0.99     52546
           3       0.99      0.99      0.99     52953
           4       0.99      0.99      0.99     53234
           5       0.99      0.99      0.99     53430
           6       0.99      0.99      0.99     53860
           7       0.99      0.99      0.99     54695
           8       1.00      1.00      1.00     54671
           9       1.00      1.00      1.00     54909
           +       1.00      1.00      1.00    131914
           -       0.99      1.00      1.00    108556
           *       1.00      1.00      1.00    132837
           /       0.78      1.00      0.88     99343
           (       0.86      0.91      0.88    210691
           )       0.94      0.74      0.83    210691

    accuracy                           0.94   1415592
   macro avg       0.96      0.97      0.97   1415592
weighted avg       0.95      0.94      0.94   1415592

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  278    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  358    1    0    0    0    0    0    0    0    0    0    0    0     1     2
2    0    0  366    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  369    0    2    0    0    0    0    0    0    0    0     0     0
4    0    0    0    0  373    0    0    0    0    0    0    0    0    0     0     0
5    0    0    0    0    0  375    1    0    0    0    0    0    0    0     0     0
6    1    0    0    0    0    1  377    0    0    0    0    0    0    0     0     0
7    0    1    0    0    0    0    0  383    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  385    0    0    0    0    0     0     0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  930    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  766    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  938    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  701     0     0
(    1   18    0    0    0    0    0    0    0    0    0    4    0   40  1356    66
)    0    3    0    0    0    0    0    0    0    0    0    0    0  157   228  1098
result accuracy by length:
1 ( 2%) 99.50
3 ( 2%) 98.63
5 ( 2%) 98.00
7 ( 4%) 96.59
9 ( 4%) 96.13
11 ( 4%) 95.31
13 ( 4%) 94.36
15 ( 4%) 93.34
17 ( 4%) 93.68
19 ( 4%) 91.70
21 ( 4%) 92.76
23 ( 4%) 91.65
25 ( 4%) 88.48
27 ( 4%) 89.79
29 ( 3%) 87.98
31 ( 3%) 86.97
33 ( 2%) 87.30
35 ( 2%) 86.47
37 ( 2%) 85.24
39 ( 2%) 85.13
41 ( 2%) 83.59
43 ( 2%) 84.76
45 ( 2%) 83.01
47 ( 2%) 84.53
49 ( 2%) 80.90
51 ( 2%) 81.55
53 ( 2%) 81.15
55 ( 2%) 79.67
57 ( 2%) 78.16
59 ( 2%) 79.39
61 ( 1%) 81.42
63 ( 0%) 79.85
65 ( 0%) 75.21
67 ( 0%) 68.97
69 ( 0%) 90.91
71 ( 0%) 50.00
result accuracy by symbol:
( (91%) 88.01
) (91%) 88.01
* (87%) 87.86
+ (84%) 87.70
- (78%) 87.54
/ (77%) 87.40
0 (51%) 86.91
1 (60%) 86.54
2 (61%) 86.83
3 (62%) 86.92
4 (62%) 87.17
5 (62%) 87.21
6 (62%) 87.29
7 (63%) 87.23
8 (63%) 87.18
9 (63%) 87.24
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 99.00
2 ( 0%) 99.00
3 ( 0%) 98.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 99.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 90.83
1 (11%) 90.93
2 ( 3%) 89.09
3 ( 3%) 90.01
4 ( 2%) 90.05
5 ( 2%) 90.71
6 ( 2%) 91.46
7 ( 2%) 90.39
8 ( 2%) 90.06
9 ( 2%) 91.23
result accuracy by generalization:
1 (22.84%) 94.30
2 (23.00%) 92.19
3 (22.36%) 90.06
4 (15.84%) 82.99
5 (15.95%) 80.88
error cases:
7 1 [-1] [-1] 7 1
1 4 [-1] [-1] 1 4
3 5 [-1] [-1] 3 5
3 5 [-1] [-1] 3 5
2 7 [-1] [-1] 2 7
0/6 0/0 [1, -1, 1] [1, -1, 1] 0 None
6/4 0/4 [1, -1, 1] [1, -1, 1] 2 0
7/2 7/4 [1, -1, 1] [1, -1, 1] 4 2
8*2 8*6 [1, -1, 1] [1, -1, 1] 16 48
4+3 4+7 [1, -1, 1] [1, -1, 1] 7 11
test (Perception Acc=94.47, Head Acc=100.00, Result Acc=88.93)
