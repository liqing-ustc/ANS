train: 11170 val: 4900 test: 48910
Add 4277 samples for class 0, acc 0.88.
Add 3211 samples for class 1, acc 0.84.
Add 2946 samples for class 2, acc 0.92.
Add 6217 samples for class 3, acc 0.95.
Add 4438 samples for class 4, acc 0.58.
Add 4467 samples for class 5, acc 0.96.
Add 6085 samples for class 6, acc 0.99.
Add 3530 samples for class 7, acc 0.80.
Add 5701 samples for class 8, acc 0.95.
Add 3792 samples for class 9, acc 0.98.
Add 4241 samples for class 10, acc 0.86.
Add 17097 samples for class 11, acc 0.84.
Add 12715 samples for class 12, acc 0.99.
Add 12436 samples for class 13, acc 0.92.
Add 18720 samples for class 14, acc 0.86.
Add 3156 samples for class 15, acc 0.85.
Namespace(curriculum=True, epochs=100, epochs_eval=5, excludes='!', output_dir='./outputs/exp_syntax_semantics_curriculum/seed_0/', perception=False, perception_pretrain='data/perception-pretrain/model.pth.tar_78.2_match', resume=None, seed=0, semantics=True, syntax=True)
ClusteringModel(
  (backbone): ResNet(
    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shortcut): Sequential()
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (cluster_head): ModuleList(
    (0): Linear(in_features=512, out_features=16, bias=True)
  )
)
use ground-truth syntax.
use ground-truth semantics.
Curriculum: [(0, 1), (1, 3), (20, 7), (40, 11), (60, 15), (80, inf)]
              precision    recall  f1-score   support

           0       0.86      0.84      0.85      4016
           1       0.69      0.47      0.56      5142
           2       0.72      0.59      0.65      5321
           3       0.87      0.95      0.91      5241
           4       0.50      0.55      0.52      5279
           5       0.93      0.80      0.86      5383
           6       0.93      0.97      0.95      5427
           7       0.53      0.63      0.58      5462
           8       0.91      0.89      0.90      5453
           9       0.94      0.64      0.76      5476
           +       0.84      0.57      0.68     13199
           -       0.70      1.00      0.83     10734
           *       0.98      1.00      0.99     13491
           /       0.81      0.86      0.84      9876
           (       0.71      0.97      0.82     21081
           )       0.84      0.61      0.70     21081

    accuracy                           0.79    141662
   macro avg       0.80      0.77      0.77    141662
weighted avg       0.80      0.79      0.78    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  237    0    0    0    0    4    6    0   32    0    0    0    0    0     0    0
1    0  169    0    0    5    0    0    0    0    0    0    0    0    0    43  142
2    7   14  222    6    0    4    1    1    0    8    0    0    2  103     0    0
3    0    0    6  350    4    4    0    0    0    1    0    0    0    0     0    0
4    0    1    0    0  204    0    0   65    0    0   85   12    0    0     0    0
5   12    2   27   10    0  302    2    0    0    2    0    0    0   19     0    0
6    0    0    0    0    0    7  370    2    0    2    0    0    0    0     0    0
7    0   39    7    2    0    0    0  244    0    0   16   42   13   10     0    7
8    0    0    5   30    0    0    0    2  344    0    0    0    0    0     2    0
9    0   14    0    2  116    2    0    0    0  248    2    0    0    0     0    0
+    0    2    0    0    0    0    0  149    0    0  530  243    3    1     0    0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/   16    0    0    0   64    0    0    0    0    0    0   16    0  599     0    0
(    2    0    8    0    0    0   12    0    0    0    0    2    0    0  1444   18
)    0    0   29    0   12    0    4    0    0    0    0    0    0    0   541  900
result accuracy by length:
1 ( 2%) 73.00
3 ( 2%) 47.00
5 ( 2%) 37.98
7 ( 4%) 35.81
9 ( 4%) 23.12
11 ( 3%) 25.57
13 ( 4%) 14.35
15 ( 4%) 13.86
17 ( 4%) 13.11
19 ( 4%)  6.86
21 ( 4%)  9.60
23 ( 4%)  9.76
25 ( 4%)  5.50
27 ( 4%)  6.90
29 ( 3%)  3.66
31 ( 3%)  5.95
33 ( 2%)  5.00
35 ( 2%)  2.74
37 ( 2%)  4.27
39 ( 3%)  0.66
41 ( 3%)  2.68
43 ( 2%)  2.90
45 ( 2%)  0.89
47 ( 2%)  1.52
49 ( 2%)  1.41
51 ( 2%)  0.76
53 ( 2%)  4.48
55 ( 2%)  1.68
57 ( 2%)  0.00
59 ( 2%)  2.80
61 ( 1%)  1.56
63 ( 0%)  0.00
65 ( 0%)  0.00
67 ( 0%)  0.00
result accuracy by symbol:
( (91%)  8.48
) (91%)  8.48
* (87%)  8.81
+ (84%)  6.16
- (77%)  8.32
/ (76%)  7.38
0 (52%)  7.58
1 (60%)  5.35
2 (61%)  6.11
3 (62%)  8.39
4 (61%)  6.07
5 (62%)  8.01
6 (62%)  7.87
7 (63%)  6.78
8 (64%)  7.96
9 (63%)  6.96
result accuracy by digit:
0 ( 0%) 80.00
1 ( 0%) 50.00
2 ( 0%) 50.00
3 ( 0%) 100.00
4 ( 0%) 60.00
5 ( 0%) 60.00
6 ( 0%) 100.00
7 ( 0%) 90.00
8 ( 0%) 100.00
9 ( 0%) 40.00
result accuracy by result:
0 (21%) 19.24
1 (10%) 11.05
2 ( 4%)  9.60
3 ( 2%) 20.00
4 ( 2%) 15.04
5 ( 2%) 16.00
6 ( 2%) 21.74
7 ( 2%) 15.93
8 ( 2%) 15.38
9 ( 1%) 13.95
result accuracy by generalization:
1 (22.45%) 23.45
2 (22.96%) 16.00
3 (22.53%)  9.15
4 (15.82%)  2.32
5 (16.24%)  1.13
error cases:
7 + [-1] [-1] 7 None
1 ) [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
1 ( [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
0 8 [-1] [-1] 0 8
0 8 [-1] [-1] 0 8
4 + [-1] [-1] 4 None
4 7 [-1] [-1] 4 7
val (Perception Acc=78.81, Head Acc=100.00, Result Acc=11.55)
------------------------------
Epoch 0/99 (max_len=1, data=1000)
Train acc: 71.41 (abduce 100.00)
Hit samples:  1000  Ave length:  1.0
Symbols:  10 [(0, 100), (1, 100), (2, 100), (3, 100), (4, 100), (5, 100), (6, 100), (7, 100), (8, 100), (9, 100)]
Head:  [((-1,), 1000)]
Learn perception with 1000 samples for 100 iterations, 1.0, 0.92375, 3200, 16 epochs, take 28 sec.
Epoch time: 0m 29s
------------------------------
Epoch 1/99 (max_len=3, data=2170)
Train acc: 83.91 (abduce 98.62)
Hit samples:  2140  Ave length:  2.07
Symbols:  15 [(0, 308), (1, 329), (2, 322), (3, 335), (4, 329), (5, 333), (6, 333), (7, 337), (8, 322), (9, 328), (10, 259), (11, 318), (12, 304), (13, 262), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1140)]
Learn perception with 2140 samples for 100 iterations, 0.9773755656108597, 0.9678356505499066, 4819, 11 epochs, take 25 sec.
Epoch time: 0m 27s
------------------------------
Epoch 2/99 (max_len=3, data=2170)
Train acc: 97.27 (abduce 99.91)
Hit samples:  2168  Ave length:  2.08
Symbols:  15 [(0, 309), (1, 335), (2, 331), (3, 337), (4, 337), (5, 339), (6, 337), (7, 341), (8, 328), (9, 339), (10, 279), (11, 318), (12, 303), (13, 270), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1168)]
Learn perception with 2168 samples for 100 iterations, 0.9782415630550622, 0.9671629614521722, 4903, 11 epochs, take 26 sec.
Epoch time: 0m 28s
------------------------------
Epoch 3/99 (max_len=3, data=2170)
Train acc: 99.08 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 334), (2, 332), (3, 340), (4, 336), (5, 338), (6, 338), (7, 342), (8, 329), (9, 340), (10, 281), (11, 315), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9787139689578714, 0.9686290486860868, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 27s
------------------------------
Epoch 4/99 (max_len=3, data=2170)
Train acc: 99.40 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 309), (1, 334), (2, 332), (3, 340), (4, 335), (5, 338), (6, 338), (7, 342), (8, 329), (9, 340), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9791574279379157, 0.9676105113057649, 4909, 11 epochs, take 26 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      0.99      4016
           1       0.64      0.87      0.74      5142
           2       0.94      0.97      0.96      5321
           3       0.97      0.99      0.98      5241
           4       0.98      0.96      0.97      5279
           5       0.98      0.99      0.98      5383
           6       0.98      1.00      0.99      5427
           7       0.96      0.97      0.96      5462
           8       0.99      0.96      0.98      5453
           9       0.99      0.97      0.98      5476
           +       0.99      0.98      0.99     13199
           -       0.98      0.99      0.98     10734
           *       1.00      1.00      1.00     13491
           /       0.99      1.00      0.99      9876
           (       0.75      0.95      0.83     21081
           )       0.97      0.61      0.75     21081

    accuracy                           0.92    141662
   macro avg       0.94      0.95      0.94    141662
weighted avg       0.93      0.92      0.92    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  315    1    0    1    0    0    2    0    0    0    0    0    1    12   29
2    0    0  364    2    1    0    1    1    0    0    0    0    1    0     0    0
3    0    0    3  365    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  357    0    0    5    0    1    2    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    5    2    0    0    0    0  372    0    0    2    0    0    0     0    2
8    0    0    2    7    0    2    0    2  369    0    0    0    0    0     0    0
9    0    0    0    0    6    4    0    2    0  373    0    0    0    0     0    0
+    0    1    0    0    0    0    0    0    0    0  915   14    0    0     0    0
-    3    0    0    0    0    0    0    0    0    0    1  748    0    2     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   70    0    0    0    2    6    0    0    0    0    2    0    0  1406    0
)    0   99    8    0    0    0    0    2    0    0    0    0    0    6   464  906
result accuracy by length:
1 ( 2%) 99.00
3 ( 2%) 99.00
5 ( 2%) 93.02
7 ( 4%) 82.53
9 ( 4%) 75.88
11 ( 3%) 66.48
13 ( 4%) 68.52
15 ( 4%) 66.83
17 ( 4%) 61.17
19 ( 4%) 57.35
21 ( 4%) 59.60
23 ( 4%) 50.24
25 ( 4%) 46.50
27 ( 4%) 44.83
29 ( 3%) 48.69
31 ( 3%) 47.02
33 ( 2%) 36.43
35 ( 2%) 34.93
37 ( 2%) 34.19
39 ( 3%) 32.89
41 ( 3%) 38.93
43 ( 2%) 30.43
45 ( 2%) 27.68
47 ( 2%) 25.00
49 ( 2%) 27.46
51 ( 2%) 24.24
53 ( 2%) 24.63
55 ( 2%) 18.49
57 ( 2%) 27.97
59 ( 2%) 19.63
61 ( 1%) 25.00
63 ( 0%) 25.71
65 ( 0%) 55.56
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 45.97
) (91%) 45.97
* (87%) 45.78
+ (84%) 44.53
- (77%) 44.15
/ (76%) 44.05
0 (52%) 42.23
1 (60%) 39.96
2 (61%) 42.62
3 (62%) 43.87
4 (61%) 42.59
5 (62%) 43.55
6 (62%) 43.81
7 (63%) 43.95
8 (64%) 43.95
9 (63%) 44.13
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 90.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 53.62
1 (10%) 49.06
2 ( 4%) 55.05
3 ( 2%) 59.26
4 ( 2%) 54.89
5 ( 2%) 57.00
6 ( 2%) 58.26
7 ( 2%) 61.95
8 ( 2%) 54.70
9 ( 1%) 61.63
result accuracy by generalization:
1 (22.45%) 70.00
2 (22.96%) 58.67
3 (22.53%) 53.44
4 (15.82%) 30.32
5 (16.24%) 24.62
error cases:
1 ) [-1] [-1] 1 None
4+3 4-3 [1, -1, 1] [1, -1, 1] 7 1
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
9-5+1 9-5+) [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 5 None
8-4+9 8-4-9 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 13 0
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) ++(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 None
val (Perception Acc=91.88, Head Acc=100.00, Result Acc=50.02)
Epoch time: 0m 44s
------------------------------
Epoch 5/99 (max_len=3, data=2170)
Train acc: 99.49 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9692401711142798, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 27s
------------------------------
Epoch 6/99 (max_len=3, data=2170)
Train acc: 99.72 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 315), (12, 303), (13, 272), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9796008869179601, 0.9667956814015074, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 27s
------------------------------
Epoch 7/99 (max_len=3, data=2170)
Train acc: 99.40 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9694438785903443, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 28s
------------------------------
Epoch 8/99 (max_len=3, data=2170)
Train acc: 99.86 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9690364636382155, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 27s
------------------------------
Epoch 9/99 (max_len=3, data=2170)
Train acc: 99.44 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9692401711142798, 4909, 11 epochs, take 26 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      0.99      4016
           1       0.70      0.85      0.76      5142
           2       0.97      0.97      0.97      5321
           3       0.97      0.99      0.98      5241
           4       0.98      0.95      0.96      5279
           5       0.98      0.98      0.98      5383
           6       0.98      1.00      0.99      5427
           7       0.95      0.98      0.96      5462
           8       0.99      0.96      0.98      5453
           9       0.99      0.97      0.98      5476
           +       0.99      0.98      0.99     13199
           -       0.97      0.99      0.98     10734
           *       1.00      1.00      1.00     13491
           /       0.99      1.00      0.99      9876
           (       0.74      0.95      0.83     21081
           )       0.96      0.62      0.75     21081

    accuracy                           0.92    141662
   macro avg       0.95      0.95      0.94    141662
weighted avg       0.93      0.92      0.92    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  306    1    0    1    0    0    2    0    0    0    0    0    1    10   38
2    0    0  363    2    1    0    1    1    0    1    0    0    1    0     1    0
3    0    0    2  365    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  353    0    0    8    0    1    2    1    0    0     0    0
5    0    0    2    0    0  373    0    0    0    0    0    0    0    0     4    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  377    0    0    2    0    0    0     0    2
8    0    0    2    7    0    2    0    2  369    0    0    0    0    0     0    0
9    0    0    0    0    4    4    0    2    0  376    0    0    0    0     0    0
+    0    1    0    0    0    0    0    0    0    0  912   16    0    0     0    0
-    1    0    0    0    0    0    0    0    0    0    0  749    0    4     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   62    0    0    0    0    6    0    0    0    0    2    0    0  1417    0
)    0   68    0    0    0    0    0    4    0    0    0    0    0    2   492  921
result accuracy by length:
1 ( 2%) 99.00
3 ( 2%) 100.00
5 ( 2%) 93.02
7 ( 4%) 85.59
9 ( 4%) 78.39
11 ( 3%) 66.48
13 ( 4%) 72.22
15 ( 4%) 68.81
17 ( 4%) 66.99
19 ( 4%) 61.27
21 ( 4%) 61.62
23 ( 4%) 53.66
25 ( 4%) 51.00
27 ( 4%) 49.75
29 ( 3%) 52.88
31 ( 3%) 52.38
33 ( 2%) 43.57
35 ( 2%) 39.73
37 ( 2%) 34.19
39 ( 3%) 36.84
41 ( 3%) 43.62
43 ( 2%) 38.41
45 ( 2%) 31.25
47 ( 2%) 33.33
49 ( 2%) 33.80
51 ( 2%) 29.55
53 ( 2%) 25.37
55 ( 2%) 26.89
57 ( 2%) 31.47
59 ( 2%) 24.30
61 ( 1%) 35.94
63 ( 0%) 25.71
65 ( 0%) 44.44
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 50.21
) (91%) 50.21
* (87%) 50.03
+ (84%) 48.69
- (77%) 47.85
/ (76%) 48.31
0 (52%) 46.17
1 (60%) 43.78
2 (61%) 46.84
3 (62%) 47.70
4 (61%) 46.63
5 (62%) 47.98
6 (62%) 48.19
7 (63%) 48.40
8 (64%) 48.15
9 (63%) 48.37
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 90.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 57.52
1 (10%) 53.37
2 ( 4%) 60.10
3 ( 2%) 60.00
4 ( 2%) 57.14
5 ( 2%) 58.00
6 ( 2%) 60.00
7 ( 2%) 64.60
8 ( 2%) 58.12
9 ( 1%) 69.77
result accuracy by generalization:
1 (22.45%) 71.73
2 (22.96%) 62.49
3 (22.53%) 57.70
4 (15.82%) 34.32
5 (16.24%) 31.03
error cases:
1 ) [-1] [-1] 1 None
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
9-5+1 9-5+) [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 5 None
8-4+9 8-4-9 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 13 0
(3+6)/7 (3+61/7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
4+(1+8) ++(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 None
2/5*1 7/5*1 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 2
val (Perception Acc=92.03, Head Acc=100.00, Result Acc=53.92)
Epoch time: 0m 44s
------------------------------
Epoch 10/99 (max_len=3, data=2170)
Train acc: 99.72 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 315), (12, 303), (13, 272), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9796008869179601, 0.9686290486860868, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 28s
------------------------------
Epoch 11/99 (max_len=3, data=2170)
Train acc: 99.63 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9700550010185374, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 28s
------------------------------
Epoch 12/99 (max_len=3, data=2170)
Train acc: 99.68 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9692401711142798, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 27s
------------------------------
Epoch 13/99 (max_len=3, data=2170)
Train acc: 99.63 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9716846608270524, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 28s
------------------------------
Epoch 14/99 (max_len=3, data=2170)
Train acc: 99.68 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9710735383988592, 4909, 11 epochs, take 26 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      4016
           1       0.64      0.83      0.73      5142
           2       0.95      0.97      0.96      5321
           3       0.98      0.98      0.98      5241
           4       0.98      0.96      0.97      5279
           5       0.99      0.98      0.98      5383
           6       0.98      0.99      0.99      5427
           7       0.96      0.98      0.97      5462
           8       0.99      0.97      0.98      5453
           9       0.98      0.98      0.98      5476
           +       0.99      0.98      0.99     13199
           -       0.97      0.99      0.98     10734
           *       1.00      1.00      1.00     13491
           /       0.99      1.00      1.00      9876
           (       0.75      0.96      0.84     21081
           )       0.95      0.61      0.74     21081

    accuracy                           0.92    141662
   macro avg       0.94      0.95      0.94    141662
weighted avg       0.93      0.92      0.92    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  302    2    0    0    0    0    1    0    0    0    0    0    0    15   39
2    0    0  363    2    0    0    1    1    0    1    0    0    1    0     1    0
3    0    0    2  362    0    0    0    0    0    3    0    0    0    0     0    0
4    0    0    0    0  357    0    0    5    0    1    2    1    0    0     0    0
5    0    0    2    0    0  373    0    0    0    0    0    0    0    0     4    0
6    0    0    0    0    2    0  380    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  377    0    0    2    0    0    0     0    2
8    0    0    2    5    0    2    0    2  372    0    0    0    0    0     0    0
9    0    0    0    0    4    2    0    2    0  378    0    0    0    0     0    0
+    0    1    0    0    0    0    0    0    0    0  912   18    0    0     0    0
-    1    0    0    0    0    0    0    0    0    0    1  752    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   47    0    0    0    0    6    0    0    0    0    2    0    0  1431    0
)    0  116    4    0    0    0    0    4    0    0    0    0    0    2   460  900
result accuracy by length:
1 ( 2%) 96.00
3 ( 2%) 99.00
5 ( 2%) 91.47
7 ( 4%) 83.84
9 ( 4%) 76.88
11 ( 3%) 67.61
13 ( 4%) 68.52
15 ( 4%) 65.35
17 ( 4%) 62.14
19 ( 4%) 58.33
21 ( 4%) 56.57
23 ( 4%) 50.73
25 ( 4%) 47.00
27 ( 4%) 45.81
29 ( 3%) 45.03
31 ( 3%) 46.43
33 ( 2%) 38.57
35 ( 2%) 32.88
37 ( 2%) 33.33
39 ( 3%) 33.55
41 ( 3%) 37.58
43 ( 2%) 34.06
45 ( 2%) 29.46
47 ( 2%) 25.76
49 ( 2%) 27.46
51 ( 2%) 24.24
53 ( 2%) 27.61
55 ( 2%) 18.49
57 ( 2%) 20.98
59 ( 2%) 14.95
61 ( 1%) 32.81
63 ( 0%) 14.29
65 ( 0%) 44.44
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 45.81
) (91%) 45.81
* (87%) 45.52
+ (84%) 44.34
- (77%) 44.12
/ (76%) 43.65
0 (52%) 41.45
1 (60%) 39.09
2 (61%) 42.39
3 (62%) 43.64
4 (61%) 42.79
5 (62%) 42.22
6 (62%) 43.87
7 (63%) 43.62
8 (64%) 43.54
9 (63%) 44.60
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 70.00
2 ( 0%) 100.00
3 ( 0%) 90.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 53.52
1 (10%) 49.63
2 ( 4%) 56.57
3 ( 2%) 54.81
4 ( 2%) 52.63
5 ( 2%) 56.00
6 ( 2%) 54.78
7 ( 2%) 61.95
8 ( 2%) 53.85
9 ( 1%) 65.12
result accuracy by generalization:
1 (22.45%) 69.45
2 (22.96%) 59.02
3 (22.53%) 52.90
4 (15.82%) 29.94
5 (16.24%) 24.50
error cases:
1 ) [-1] [-1] 1 None
1 ( [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
3 9 [-1] [-1] 3 9
4+3 4-3 [1, -1, 1] [1, -1, 1] 7 1
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
9-5+1 9-5+) [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 5 None
8-4+9 8-4-9 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 13 0
val (Perception Acc=91.99, Head Acc=100.00, Result Acc=49.78)
Epoch time: 0m 44s
------------------------------
Epoch 15/99 (max_len=3, data=2170)
Train acc: 99.63 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 315), (12, 303), (13, 272), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9796008869179601, 0.9674068038297006, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 27s
------------------------------
Epoch 16/99 (max_len=3, data=2170)
Train acc: 99.63 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9667956814015074, 4909, 11 epochs, take 26 sec.
Epoch time: 0m 28s
------------------------------
Epoch 17/99 (max_len=3, data=2170)
Train acc: 99.54 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9702587084946017, 4909, 11 epochs, take 27 sec.
Epoch time: 0m 28s
------------------------------
Epoch 18/99 (max_len=3, data=2170)
Train acc: 99.68 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9724994907313098, 4909, 11 epochs, take 27 sec.
Epoch time: 0m 28s
------------------------------
Epoch 19/99 (max_len=3, data=2170)
Train acc: 99.72 (abduce 100.00)
Hit samples:  2170  Ave length:  2.08
Symbols:  15 [(0, 308), (1, 333), (2, 332), (3, 340), (4, 334), (5, 339), (6, 338), (7, 343), (8, 329), (9, 341), (10, 282), (11, 314), (12, 303), (13, 273), (15, 1)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170)]
Learn perception with 2170 samples for 100 iterations, 0.9798226164079823, 0.9692401711142798, 4909, 11 epochs, take 26 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.71      0.81      0.75      5142
           2       0.97      0.97      0.97      5321
           3       0.96      0.98      0.97      5241
           4       0.99      0.95      0.97      5279
           5       0.98      0.99      0.98      5383
           6       0.98      0.99      0.99      5427
           7       0.94      0.97      0.96      5462
           8       0.99      0.95      0.97      5453
           9       0.99      0.98      0.98      5476
           +       0.99      0.98      0.99     13199
           -       0.97      0.99      0.98     10734
           *       1.00      1.00      1.00     13491
           /       0.99      1.00      1.00      9876
           (       0.74      0.97      0.84     21081
           )       0.95      0.62      0.75     21081

    accuracy                           0.92    141662
   macro avg       0.95      0.95      0.94    141662
weighted avg       0.93      0.92      0.92    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  292    1    0    0    0    0    2    0    0    0    0    0    0    22   42
2    0    0  363    2    0    0    1    1    0    1    0    0    1    0     1    0
3    0    0    2  363    0    0    0    0    0    1    0    0    0    0     0    0
4    0    1    0    0  352    0    2    8    0    1    2    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    2    0    0    0    0    0  380    0    0    0    0    0    0    0     0    0
7    0    2    2    0    0    0    0  374    0    0    2    0    0    0     0    2
8    0    0    2   12    0    2    0    2  364    0    0    0    0    0     0    0
9    0    0    0    0    2    4    0    2    0  378    0    0    0    0     0    0
+    0    3    0    0    0    0    0    1    0    0  911   15    0    0     0    0
-    1    0    0    0    0    0    0    0    0    0    0  751    0    2     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   37    0    0    0    0    4    0    0    0    0    2    0    0  1438    6
)    0   76    0    0    0    0    0    4    0    0    0    0    0    2   475  929
result accuracy by length:
1 ( 2%) 98.00
3 ( 2%) 97.00
5 ( 2%) 91.47
7 ( 4%) 84.28
9 ( 4%) 77.89
11 ( 3%) 71.02
13 ( 4%) 72.69
15 ( 4%) 66.83
17 ( 4%) 66.50
19 ( 4%) 59.31
21 ( 4%) 59.60
23 ( 4%) 54.63
25 ( 4%) 52.50
27 ( 4%) 51.72
29 ( 3%) 51.31
31 ( 3%) 50.00
33 ( 2%) 38.57
35 ( 2%) 37.67
37 ( 2%) 38.46
39 ( 3%) 40.13
41 ( 3%) 38.93
43 ( 2%) 44.20
45 ( 2%) 31.25
47 ( 2%) 30.30
49 ( 2%) 35.21
51 ( 2%) 34.09
53 ( 2%) 33.58
55 ( 2%) 20.17
57 ( 2%) 30.07
59 ( 2%) 19.63
61 ( 1%) 29.69
63 ( 0%) 22.86
65 ( 0%) 22.22
67 ( 0%)  0.00
result accuracy by symbol:
( (91%) 49.92
) (91%) 49.92
* (87%) 49.71
+ (84%) 48.45
- (77%) 47.85
/ (76%) 47.86
0 (52%) 46.64
1 (60%) 42.17
2 (61%) 47.08
3 (62%) 47.70
4 (61%) 46.67
5 (62%) 47.75
6 (62%) 47.89
7 (63%) 47.98
8 (64%) 47.04
9 (63%) 48.56
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 80.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 57.62
1 (10%) 53.37
2 ( 4%) 60.61
3 ( 2%) 57.78
4 ( 2%) 52.63
5 ( 2%) 57.00
6 ( 2%) 56.52
7 ( 2%) 65.49
8 ( 2%) 57.26
9 ( 1%) 69.77
result accuracy by generalization:
1 (22.45%) 71.73
2 (22.96%) 61.07
3 (22.53%) 57.61
4 (15.82%) 34.32
5 (16.24%) 30.90
error cases:
1 ( [-1] [-1] 1 None
1 ) [-1] [-1] 1 None
1+8 (+8 [1, -1, 1] [1, -1, 1] 9 None
4+3 4-3 [1, -1, 1] [1, -1, 1] 7 1
1-1 1-) [1, -1, 1] [1, -1, 1] 0 None
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
7-(8+6) )-(8+61 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
9/(9-2) 9/(5-2( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 3
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
5+(0-1) 5+(0-)) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 5 None
val (Perception Acc=92.09, Head Acc=100.00, Result Acc=53.55)
Epoch time: 0m 44s
------------------------------
Epoch 20/99 (max_len=7, data=3387)
Train acc: 92.91 (abduce 99.70)
Hit samples:  3377  Ave length:  3.55
Symbols:  16 [(0, 613), (1, 730), (2, 716), (3, 753), (4, 735), (5, 721), (6, 719), (7, 762), (8, 710), (9, 713), (10, 971), (11, 1022), (12, 933), (13, 889), (14, 683), (15, 333)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 373), ((2, 2, 5, 2, 2, -1, 5), 140), ((1, 3, 1, -1, 5, 3, 5), 91), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3377 samples for 100 iterations, 0.9703407481462968, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 21/99 (max_len=7, data=3387)
Train acc: 97.70 (abduce 99.94)
Hit samples:  3385  Ave length:  3.56
Symbols:  16 [(0, 615), (1, 732), (2, 718), (3, 750), (4, 740), (5, 720), (6, 720), (7, 764), (8, 720), (9, 718), (10, 982), (11, 1020), (12, 934), (13, 896), (14, 691), (15, 339)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 379), ((2, 2, 5, 2, 2, -1, 5), 141), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3385 samples for 100 iterations, 0.9709760344970562, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 22/99 (max_len=7, data=3387)
Train acc: 98.57 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 615), (1, 734), (2, 718), (3, 751), (4, 741), (5, 721), (6, 721), (7, 765), (8, 718), (9, 719), (10, 984), (11, 1022), (12, 935), (13, 895), (14, 692), (15, 342)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9712581794085977, 5 epochs, take 27 sec.
Epoch time: 0m 30s
------------------------------
Epoch 23/99 (max_len=7, data=3387)
Train acc: 99.21 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 752), (4, 742), (5, 723), (6, 721), (7, 762), (8, 717), (9, 720), (10, 984), (11, 1021), (12, 935), (13, 896), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9715066677710594, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 24/99 (max_len=7, data=3387)
Train acc: 99.32 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 751), (4, 744), (5, 723), (6, 720), (7, 762), (8, 718), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.971837985587675, 5 epochs, take 27 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      4016
           1       0.82      0.93      0.87      5142
           2       0.97      0.98      0.98      5321
           3       0.99      0.99      0.99      5241
           4       1.00      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      0.99     13199
           -       0.99      0.99      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.74      0.96      0.84     21081
           )       0.99      0.65      0.79     21081

    accuracy                           0.94    141662
   macro avg       0.96      0.97      0.96    141662
weighted avg       0.95      0.94      0.93    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  339    1    0    0    0    0    0    0    0    0    0    0    1    11    7
2    0    0  369    1    0    0    0    0    0    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  363    0    0    2    0    1    2    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    2    0  380    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    3    0    0    0    0    0    0    0    0  923    5    0    0     0    0
-    0    0    0    0    0    1    0    0    0    0    0  752    0    1     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   48    0    0    0    0    2    0    0    0    0    2    0    0  1435    0
)    0   24    0    0    0    0    0    0    0    0    0    0    0   10   481  971
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 93.01
9 ( 4%) 87.94
11 ( 3%) 84.66
13 ( 4%) 82.41
15 ( 4%) 85.64
17 ( 4%) 81.07
19 ( 4%) 77.45
21 ( 4%) 81.31
23 ( 4%) 70.73
25 ( 4%) 72.50
27 ( 4%) 67.98
29 ( 3%) 74.35
31 ( 3%) 68.45
33 ( 2%) 72.86
35 ( 2%) 61.64
37 ( 2%) 58.97
39 ( 3%) 64.47
41 ( 3%) 67.11
43 ( 2%) 62.32
45 ( 2%) 55.36
47 ( 2%) 54.55
49 ( 2%) 59.86
51 ( 2%) 53.03
53 ( 2%) 51.49
55 ( 2%) 47.06
57 ( 2%) 49.65
59 ( 2%) 44.86
61 ( 1%) 48.44
63 ( 0%) 42.86
65 ( 0%) 55.56
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 69.30
) (91%) 69.30
* (87%) 69.22
+ (84%) 68.55
- (77%) 67.85
/ (76%) 67.38
0 (52%) 66.02
1 (60%) 64.73
2 (61%) 66.88
3 (62%) 67.54
4 (61%) 65.84
5 (62%) 67.71
6 (62%) 67.62
7 (63%) 67.42
8 (64%) 67.07
9 (63%) 68.71
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 74.19
1 (10%) 68.16
2 ( 4%) 75.25
3 ( 2%) 75.56
4 ( 2%) 72.18
5 ( 2%) 80.00
6 ( 2%) 77.39
7 ( 2%) 85.84
8 ( 2%) 73.50
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 82.91
2 (22.96%) 79.11
3 (22.53%) 76.54
4 (15.82%) 60.13
5 (16.24%) 50.63
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
4+(1+8) ++(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 None
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
3-(5+1) 3-(5+11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
7*(2*8) 7*(2*81 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 112 None
val (Perception Acc=93.60, Head Acc=100.00, Result Acc=71.76)
Epoch time: 0m 46s
------------------------------
Epoch 25/99 (max_len=7, data=3387)
Train acc: 99.50 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 733), (2, 718), (3, 751), (4, 743), (5, 722), (6, 720), (7, 762), (8, 718), (9, 720), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9721693034042905, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 26/99 (max_len=7, data=3387)
Train acc: 99.59 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 733), (2, 718), (3, 751), (4, 743), (5, 722), (6, 720), (7, 762), (8, 718), (9, 720), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9721693034042905, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 27/99 (max_len=7, data=3387)
Train acc: 99.47 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 752), (4, 743), (5, 722), (6, 720), (7, 764), (8, 717), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9720036444959828, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 28/99 (max_len=7, data=3387)
Train acc: 99.65 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 734), (2, 718), (3, 752), (4, 741), (5, 722), (6, 720), (7, 765), (8, 717), (9, 718), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9720864739501367, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 29/99 (max_len=7, data=3387)
Train acc: 99.50 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 733), (2, 718), (3, 752), (4, 743), (5, 722), (6, 720), (7, 763), (8, 717), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9721693034042905, 5 epochs, take 27 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      4016
           1       0.84      0.93      0.88      5142
           2       0.97      0.98      0.98      5321
           3       0.99      0.99      0.99      5241
           4       1.00      0.97      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      0.99      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.74      0.97      0.84     21081
           )       0.99      0.65      0.79     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.96    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  337    1    0    0    0    0    1    0    0    0    0    0    1    12    7
2    0    0  369    1    0    0    0    0    0    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  362    0    0    4    0    1    0    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    3    0    0    0    0    0    0    0    0  923    5    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  753    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   37    0    0    0    0    2    0    0    0    0    2    0    0  1446    0
)    0   22    0    0    0    0    0    0    0    0    0    0    0   10   481  973
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 93.01
9 ( 4%) 87.94
11 ( 3%) 85.23
13 ( 4%) 86.11
15 ( 4%) 86.14
17 ( 4%) 83.50
19 ( 4%) 80.39
21 ( 4%) 83.84
23 ( 4%) 72.20
25 ( 4%) 76.00
27 ( 4%) 71.43
29 ( 3%) 76.96
31 ( 3%) 69.64
33 ( 2%) 74.29
35 ( 2%) 66.44
37 ( 2%) 66.67
39 ( 3%) 67.11
41 ( 3%) 67.11
43 ( 2%) 63.77
45 ( 2%) 55.36
47 ( 2%) 59.85
49 ( 2%) 60.56
51 ( 2%) 56.82
53 ( 2%) 59.70
55 ( 2%) 51.26
57 ( 2%) 55.94
59 ( 2%) 50.47
61 ( 1%) 51.56
63 ( 0%) 42.86
65 ( 0%) 55.56
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 71.98
) (91%) 71.98
* (87%) 71.89
+ (84%) 71.15
- (77%) 70.73
/ (76%) 70.28
0 (52%) 68.79
1 (60%) 67.17
2 (61%) 69.80
3 (62%) 70.46
4 (61%) 68.99
5 (62%) 70.21
6 (62%) 70.70
7 (63%) 70.33
8 (64%) 69.94
9 (63%) 71.42
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 76.57
1 (10%) 70.97
2 ( 4%) 77.78
3 ( 2%) 78.52
4 ( 2%) 75.19
5 ( 2%) 80.00
6 ( 2%) 80.87
7 ( 2%) 88.50
8 ( 2%) 74.36
9 ( 1%) 88.37
result accuracy by generalization:
1 (22.45%) 84.64
2 (22.96%) 81.16
3 (22.53%) 78.89
4 (15.82%) 62.06
5 (16.24%) 55.28
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
5/(6-0) 5/(6-01 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
3-(5+1) 3-(5+11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
1+3+4 1+3+3 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 8 7
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
val (Perception Acc=93.75, Head Acc=100.00, Result Acc=74.20)
Epoch time: 0m 45s
------------------------------
Epoch 30/99 (max_len=7, data=3387)
Train acc: 99.59 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 752), (4, 742), (5, 722), (6, 720), (7, 765), (8, 717), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9719208150418289, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 31/99 (max_len=7, data=3387)
Train acc: 99.47 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 733), (2, 718), (3, 752), (4, 742), (5, 722), (6, 720), (7, 765), (8, 717), (9, 718), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9721693034042905, 5 epochs, take 27 sec.
Epoch time: 0m 30s
------------------------------
Epoch 32/99 (max_len=7, data=3387)
Train acc: 99.59 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 751), (4, 743), (5, 722), (6, 720), (7, 764), (8, 718), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9720864739501367, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 33/99 (max_len=7, data=3387)
Train acc: 99.45 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 751), (4, 743), (5, 722), (6, 720), (7, 763), (8, 718), (9, 720), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9720036444959828, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 34/99 (max_len=7, data=3387)
Train acc: 99.71 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 733), (2, 718), (3, 751), (4, 743), (5, 722), (6, 720), (7, 763), (8, 718), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9722521328584445, 5 epochs, take 27 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      4016
           1       0.83      0.94      0.88      5142
           2       0.97      0.98      0.97      5321
           3       0.99      0.99      0.99      5241
           4       1.00      0.98      0.99      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      0.99     13199
           -       0.99      0.99      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.74      0.97      0.84     21081
           )       0.99      0.66      0.79     21081

    accuracy                           0.94    141662
   macro avg       0.96      0.97      0.96    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  339    1    0    0    0    0    0    0    0    0    0    0    1    11    7
2    0    0  367    1    0    0    0    0    0    1    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  363    0    0    4    0    1    0    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    3    0    0    0    0    0    0    0    0  923    5    0    0     0    0
-    1    0    0    0    0    0    0    0    0    0    1  750    0    1     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   43    0    0    0    0    2    0    0    0    0    2    0    0  1440    0
)    0   22    0    0    0    0    0    0    0    0    0    0    0   10   479  975
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 99.22
7 ( 4%) 92.58
9 ( 4%) 87.94
11 ( 3%) 84.66
13 ( 4%) 84.26
15 ( 4%) 85.64
17 ( 4%) 83.01
19 ( 4%) 79.41
21 ( 4%) 81.31
23 ( 4%) 72.68
25 ( 4%) 75.50
27 ( 4%) 69.46
29 ( 3%) 76.44
31 ( 3%) 70.24
33 ( 2%) 71.43
35 ( 2%) 60.27
37 ( 2%) 67.52
39 ( 3%) 65.13
41 ( 3%) 65.77
43 ( 2%) 62.32
45 ( 2%) 56.25
47 ( 2%) 57.58
49 ( 2%) 59.15
51 ( 2%) 57.58
53 ( 2%) 55.97
55 ( 2%) 48.74
57 ( 2%) 53.15
59 ( 2%) 47.66
61 ( 1%) 51.56
63 ( 0%) 42.86
65 ( 0%) 77.78
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 70.77
) (91%) 70.77
* (87%) 70.68
+ (84%) 69.97
- (77%) 69.50
/ (76%) 68.97
0 (52%) 67.70
1 (60%) 65.80
2 (61%) 68.41
3 (62%) 69.15
4 (61%) 67.63
5 (62%) 69.21
6 (62%) 69.16
7 (63%) 69.07
8 (64%) 68.79
9 (63%) 70.27
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 75.33
1 (10%) 68.91
2 ( 4%) 76.77
3 ( 2%) 77.78
4 ( 2%) 74.44
5 ( 2%) 78.00
6 ( 2%) 80.00
7 ( 2%) 88.50
8 ( 2%) 76.07
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 84.00
2 (22.96%) 80.53
3 (22.53%) 77.45
4 (15.82%) 61.42
5 (16.24%) 53.02
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
3-(5+1) 3-(5+11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
7*(2*8) 7*(2*81 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 112 None
val (Perception Acc=93.69, Head Acc=100.00, Result Acc=73.12)
Epoch time: 0m 45s
------------------------------
Epoch 35/99 (max_len=7, data=3387)
Train acc: 99.62 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 751), (4, 744), (5, 722), (6, 720), (7, 762), (8, 718), (9, 720), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9720864739501367, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 36/99 (max_len=7, data=3387)
Train acc: 99.62 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 734), (2, 718), (3, 751), (4, 742), (5, 722), (6, 720), (7, 763), (8, 718), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9721693034042905, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 37/99 (max_len=7, data=3387)
Train acc: 99.51 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 617), (1, 733), (2, 718), (3, 751), (4, 743), (5, 722), (6, 720), (7, 763), (8, 718), (9, 719), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.9722521328584445, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 38/99 (max_len=7, data=3387)
Train acc: 99.62 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 751), (4, 742), (5, 722), (6, 720), (7, 764), (8, 718), (9, 720), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.971837985587675, 5 epochs, take 27 sec.
Epoch time: 0m 29s
------------------------------
Epoch 39/99 (max_len=7, data=3387)
Train acc: 99.71 (abduce 100.00)
Hit samples:  3387  Ave length:  3.56
Symbols:  16 [(0, 616), (1, 733), (2, 718), (3, 751), (4, 742), (5, 722), (6, 720), (7, 764), (8, 718), (9, 720), (10, 984), (11, 1020), (12, 935), (13, 897), (14, 692), (15, 341)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, 5, 3, -1, 5), 88), ((1, 5, 3, 1, 3, -1, 5), 20), ((1, -1, 3, 5, 3, 1, 5), 17)]
Learn perception with 3387 samples for 100 iterations, 0.971837985587675, 5 epochs, take 27 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      1.00      4016
           1       0.83      0.94      0.88      5142
           2       0.97      0.98      0.98      5321
           3       0.99      0.99      0.99      5241
           4       0.99      0.97      0.98      5279
           5       0.99      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.98      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      0.99      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.74      0.97      0.84     21081
           )       0.99      0.65      0.79     21081

    accuracy                           0.94    141662
   macro avg       0.96      0.97      0.96    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  339    1    0    0    0    0    1    0    0    0    0    0    1    11    6
2    1    0  367    1    0    0    0    0    0    1    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  362    0    0    4    0    1    0    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    1    0    0    1    0    0    0    0    0  924    4    0    0     0    0
-    0    0    0    0    0    1    0    0    0    0    0  753    0    1     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   41    0    0    2    0    2    0    0    0    0    2    0    0  1439    0
)    0   24    0    0    0    0    0    0    0    0    0    0    0   10   481  971
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 99.22
7 ( 4%) 93.45
9 ( 4%) 86.93
11 ( 3%) 85.23
13 ( 4%) 84.72
15 ( 4%) 85.64
17 ( 4%) 82.04
19 ( 4%) 77.94
21 ( 4%) 80.81
23 ( 4%) 72.20
25 ( 4%) 75.00
27 ( 4%) 69.95
29 ( 3%) 78.01
31 ( 3%) 72.02
33 ( 2%) 72.14
35 ( 2%) 62.33
37 ( 2%) 64.96
39 ( 3%) 65.13
41 ( 3%) 69.80
43 ( 2%) 63.04
45 ( 2%) 57.14
47 ( 2%) 55.30
49 ( 2%) 62.68
51 ( 2%) 55.30
53 ( 2%) 55.22
55 ( 2%) 49.58
57 ( 2%) 53.15
59 ( 2%) 44.86
61 ( 1%) 51.56
63 ( 0%) 42.86
65 ( 0%) 77.78
67 ( 0%) 33.33
result accuracy by symbol:
( (91%) 70.89
) (91%) 70.89
* (87%) 70.77
+ (84%) 70.19
- (77%) 69.69
/ (76%) 69.21
0 (52%) 67.73
1 (60%) 66.27
2 (61%) 68.47
3 (62%) 69.25
4 (61%) 68.03
5 (62%) 69.47
6 (62%) 69.45
7 (63%) 69.03
8 (64%) 68.69
9 (63%) 70.27
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 76.19
1 (10%) 70.04
2 ( 4%) 76.77
3 ( 2%) 77.04
4 ( 2%) 74.44
5 ( 2%) 78.00
6 ( 2%) 78.26
7 ( 2%) 87.61
8 ( 2%) 76.07
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 84.09
2 (22.96%) 80.53
3 (22.53%) 77.54
4 (15.82%) 62.19
5 (16.24%) 52.76
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
2*(1/4) 2*((/4) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 2 None
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(4-1)*1 (4-11*1 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 3 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
3-(5+1) 3-(5+11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
7*(2*8) 7*(2*81 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 112 None
6*(9*9) 6*(9*91 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 486 None
val (Perception Acc=93.67, Head Acc=100.00, Result Acc=73.24)
Epoch time: 0m 45s
------------------------------
Epoch 40/99 (max_len=11, data=4683)
Train acc: 96.42 (abduce 99.94)
Hit samples:  4680  Ave length:  5.34
Symbols:  16 [(0, 1114), (1, 1324), (2, 1328), (3, 1359), (4, 1311), (5, 1286), (6, 1282), (7, 1381), (8, 1257), (9, 1271), (10, 2202), (11, 2171), (12, 1914), (13, 1975), (14, 2495), (15, 1298)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 113), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4680 samples for 100 iterations, 0.9655559115668055, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 41/99 (max_len=11, data=4683)
Train acc: 97.99 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1113), (1, 1326), (2, 1330), (3, 1366), (4, 1312), (5, 1287), (6, 1283), (7, 1382), (8, 1257), (9, 1270), (10, 2207), (11, 2174), (12, 1917), (13, 1977), (14, 2491), (15, 1305)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9662759531143738, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 42/99 (max_len=11, data=4683)
Train acc: 99.05 (abduce 99.98)
Hit samples:  4682  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1326), (2, 1328), (3, 1363), (4, 1311), (5, 1286), (6, 1282), (7, 1384), (8, 1260), (9, 1268), (10, 2208), (11, 2172), (12, 1917), (13, 1976), (14, 2489), (15, 1305)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 141), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4682 samples for 100 iterations, 0.9664265706282513, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 43/99 (max_len=11, data=4683)
Train acc: 99.08 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1325), (2, 1329), (3, 1364), (4, 1310), (5, 1286), (6, 1282), (7, 1384), (8, 1259), (9, 1271), (10, 2209), (11, 2172), (12, 1917), (13, 1977), (14, 2493), (15, 1303)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9665959915189822, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 44/99 (max_len=11, data=4683)
Train acc: 99.30 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1323), (2, 1329), (3, 1364), (4, 1311), (5, 1286), (6, 1282), (7, 1382), (8, 1259), (9, 1272), (10, 2209), (11, 2172), (12, 1918), (13, 1977), (14, 2493), (15, 1304)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9666760011201344, 3 epochs, take 32 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      0.99      4016
           1       0.87      0.93      0.90      5142
           2       0.97      0.99      0.98      5321
           3       0.99      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      0.99      0.99      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.75      0.97      0.85     21081
           )       0.99      0.67      0.80     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.96    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  338    0    0    0    0    0    1    0    0    0    0    0    1    11    7
2    0    0  371    0    0    0    0    0    0    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  363    0    0    3    0    1    0    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  384    0    0    0    0     0    2
+    0    0    0    0    1    0    0    0    0    0  925    3    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  754    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   33    0    0    0    0    2    0    0    0    2    2    0    0  1442    4
)    0   16    0    0    0    0    0    0    0    0    0    0    0   12   467  991
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 99.00
5 ( 2%) 99.22
7 ( 4%) 94.76
9 ( 4%) 87.94
11 ( 3%) 86.93
13 ( 4%) 88.43
15 ( 4%) 83.17
17 ( 4%) 83.01
19 ( 4%) 80.88
21 ( 4%) 87.37
23 ( 4%) 77.07
25 ( 4%) 71.50
27 ( 4%) 75.37
29 ( 3%) 76.96
31 ( 3%) 71.43
33 ( 2%) 78.57
35 ( 2%) 64.38
37 ( 2%) 67.52
39 ( 3%) 69.74
41 ( 3%) 67.11
43 ( 2%) 64.49
45 ( 2%) 59.82
47 ( 2%) 62.12
49 ( 2%) 62.68
51 ( 2%) 59.85
53 ( 2%) 63.43
55 ( 2%) 49.58
57 ( 2%) 55.94
59 ( 2%) 54.21
61 ( 1%) 60.94
63 ( 0%) 51.43
65 ( 0%) 66.67
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 73.50
) (91%) 73.50
* (87%) 73.36
+ (84%) 72.66
- (77%) 72.34
/ (76%) 72.17
0 (52%) 71.13
1 (60%) 69.08
2 (61%) 71.83
3 (62%) 71.64
4 (61%) 71.51
5 (62%) 71.74
6 (62%) 71.97
7 (63%) 72.39
8 (64%) 71.46
9 (63%) 72.29
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 79.14
1 (10%) 73.97
2 ( 4%) 78.79
3 ( 2%) 79.26
4 ( 2%) 75.94
5 ( 2%) 78.00
6 ( 2%) 78.26
7 ( 2%) 85.84
8 ( 2%) 76.07
9 ( 1%) 88.37
result accuracy by generalization:
1 (22.45%) 86.00
2 (22.96%) 81.96
3 (22.53%) 79.35
4 (15.82%) 64.26
5 (16.24%) 57.91
error cases:
6+9 6+) [1, -1, 1] [1, -1, 1] 15 None
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
5*(9-5) 5*19-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 0
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
6*(9*5) 6*(9*51 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 270 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
(8+5)*8 (8+2(*8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 104 80
val (Perception Acc=93.95, Head Acc=100.00, Result Acc=75.57)
Epoch time: 0m 52s
------------------------------
Epoch 45/99 (max_len=11, data=4683)
Train acc: 99.28 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1322), (2, 1329), (3, 1364), (4, 1312), (5, 1286), (6, 1282), (7, 1382), (8, 1259), (9, 1272), (10, 2209), (11, 2173), (12, 1918), (13, 1976), (14, 2493), (15, 1304)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9667160059207105, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 46/99 (max_len=11, data=4683)
Train acc: 99.43 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1322), (2, 1329), (3, 1365), (4, 1312), (5, 1286), (6, 1282), (7, 1380), (8, 1258), (9, 1274), (10, 2209), (11, 2172), (12, 1918), (13, 1977), (14, 2492), (15, 1305)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9665959915189822, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 47/99 (max_len=11, data=4683)
Train acc: 99.41 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1323), (2, 1329), (3, 1365), (4, 1312), (5, 1286), (6, 1282), (7, 1382), (8, 1258), (9, 1272), (10, 2208), (11, 2173), (12, 1918), (13, 1977), (14, 2492), (15, 1305)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9665559867184063, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 48/99 (max_len=11, data=4683)
Train acc: 99.44 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1324), (2, 1329), (3, 1365), (4, 1310), (5, 1286), (6, 1282), (7, 1381), (8, 1258), (9, 1273), (10, 2209), (11, 2173), (12, 1918), (13, 1976), (14, 2491), (15, 1306)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9665559867184063, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 49/99 (max_len=11, data=4683)
Train acc: 99.38 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1323), (2, 1329), (3, 1365), (4, 1312), (5, 1286), (6, 1282), (7, 1379), (8, 1258), (9, 1274), (10, 2209), (11, 2172), (12, 1918), (13, 1977), (14, 2491), (15, 1306)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9665959915189822, 3 epochs, take 32 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      0.99      4016
           1       0.88      0.93      0.91      5142
           2       0.97      0.99      0.98      5321
           3       0.98      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.98      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.75      0.97      0.84     21081
           )       0.99      0.66      0.79     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.96    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  337    0    0    0    0    0    0    0    0    0    0    0    1    12    8
2    0    0  371    0    0    0    0    0    0    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  363    0    0    3    0    1    0    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    5    0    0    0    0  377    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    0    0    0    1    0    0    0    0    0  925    3    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  754    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   31    0    0    0    0    2    0    0    0    2    2    0    0  1444    4
)    0   14    0    0    0    0    0    0    0    0    0    0    0   12   475  985
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 99.22
7 ( 4%) 95.63
9 ( 4%) 87.44
11 ( 3%) 86.93
13 ( 4%) 87.96
15 ( 4%) 84.65
17 ( 4%) 84.47
19 ( 4%) 80.88
21 ( 4%) 86.87
23 ( 4%) 76.10
25 ( 4%) 73.00
27 ( 4%) 77.34
29 ( 3%) 78.53
31 ( 3%) 72.62
33 ( 2%) 78.57
35 ( 2%) 65.75
37 ( 2%) 67.52
39 ( 3%) 69.08
41 ( 3%) 69.13
43 ( 2%) 66.67
45 ( 2%) 58.93
47 ( 2%) 62.12
49 ( 2%) 64.79
51 ( 2%) 64.39
53 ( 2%) 64.18
55 ( 2%) 52.10
57 ( 2%) 58.04
59 ( 2%) 55.14
61 ( 1%) 59.38
63 ( 0%) 51.43
65 ( 0%) 66.67
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 74.30
) (91%) 74.30
* (87%) 74.26
+ (84%) 73.58
- (77%) 72.91
/ (76%) 72.92
0 (52%) 72.46
1 (60%) 69.65
2 (61%) 73.02
3 (62%) 72.52
4 (61%) 72.31
5 (62%) 72.66
6 (62%) 73.11
7 (63%) 73.01
8 (64%) 72.01
9 (63%) 73.34
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 80.48
1 (10%) 73.60
2 ( 4%) 80.30
3 ( 2%) 80.74
4 ( 2%) 75.19
5 ( 2%) 81.00
6 ( 2%) 79.13
7 ( 2%) 84.96
8 ( 2%) 76.07
9 ( 1%) 88.37
result accuracy by generalization:
1 (22.45%) 86.45
2 (22.96%) 82.58
3 (22.53%) 79.89
4 (15.82%) 65.55
5 (16.24%) 59.17
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
5*(9-5) 5*19-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 0
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
(8+5)*8 (8+2(*8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 104 80
8/1-(6+1) 3/1-(6+1) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 1 0
1*(6+2)-6 )*(6+2(-6 [1, 7, 4, 4, 1, 4, 4, -1, 7] [1, 7, 4, 4, 1, 4, 4, -1, 7] 2 None
val (Perception Acc=93.89, Head Acc=100.00, Result Acc=76.35)
Epoch time: 0m 52s
------------------------------
Epoch 50/99 (max_len=11, data=4683)
Train acc: 99.44 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1322), (2, 1329), (3, 1365), (4, 1313), (5, 1286), (6, 1282), (7, 1382), (8, 1258), (9, 1271), (10, 2209), (11, 2173), (12, 1918), (13, 1976), (14, 2490), (15, 1307)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9666359963195583, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 51/99 (max_len=11, data=4683)
Train acc: 99.37 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1322), (2, 1329), (3, 1365), (4, 1314), (5, 1286), (6, 1282), (7, 1381), (8, 1258), (9, 1271), (10, 2209), (11, 2174), (12, 1918), (13, 1975), (14, 2490), (15, 1307)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9666359963195583, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 52/99 (max_len=11, data=4683)
Train acc: 99.46 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1322), (2, 1330), (3, 1365), (4, 1313), (5, 1286), (6, 1282), (7, 1381), (8, 1257), (9, 1272), (10, 2210), (11, 2173), (12, 1918), (13, 1975), (14, 2490), (15, 1307)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9666359963195583, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 53/99 (max_len=11, data=4683)
Train acc: 99.43 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1116), (1, 1322), (2, 1329), (3, 1365), (4, 1315), (5, 1286), (6, 1282), (7, 1380), (8, 1258), (9, 1271), (10, 2209), (11, 2174), (12, 1918), (13, 1975), (14, 2490), (15, 1307)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9666760011201344, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 54/99 (max_len=11, data=4683)
Train acc: 98.83 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1325), (2, 1327), (3, 1365), (4, 1312), (5, 1286), (6, 1282), (7, 1382), (8, 1258), (9, 1272), (10, 2209), (11, 2174), (12, 1918), (13, 1977), (14, 2491), (15, 1304)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9667960155218627, 3 epochs, take 32 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.81      0.94      0.87      5142
           2       0.97      0.99      0.98      5321
           3       0.99      0.99      0.99      5241
           4       0.99      0.98      0.98      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.98      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.97      1.00      0.99      9876
           (       0.76      0.96      0.85     21081
           )       0.99      0.67      0.79     21081

    accuracy                           0.94    141662
   macro avg       0.96      0.97      0.96    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  340    1    0    0    0    0    1    0    0    0    0    0    1     9    7
2    0    0  370    1    0    0    0    0    0    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  363    0    0    4    0    1    0    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    0    0    0    1    0    0    0    0    0  925    3    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  754    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   41    0    0    0    0    2    0    0    0    2    2    0    0  1433    4
)    2   35    0    0    0    0    0    0    0    0    0    0    0   16   444  989
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 99.22
7 ( 4%) 94.76
9 ( 4%) 85.43
11 ( 3%) 86.36
13 ( 4%) 86.57
15 ( 4%) 81.68
17 ( 4%) 80.58
19 ( 4%) 76.47
21 ( 4%) 81.82
23 ( 4%) 73.17
25 ( 4%) 69.50
27 ( 4%) 74.88
29 ( 3%) 71.20
31 ( 3%) 66.07
33 ( 2%) 71.43
35 ( 2%) 58.90
37 ( 2%) 64.10
39 ( 3%) 63.16
41 ( 3%) 61.07
43 ( 2%) 61.59
45 ( 2%) 52.68
47 ( 2%) 56.82
49 ( 2%) 53.52
51 ( 2%) 55.30
53 ( 2%) 56.72
55 ( 2%) 47.06
57 ( 2%) 45.45
59 ( 2%) 44.86
61 ( 1%) 48.44
63 ( 0%) 40.00
65 ( 0%) 55.56
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 69.01
) (91%) 69.01
* (87%) 68.96
+ (84%) 68.17
- (77%) 67.61
/ (76%) 67.40
0 (52%) 66.33
1 (60%) 64.46
2 (61%) 67.24
3 (62%) 67.34
4 (61%) 66.30
5 (62%) 67.06
6 (62%) 66.87
7 (63%) 67.16
8 (64%) 67.04
9 (63%) 67.98
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 73.81
1 (10%) 67.79
2 ( 4%) 75.25
3 ( 2%) 72.59
4 ( 2%) 73.68
5 ( 2%) 74.00
6 ( 2%) 76.52
7 ( 2%) 81.42
8 ( 2%) 75.21
9 ( 1%) 84.88
result accuracy by generalization:
1 (22.45%) 84.55
2 (22.96%) 78.49
3 (22.53%) 76.00
4 (15.82%) 57.81
5 (16.24%) 50.75
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
(8-0)/9 (8-00/9 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 1 None
0/(0+3) 0/(0+31 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
(0+7)*4 (0-71*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 None
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
(8+5)*8 (8+2(*8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 104 80
val (Perception Acc=93.86, Head Acc=100.00, Result Acc=71.51)
Epoch time: 0m 52s
------------------------------
Epoch 55/99 (max_len=11, data=4683)
Train acc: 99.29 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1326), (2, 1327), (3, 1365), (4, 1312), (5, 1286), (6, 1282), (7, 1381), (8, 1258), (9, 1272), (10, 2210), (11, 2174), (12, 1918), (13, 1975), (14, 2485), (15, 1311)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9670360443253191, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 56/99 (max_len=11, data=4683)
Train acc: 99.35 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1327), (2, 1327), (3, 1365), (4, 1311), (5, 1286), (6, 1282), (7, 1381), (8, 1258), (9, 1272), (10, 2209), (11, 2175), (12, 1918), (13, 1975), (14, 2480), (15, 1316)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9670760491258951, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 57/99 (max_len=11, data=4683)
Train acc: 99.51 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1327), (2, 1327), (3, 1364), (4, 1310), (5, 1286), (6, 1282), (7, 1383), (8, 1259), (9, 1271), (10, 2209), (11, 2175), (12, 1918), (13, 1975), (14, 2480), (15, 1316)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9671960635276233, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 58/99 (max_len=11, data=4683)
Train acc: 99.51 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1326), (2, 1327), (3, 1364), (4, 1313), (5, 1286), (6, 1282), (7, 1381), (8, 1259), (9, 1271), (10, 2209), (11, 2175), (12, 1918), (13, 1975), (14, 2478), (15, 1318)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9672760731287755, 3 epochs, take 32 sec.
Epoch time: 0m 36s
------------------------------
Epoch 59/99 (max_len=11, data=4683)
Train acc: 99.52 (abduce 100.00)
Hit samples:  4683  Ave length:  5.34
Symbols:  16 [(0, 1115), (1, 1326), (2, 1327), (3, 1364), (4, 1313), (5, 1286), (6, 1282), (7, 1381), (8, 1259), (9, 1271), (10, 2209), (11, 2175), (12, 1918), (13, 1975), (14, 2478), (15, 1318)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 4683 samples for 100 iterations, 0.9672760731287755, 3 epochs, take 32 sec.
              precision    recall  f1-score   support

           0       0.99      1.00      0.99      4016
           1       0.87      0.93      0.90      5142
           2       0.97      0.98      0.98      5321
           3       0.99      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.75      0.97      0.84     21081
           )       0.98      0.67      0.79     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.96    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  337    1    0    0    0    0    1    0    0    0    0    0    1    11    8
2    0    0  369    1    0    0    0    0    1    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  363    0    0    3    0    2    0    1    0    0     0    0
5    0    0    2    0    0  375    0    0    0    0    0    0    0    0     2    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    0    0    0    1    0    0    0    0    0  926    3    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  754    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    2   31    0    0    0    0    2    0    0    0    2    2    0    0  1442    6
)    0   16    0    0    0    0    0    0    0    0    0    0    0   12   469  989
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 95.20
9 ( 4%) 88.94
11 ( 3%) 88.07
13 ( 4%) 88.89
15 ( 4%) 83.66
17 ( 4%) 83.50
19 ( 4%) 80.88
21 ( 4%) 87.88
23 ( 4%) 77.56
25 ( 4%) 74.50
27 ( 4%) 81.77
29 ( 3%) 80.10
31 ( 3%) 72.62
33 ( 2%) 75.00
35 ( 2%) 65.07
37 ( 2%) 68.38
39 ( 3%) 69.08
41 ( 3%) 71.14
43 ( 2%) 65.22
45 ( 2%) 58.93
47 ( 2%) 65.15
49 ( 2%) 64.79
51 ( 2%) 63.64
53 ( 2%) 64.93
55 ( 2%) 56.30
57 ( 2%) 56.64
59 ( 2%) 49.53
61 ( 1%) 60.94
63 ( 0%) 51.43
65 ( 0%) 77.78
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 74.75
) (91%) 74.75
* (87%) 74.75
+ (84%) 74.08
- (77%) 73.39
/ (76%) 73.24
0 (52%) 72.70
1 (60%) 69.81
2 (61%) 73.26
3 (62%) 73.02
4 (61%) 72.74
5 (62%) 73.21
6 (62%) 73.44
7 (63%) 73.56
8 (64%) 72.93
9 (63%) 73.79
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 78.95
1 (10%) 72.28
2 ( 4%) 80.81
3 ( 2%) 80.00
4 ( 2%) 76.69
5 ( 2%) 78.00
6 ( 2%) 80.87
7 ( 2%) 85.84
8 ( 2%) 76.92
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 86.36
2 (22.96%) 82.58
3 (22.53%) 81.43
4 (15.82%) 66.19
5 (16.24%) 59.05
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
0/(0+3) 0/(0+31 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
7/1/7 7/(/7 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 1 None
5*(9-5) 5*(9-() [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 None
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
2*(9*3) 2*19*3) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 54 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
(8+5)*8 (8+2(*8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 104 80
val (Perception Acc=93.95, Head Acc=100.00, Result Acc=76.76)
Epoch time: 0m 52s
------------------------------
Epoch 60/99 (max_len=15, data=6058)
Train acc: 96.41 (abduce 99.83)
Hit samples:  6048  Ave length:  7.3
Symbols:  16 [(0, 1752), (1, 2127), (2, 2168), (3, 2231), (4, 2096), (5, 2082), (6, 2057), (7, 2186), (8, 2014), (9, 2055), (10, 3917), (11, 3883), (12, 3414), (13, 3561), (14, 5585), (15, 2998)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6048 samples for 100 iterations, 0.9612246747949055, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 61/99 (max_len=15, data=6058)
Train acc: 96.82 (abduce 99.85)
Hit samples:  6049  Ave length:  7.3
Symbols:  16 [(0, 1752), (1, 2135), (2, 2177), (3, 2224), (4, 2096), (5, 2087), (6, 2056), (7, 2187), (8, 2020), (9, 2053), (10, 3925), (11, 3880), (12, 3417), (13, 3556), (14, 5585), (15, 2995)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6049 samples for 100 iterations, 0.9614225846641749, 2 epochs, take 38 sec.
Epoch time: 0m 45s
------------------------------
Epoch 62/99 (max_len=15, data=6058)
Train acc: 98.06 (abduce 99.97)
Hit samples:  6056  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2133), (2, 2184), (3, 2222), (4, 2102), (5, 2094), (6, 2063), (7, 2186), (8, 2029), (9, 2058), (10, 3933), (11, 3888), (12, 3424), (13, 3571), (14, 5601), (15, 3002)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6056 samples for 100 iterations, 0.9616879887889336, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 63/99 (max_len=15, data=6058)
Train acc: 98.55 (abduce 99.97)
Hit samples:  6056  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2130), (2, 2182), (3, 2216), (4, 2102), (5, 2094), (6, 2065), (7, 2191), (8, 2032), (9, 2059), (10, 3934), (11, 3888), (12, 3424), (13, 3567), (14, 5595), (15, 3011)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6056 samples for 100 iterations, 0.9619818272230007, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 64/99 (max_len=15, data=6058)
Train acc: 98.84 (abduce 99.97)
Hit samples:  6056  Ave length:  7.31
Symbols:  16 [(0, 1751), (1, 2130), (2, 2182), (3, 2222), (4, 2098), (5, 2094), (6, 2065), (7, 2194), (8, 2028), (9, 2059), (10, 3933), (11, 3889), (12, 3424), (13, 3568), (14, 5588), (15, 3017)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6056 samples for 100 iterations, 0.961891415397134, 2 epochs, take 38 sec.
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4016
           1       0.87      0.94      0.90      5142
           2       0.98      0.99      0.98      5321
           3       0.99      0.99      0.99      5241
           4       1.00      0.98      0.99      5279
           5       1.00      0.99      1.00      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       1.00      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.99      1.00      0.99      9876
           (       0.75      0.97      0.85     21081
           )       0.98      0.67      0.80     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  342    1    0    0    0    0    1    0    0    0    0    0    0     8    8
2    0    0  370    0    0    0    0    0    1    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    1  363    0    0    3    0    0    0    1    0    0     0    0
5    0    2    0    0    0  377    0    0    0    0    0    0    0    0     0    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    0    0    0    0    0    0    0    0    0  925    4    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  755    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   31    0    0    0    0    2    0    0    0    0    2    0    0  1442   10
)    0   14    0    0    0    0    0    0    0    0    0    0    0    8   465  999
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 97.67
7 ( 4%) 96.51
9 ( 4%) 90.95
11 ( 3%) 89.20
13 ( 4%) 88.89
15 ( 4%) 85.15
17 ( 4%) 86.89
19 ( 4%) 81.86
21 ( 4%) 88.38
23 ( 4%) 81.95
25 ( 4%) 76.50
27 ( 4%) 80.30
29 ( 3%) 80.63
31 ( 3%) 76.19
33 ( 2%) 78.57
35 ( 2%) 67.81
37 ( 2%) 73.50
39 ( 3%) 71.05
41 ( 3%) 71.14
43 ( 2%) 75.36
45 ( 2%) 66.07
47 ( 2%) 61.36
49 ( 2%) 67.61
51 ( 2%) 68.94
53 ( 2%) 71.64
55 ( 2%) 62.18
57 ( 2%) 62.94
59 ( 2%) 54.21
61 ( 1%) 68.75
63 ( 0%) 48.57
65 ( 0%) 77.78
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 77.41
) (91%) 77.41
* (87%) 77.31
+ (84%) 76.60
- (77%) 76.51
/ (76%) 76.25
0 (52%) 75.23
1 (60%) 73.23
2 (61%) 76.28
3 (62%) 76.49
4 (61%) 75.32
5 (62%) 75.81
6 (62%) 76.22
7 (63%) 76.33
8 (64%) 75.76
9 (63%) 76.37
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 82.19
1 (10%) 76.40
2 ( 4%) 82.32
3 ( 2%) 80.00
4 ( 2%) 81.95
5 ( 2%) 83.00
6 ( 2%) 82.61
7 ( 2%) 84.96
8 ( 2%) 80.34
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 89.27
2 (22.96%) 83.91
3 (22.53%) 81.97
4 (15.82%) 69.42
5 (16.24%) 64.07
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
4+(1+8) 7+(1+8( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 13 16
0/(0+3) 0/(0+31 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
5*(9-5) 5*(9-1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 40
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
1+1/6 0+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 1
1+3+4 1+3+3 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 8 7
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
8/1-(6+1) 3/1-(6+1) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 1 0
val (Perception Acc=94.11, Head Acc=100.00, Result Acc=79.16)
Epoch time: 1m 1s
------------------------------
Epoch 65/99 (max_len=15, data=6058)
Train acc: 98.86 (abduce 99.95)
Hit samples:  6055  Ave length:  7.3
Symbols:  16 [(0, 1750), (1, 2130), (2, 2181), (3, 2221), (4, 2097), (5, 2093), (6, 2066), (7, 2192), (8, 2030), (9, 2058), (10, 3932), (11, 3887), (12, 3423), (13, 3567), (14, 5583), (15, 3019)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6055 samples for 100 iterations, 0.961834995138936, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 66/99 (max_len=15, data=6058)
Train acc: 98.93 (abduce 99.97)
Hit samples:  6056  Ave length:  7.31
Symbols:  16 [(0, 1751), (1, 2130), (2, 2185), (3, 2221), (4, 2098), (5, 2092), (6, 2066), (7, 2194), (8, 2029), (9, 2057), (10, 3934), (11, 3887), (12, 3424), (13, 3568), (14, 5587), (15, 3019)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6056 samples for 100 iterations, 0.9618688124406672, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 67/99 (max_len=15, data=6058)
Train acc: 99.04 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2131), (2, 2184), (3, 2219), (4, 2100), (5, 2093), (6, 2070), (7, 2191), (8, 2031), (9, 2057), (10, 3936), (11, 3888), (12, 3425), (13, 3569), (14, 5586), (15, 3023)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.962060784092193, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 68/99 (max_len=15, data=6058)
Train acc: 99.12 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2130), (2, 2184), (3, 2222), (4, 2097), (5, 2093), (6, 2072), (7, 2191), (8, 2029), (9, 2058), (10, 3937), (11, 3889), (12, 3425), (13, 3568), (14, 5585), (15, 3023)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9619703988249916, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 69/99 (max_len=15, data=6058)
Train acc: 99.23 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1753), (1, 2129), (2, 2184), (3, 2221), (4, 2099), (5, 2093), (6, 2071), (7, 2190), (8, 2030), (9, 2058), (10, 3938), (11, 3887), (12, 3425), (13, 3568), (14, 5585), (15, 3024)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9620155914585923, 2 epochs, take 38 sec.
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4016
           1       0.88      0.94      0.91      5142
           2       0.98      0.99      0.98      5321
           3       1.00      0.99      1.00      5241
           4       1.00      0.98      0.99      5279
           5       1.00      0.99      1.00      5383
           6       0.99      1.00      1.00      5427
           7       0.99      0.99      0.99      5462
           8       1.00      0.99      1.00      5453
           9       1.00      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.76      0.97      0.85     21081
           )       0.98      0.67      0.80     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  341    1    0    0    0    0    0    0    0    0    0    0    0     9    7
2    0    0  371    0    0    0    0    0    0    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  366    0    0    0    0    0    0    1    0    0     0    0
5    0    2    0    0    0  377    0    0    0    0    0    0    0    0     0    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0    0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    0    0    0    0    0    0    0    0    0  926    4    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   27    0    0    0    0    2    0    0    0    2    2    0    0  1444   10
)    0   16    0    0    0    0    0    0    0    0    0    0    0   12   459  999
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 96.94
9 ( 4%) 91.46
11 ( 3%) 90.91
13 ( 4%) 91.67
15 ( 4%) 85.15
17 ( 4%) 88.35
19 ( 4%) 83.33
21 ( 4%) 89.39
23 ( 4%) 84.88
25 ( 4%) 77.00
27 ( 4%) 82.76
29 ( 3%) 83.25
31 ( 3%) 79.76
33 ( 2%) 79.29
35 ( 2%) 65.75
37 ( 2%) 76.07
39 ( 3%) 71.71
41 ( 3%) 75.84
43 ( 2%) 77.54
45 ( 2%) 64.29
47 ( 2%) 65.91
49 ( 2%) 67.61
51 ( 2%) 71.97
53 ( 2%) 71.64
55 ( 2%) 62.18
57 ( 2%) 67.13
59 ( 2%) 57.94
61 ( 1%) 70.31
63 ( 0%) 48.57
65 ( 0%) 88.89
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 79.01
) (91%) 79.01
* (87%) 78.91
+ (84%) 78.36
- (77%) 78.08
/ (76%) 77.76
0 (52%) 77.19
1 (60%) 74.87
2 (61%) 77.71
3 (62%) 77.84
4 (61%) 77.35
5 (62%) 77.38
6 (62%) 78.08
7 (63%) 77.98
8 (64%) 77.48
9 (63%) 78.16
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 82.76
1 (10%) 77.53
2 ( 4%) 81.31
3 ( 2%) 80.74
4 ( 2%) 81.95
5 ( 2%) 85.00
6 ( 2%) 85.22
7 ( 2%) 86.73
8 ( 2%) 82.05
9 ( 1%) 88.37
result accuracy by generalization:
1 (22.45%) 89.82
2 (22.96%) 85.60
3 (22.53%) 83.70
4 (15.82%) 71.10
5 (16.24%) 66.33
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
0/(0+3) 0/(0+31 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
5*(9-5) 5*(9-1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 40
(0+7)*4 (0-71*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 None
1+1/6 0+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 1
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
1*(6+2)-6 )*(6+2(-6 [1, 7, 4, 4, 1, 4, 4, -1, 7] [1, 7, 4, 4, 1, 4, 4, -1, 7] 2 None
(3-3)*(2-2) 13-3(*(2-2) [2, 2, 5, 2, 2, -1, 8, 8, 5, 8, 8] [2, 2, 5, 2, 2, -1, 8, 8, 5, 8, 8] 0 None
val (Perception Acc=94.21, Head Acc=100.00, Result Acc=80.69)
Epoch time: 1m 0s
------------------------------
Epoch 70/99 (max_len=15, data=6058)
Train acc: 99.22 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1753), (1, 2129), (2, 2184), (3, 2223), (4, 2096), (5, 2094), (6, 2072), (7, 2189), (8, 2028), (9, 2060), (10, 3939), (11, 3886), (12, 3425), (13, 3567), (14, 5586), (15, 3024)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.962128573042594, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 71/99 (max_len=15, data=6058)
Train acc: 99.22 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1753), (1, 2129), (2, 2184), (3, 2222), (4, 2096), (5, 2094), (6, 2072), (7, 2191), (8, 2029), (9, 2058), (10, 3939), (11, 3887), (12, 3425), (13, 3567), (14, 5585), (15, 3024)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9621737656761947, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 72/99 (max_len=15, data=6058)
Train acc: 99.12 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2129), (2, 2185), (3, 2223), (4, 2099), (5, 2093), (6, 2072), (7, 2189), (8, 2028), (9, 2058), (10, 3938), (11, 3888), (12, 3425), (13, 3567), (14, 5586), (15, 3023)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9621059767257937, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 73/99 (max_len=15, data=6058)
Train acc: 99.14 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2129), (2, 2183), (3, 2223), (4, 2098), (5, 2094), (6, 2072), (7, 2191), (8, 2029), (9, 2057), (10, 3941), (11, 3886), (12, 3425), (13, 3567), (14, 5585), (15, 3023)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9621059767257937, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 74/99 (max_len=15, data=6058)
Train acc: 98.45 (abduce 99.97)
Hit samples:  6056  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2124), (2, 2186), (3, 2220), (4, 2098), (5, 2092), (6, 2070), (7, 2190), (8, 2029), (9, 2059), (10, 3939), (11, 3886), (12, 3422), (13, 3559), (14, 5612), (15, 3002)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6056 samples for 100 iterations, 0.9613698010849909, 2 epochs, take 38 sec.
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4016
           1       0.84      0.96      0.89      5142
           2       0.97      0.99      0.98      5321
           3       0.99      0.99      0.99      5241
           4       1.00      0.98      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       1.00      0.99      0.99      5462
           8       1.00      0.99      1.00      5453
           9       1.00      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.76      0.95      0.84     21081
           )       0.98      0.68      0.80     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  347    1    0    0    0    0    0    0    0    0    0    0    0     5     6
2    0    0  371    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0     0
4    0    0    0    1  365    0    0    0    0    0    0    1    0    0     0     0
5    0    2    2    0    0  375    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    2    0    0    0    0  382    0    0    0    0    0    0     0     0
8    0    0    2    0    0    0    0    0  382    0    0    0    0    0     0     0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  926    4    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    0   48    0    0    0    0    2    0    0    0    2    2    0    0  1417    16
)    0   16    0    0    0    0    0    0    0    0    0    0    0   10   446  1014
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 96.90
7 ( 4%) 94.76
9 ( 4%) 89.95
11 ( 3%) 91.48
13 ( 4%) 90.74
15 ( 4%) 85.64
17 ( 4%) 85.44
19 ( 4%) 82.84
21 ( 4%) 86.87
23 ( 4%) 79.51
25 ( 4%) 76.00
27 ( 4%) 76.35
29 ( 3%) 79.58
31 ( 3%) 75.60
33 ( 2%) 72.86
35 ( 2%) 66.44
37 ( 2%) 73.50
39 ( 3%) 66.45
41 ( 3%) 70.47
43 ( 2%) 72.46
45 ( 2%) 64.29
47 ( 2%) 62.12
49 ( 2%) 64.79
51 ( 2%) 64.39
53 ( 2%) 70.15
55 ( 2%) 55.46
57 ( 2%) 63.64
59 ( 2%) 52.34
61 ( 1%) 65.62
63 ( 0%) 48.57
65 ( 0%) 44.44
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 75.87
) (91%) 75.87
* (87%) 75.84
+ (84%) 75.07
- (77%) 74.86
/ (76%) 74.33
0 (52%) 73.52
1 (60%) 72.29
2 (61%) 74.15
3 (62%) 74.30
4 (61%) 73.63
5 (62%) 74.48
6 (62%) 74.32
7 (63%) 74.36
8 (64%) 74.71
9 (63%) 74.84
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 79.24
1 (10%) 75.47
2 ( 4%) 79.29
3 ( 2%) 77.04
4 ( 2%) 78.20
5 ( 2%) 83.00
6 ( 2%) 83.48
7 ( 2%) 83.19
8 ( 2%) 82.05
9 ( 1%) 82.56
result accuracy by generalization:
1 (22.45%) 87.36
2 (22.96%) 83.20
3 (22.53%) 81.97
4 (15.82%) 64.90
5 (16.24%) 63.57
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
4*(0-0) 4*10-0( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
(4+8)/8 14+8)/8 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 2 None
0*(8*8) 0*18*8) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
0/(0+3) 0/(0+31 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
(4+3)*7 (4+31*7 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 49 None
5*(9-5) 5*(9-1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 40
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
1+1/6 0+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 1
1+3+4 1+3+3 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 8 7
val (Perception Acc=94.12, Head Acc=100.00, Result Acc=77.78)
Epoch time: 1m 1s
------------------------------
Epoch 75/99 (max_len=15, data=6058)
Train acc: 98.27 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2126), (2, 2185), (3, 2224), (4, 2100), (5, 2093), (6, 2071), (7, 2194), (8, 2028), (9, 2055), (10, 3939), (11, 3888), (12, 3425), (13, 3565), (14, 5578), (15, 3032)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9617218393401875, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 76/99 (max_len=15, data=6058)
Train acc: 98.81 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2126), (2, 2184), (3, 2222), (4, 2103), (5, 2094), (6, 2071), (7, 2189), (8, 2030), (9, 2057), (10, 3939), (11, 3887), (12, 3425), (13, 3564), (14, 5576), (15, 3036)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9617670319737883, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 77/99 (max_len=15, data=6058)
Train acc: 99.37 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2126), (2, 2184), (3, 2224), (4, 2101), (5, 2094), (6, 2072), (7, 2190), (8, 2029), (9, 2056), (10, 3939), (11, 3887), (12, 3425), (13, 3564), (14, 5570), (15, 3042)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9619026098745904, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 78/99 (max_len=15, data=6058)
Train acc: 99.22 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2126), (2, 2184), (3, 2224), (4, 2101), (5, 2094), (6, 2072), (7, 2190), (8, 2028), (9, 2057), (10, 3939), (11, 3885), (12, 3425), (13, 3564), (14, 5566), (15, 3048)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9620381877753926, 2 epochs, take 38 sec.
Epoch time: 0m 44s
------------------------------
Epoch 79/99 (max_len=15, data=6058)
Train acc: 99.28 (abduce 99.98)
Hit samples:  6057  Ave length:  7.31
Symbols:  16 [(0, 1752), (1, 2127), (2, 2184), (3, 2224), (4, 2098), (5, 2094), (6, 2072), (7, 2191), (8, 2028), (9, 2058), (10, 3939), (11, 3886), (12, 3425), (13, 3564), (14, 5566), (15, 3047)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 6057 samples for 100 iterations, 0.9619478025081911, 2 epochs, take 38 sec.
              precision    recall  f1-score   support

           0       1.00      1.00      1.00      4016
           1       0.87      0.95      0.91      5142
           2       0.98      0.99      0.98      5321
           3       0.99      0.99      0.99      5241
           4       1.00      0.98      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       1.00      0.99      0.99      5462
           8       1.00      0.99      0.99      5453
           9       0.99      1.00      1.00      5476
           +       1.00      0.99      1.00     13199
           -       0.99      1.00      0.99     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.75      0.97      0.85     21081
           )       0.98      0.67      0.80     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (    )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0    0
1    0  343    1    0    0    0    0    0    0    0    0    0    0    0     8    6
2    0    0  371    0    0    0    0    0    0    0    0    0    0    0     0    0
3    0    0    1  367    0    0    0    0    0    0    0    0    0    0     0    0
4    0    0    0    0  366    0    0    0    0    0    0    1    0    0     0    0
5    0    2    0    0    0  375    0    0    0    2    0    0    0    0     0    0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0    0
7    0    0    2    0    0    0    0  380    0    0    2    0    0    0     0    0
8    0    0    2    2    0    0    0    0  379    0    0    0    0    0     0    0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0    0
+    0    0    0    0    0    0    0    0    0    0  925    4    0    0     0    0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0    0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0    0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0    0
(    0   31    0    0    0    0    2    0    0    0    0    2    0    0  1440   12
)    0   14    0    0    0    0    0    0    0    0    0    0    0   12   465  995
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 97.67
7 ( 4%) 96.51
9 ( 4%) 89.95
11 ( 3%) 89.20
13 ( 4%) 89.81
15 ( 4%) 85.15
17 ( 4%) 88.35
19 ( 4%) 81.86
21 ( 4%) 87.88
23 ( 4%) 82.44
25 ( 4%) 78.00
27 ( 4%) 80.79
29 ( 3%) 80.10
31 ( 3%) 76.19
33 ( 2%) 77.14
35 ( 2%) 69.18
37 ( 2%) 75.21
39 ( 3%) 70.39
41 ( 3%) 71.14
43 ( 2%) 75.36
45 ( 2%) 61.61
47 ( 2%) 65.91
49 ( 2%) 66.90
51 ( 2%) 68.94
53 ( 2%) 67.91
55 ( 2%) 62.18
57 ( 2%) 65.03
59 ( 2%) 57.01
61 ( 1%) 70.31
63 ( 0%) 48.57
65 ( 0%) 66.67
67 ( 0%) 66.67
result accuracy by symbol:
( (91%) 77.58
) (91%) 77.58
* (87%) 77.47
+ (84%) 76.92
- (77%) 76.67
/ (76%) 76.17
0 (52%) 75.39
1 (60%) 74.10
2 (61%) 76.48
3 (62%) 76.43
4 (61%) 75.56
5 (62%) 75.85
6 (62%) 76.54
7 (63%) 76.04
8 (64%) 75.73
9 (63%) 76.88
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 81.33
1 (10%) 77.15
2 ( 4%) 83.33
3 ( 2%) 81.48
4 ( 2%) 81.95
5 ( 2%) 80.00
6 ( 2%) 81.74
7 ( 2%) 84.07
8 ( 2%) 82.91
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 89.09
2 (22.96%) 84.27
3 (22.53%) 82.52
4 (15.82%) 69.29
5 (16.24%) 64.20
error cases:
4*9+7 4*9+2 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 43 38
4*(0-0) 4*10-0( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
5*(9-5) 5*(9-1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 40
(0+7)*4 (0-7)*4 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 28 0
1+1/6 0+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 1
8/2/1 8/2/( [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 4 None
7*(9*8) 7*(9*2) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 504 126
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
7*(9*4) +*(9*4( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 252 None
8/1-(6+1) 3/1-(6+1) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 1 0
val (Perception Acc=94.07, Head Acc=100.00, Result Acc=79.33)
Epoch time: 1m 1s
------------------------------
Epoch 80/99 (max_len=inf, data=11170)
Train acc: 92.46 (abduce 99.77)
Hit samples:  11144  Ave length:  14.84
Symbols:  16 [(0, 5633), (1, 7111), (2, 6981), (3, 6901), (4, 6714), (5, 6696), (6, 6553), (7, 6675), (8, 6559), (9, 6472), (10, 14830), (11, 14418), (12, 12836), (13, 13146), (14, 28563), (15, 15306)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11144 samples for 100 iterations, 0.9494479848120246, 1 epochs, take 70 sec.
Epoch time: 1m 36s
------------------------------
Epoch 81/99 (max_len=inf, data=11170)
Train acc: 89.51 (abduce 99.62)
Hit samples:  11128  Ave length:  14.83
Symbols:  16 [(0, 5630), (1, 7127), (2, 6975), (3, 6882), (4, 6687), (5, 6705), (6, 6527), (7, 6689), (8, 6528), (9, 6483), (10, 14801), (11, 14371), (12, 12792), (13, 13154), (14, 28385), (15, 15336)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11128 samples for 100 iterations, 0.9501429679170301, 1 epochs, take 70 sec.
Epoch time: 1m 35s
------------------------------
Epoch 82/99 (max_len=inf, data=11170)
Train acc: 88.80 (abduce 99.70)
Hit samples:  11136  Ave length:  14.84
Symbols:  16 [(0, 5648), (1, 7167), (2, 6993), (3, 6857), (4, 6689), (5, 6717), (6, 6541), (7, 6701), (8, 6570), (9, 6492), (10, 14823), (11, 14376), (12, 12814), (13, 13160), (14, 28288), (15, 15458)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 141), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11136 samples for 100 iterations, 0.9505184701199075, 1 epochs, take 70 sec.
Epoch time: 1m 34s
------------------------------
Epoch 83/99 (max_len=inf, data=11170)
Train acc: 90.84 (abduce 99.81)
Hit samples:  11149  Ave length:  14.85
Symbols:  16 [(0, 5669), (1, 7128), (2, 6981), (3, 6869), (4, 6684), (5, 6716), (6, 6541), (7, 6713), (8, 6620), (9, 6498), (10, 14858), (11, 14408), (12, 12837), (13, 13187), (14, 28455), (15, 15429)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11149 samples for 100 iterations, 0.9504991153007676, 1 epochs, take 71 sec.
Epoch time: 1m 33s
------------------------------
Epoch 84/99 (max_len=inf, data=11170)
Train acc: 91.14 (abduce 99.82)
Hit samples:  11150  Ave length:  14.85
Symbols:  16 [(0, 5677), (1, 7128), (2, 6959), (3, 6871), (4, 6708), (5, 6718), (6, 6534), (7, 6701), (8, 6616), (9, 6493), (10, 14878), (11, 14418), (12, 12837), (13, 13209), (14, 28295), (15, 15516)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 379), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11150 samples for 100 iterations, 0.951080588071854, 1 epochs, take 71 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.90      0.97      0.93      5142
           2       1.00      0.99      0.99      5321
           3       0.99      0.99      0.99      5241
           4       1.00      0.99      0.99      5279
           5       1.00      0.99      1.00      5383
           6       1.00      1.00      1.00      5427
           7       1.00      1.00      1.00      5462
           8       1.00      1.00      1.00      5453
           9       1.00      1.00      1.00      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      1.00     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.75      0.96      0.84     21081
           )       0.98      0.68      0.80     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  353    0    0    0    0    0    0    0    0    0    0    0    0     2     5
2    0    0  372    1    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  367    0    0    0    0    1    0    0    0    0    0     0     0
4    0    0    0    0  368    0    0    0    0    0    0    1    0    0     0     0
5    0    2    0    0    0  377    0    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  930    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    4   31    0    0    0    0    0    0    0    0    2    2    0    6  1425    16
)    2    6    0    0    0    0    0    0    0    0    0    0    0   10   463  1006
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 98.45
7 ( 4%) 97.38
9 ( 4%) 94.47
11 ( 3%) 92.61
13 ( 4%) 90.28
15 ( 4%) 90.59
17 ( 4%) 92.72
19 ( 4%) 88.73
21 ( 4%) 90.91
23 ( 4%) 89.27
25 ( 4%) 86.00
27 ( 4%) 84.24
29 ( 3%) 87.43
31 ( 3%) 78.57
33 ( 2%) 84.29
35 ( 2%) 82.19
37 ( 2%) 80.34
39 ( 3%) 77.63
41 ( 3%) 78.52
43 ( 2%) 83.33
45 ( 2%) 74.11
47 ( 2%) 75.76
49 ( 2%) 75.35
51 ( 2%) 72.73
53 ( 2%) 73.88
55 ( 2%) 70.59
57 ( 2%) 79.72
59 ( 2%) 59.81
61 ( 1%) 71.88
63 ( 0%) 68.57
65 ( 0%) 66.67
67 ( 0%) 100.00
result accuracy by symbol:
( (91%) 83.68
) (91%) 83.68
* (87%) 83.72
+ (84%) 83.19
- (77%) 82.78
/ (76%) 82.53
0 (52%) 82.11
1 (60%) 81.43
2 (61%) 82.43
3 (62%) 83.18
4 (61%) 81.79
5 (62%) 82.03
6 (62%) 82.42
7 (63%) 83.31
8 (64%) 82.58
9 (63%) 82.63
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 85.71
1 (10%) 83.52
2 ( 4%) 85.35
3 ( 2%) 86.67
4 ( 2%) 86.47
5 ( 2%) 90.00
6 ( 2%) 89.57
7 ( 2%) 88.50
8 ( 2%) 88.03
9 ( 1%) 90.70
result accuracy by generalization:
1 (22.45%) 92.27
2 (22.96%) 89.24
3 (22.53%) 87.77
4 (15.82%) 76.39
5 (16.24%) 73.37
error cases:
4*(0-0) 4*10-0( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 0 None
(9-7)/3 19-7)/3 [2, 2, 5, 2, 2, -1, 5] [2, 2, 5, 2, 2, -1, 5] 1 None
5/6*3 5/6*8 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 3 8
5*(9-5) 5*(9-1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 40
1+1/6 2+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 3
5*(9*7) 5*(9*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
1*(6+2)-6 )*(6+2(-6 [1, 7, 4, 4, 1, 4, 4, -1, 7] [1, 7, 4, 4, 1, 4, 4, -1, 7] 2 None
(3-3)*(2-2) 13-3(*(2-2) [2, 2, 5, 2, 2, -1, 8, 8, 5, 8, 8] [2, 2, 5, 2, 2, -1, 8, 8, 5, 8, 8] 0 None
3*(0*9*8) 3*10*9*8) [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 0 None
4*((8+8)/6) -*((8+8)/6) [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] 12 None
val (Perception Acc=94.32, Head Acc=100.00, Result Acc=84.98)
Epoch time: 1m 50s
------------------------------
Epoch 85/99 (max_len=inf, data=11170)
Train acc: 92.62 (abduce 99.88)
Hit samples:  11157  Ave length:  14.86
Symbols:  16 [(0, 5657), (1, 7129), (2, 6957), (3, 6837), (4, 6716), (5, 6718), (6, 6550), (7, 6692), (8, 6641), (9, 6526), (10, 14898), (11, 14434), (12, 12851), (13, 13268), (14, 28239), (15, 15626)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 379), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11157 samples for 100 iterations, 0.9510555753322996, 1 epochs, take 70 sec.
Epoch time: 1m 32s
------------------------------
Epoch 86/99 (max_len=inf, data=11170)
Train acc: 93.33 (abduce 99.90)
Hit samples:  11159  Ave length:  14.86
Symbols:  16 [(0, 5664), (1, 7157), (2, 6964), (3, 6832), (4, 6707), (5, 6717), (6, 6555), (7, 6695), (8, 6642), (9, 6531), (10, 14897), (11, 14447), (12, 12857), (13, 13326), (14, 28046), (15, 15740)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11159 samples for 100 iterations, 0.9509642471512936, 1 epochs, take 71 sec.
Epoch time: 1m 33s
------------------------------
Epoch 87/99 (max_len=inf, data=11170)
Train acc: 93.06 (abduce 99.91)
Hit samples:  11160  Ave length:  14.86
Symbols:  16 [(0, 5669), (1, 7175), (2, 6969), (3, 6852), (4, 6714), (5, 6711), (6, 6558), (7, 6687), (8, 6625), (9, 6537), (10, 14890), (11, 14471), (12, 12864), (13, 13524), (14, 27481), (15, 16083)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11160 samples for 100 iterations, 0.9499909535009952, 1 epochs, take 71 sec.
Epoch time: 1m 32s
------------------------------
Epoch 88/99 (max_len=inf, data=11170)
Train acc: 93.49 (abduce 99.87)
Hit samples:  11156  Ave length:  14.86
Symbols:  16 [(0, 5677), (1, 7170), (2, 6960), (3, 6850), (4, 6721), (5, 6712), (6, 6555), (7, 6672), (8, 6626), (9, 6542), (10, 14885), (11, 14480), (12, 12864), (13, 13899), (14, 26982), (15, 16175)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11156 samples for 100 iterations, 0.9472703142908849, 1 epochs, take 71 sec.
Epoch time: 1m 32s
------------------------------
Epoch 89/99 (max_len=inf, data=11170)
Train acc: 92.12 (abduce 99.87)
Hit samples:  11156  Ave length:  14.85
Symbols:  16 [(0, 5669), (1, 7186), (2, 6960), (3, 6864), (4, 6719), (5, 6719), (6, 6553), (7, 6684), (8, 6598), (9, 6555), (10, 14885), (11, 14495), (12, 12856), (13, 14465), (14, 26283), (15, 16231)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11156 samples for 100 iterations, 0.943857785930655, 1 epochs, take 70 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.92      0.98      0.95      5142
           2       0.99      0.99      0.99      5321
           3       0.99      0.99      0.99      5241
           4       0.99      0.98      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       1.00      1.00      1.00      5462
           8       0.99      1.00      1.00      5453
           9       1.00      1.00      1.00      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      1.00     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.76      0.96      0.85     21081
           )       0.98      0.68      0.80     21081

    accuracy                           0.94    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.94      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  354    0    0    0    0    0    0    0    0    0    0    0    0     2     4
2    0    0  373    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  367    0    0    0    0    1    0    0    0    0    0     0     0
4    0    0    0    0  365    0    0    0    0    0    2    1    0    0     0     0
5    0    2    0    0    0  375    2    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  930    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    4   20    0    0    2    0    0    0    0    0    0    2    0    6  1435    16
)    2    8    0    2    0    0    0    0    0    0    0    0    0   10   452  1012
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 97.67
7 ( 4%) 97.82
9 ( 4%) 94.97
11 ( 3%) 94.89
13 ( 4%) 91.20
15 ( 4%) 89.60
17 ( 4%) 93.20
19 ( 4%) 90.69
21 ( 4%) 90.91
23 ( 4%) 88.78
25 ( 4%) 82.50
27 ( 4%) 86.21
29 ( 3%) 89.01
31 ( 3%) 77.38
33 ( 2%) 85.71
35 ( 2%) 78.08
37 ( 2%) 83.76
39 ( 3%) 79.61
41 ( 3%) 79.19
43 ( 2%) 81.16
45 ( 2%) 75.89
47 ( 2%) 78.79
49 ( 2%) 76.76
51 ( 2%) 71.97
53 ( 2%) 76.87
55 ( 2%) 70.59
57 ( 2%) 77.62
59 ( 2%) 61.68
61 ( 1%) 68.75
63 ( 0%) 71.43
65 ( 0%) 55.56
67 ( 0%) 100.00
result accuracy by symbol:
( (91%) 84.04
) (91%) 84.04
* (87%) 84.03
+ (84%) 83.43
- (77%) 83.10
/ (76%) 82.93
0 (52%) 82.42
1 (60%) 81.69
2 (61%) 83.32
3 (62%) 83.44
4 (61%) 81.96
5 (62%) 82.71
6 (62%) 82.82
7 (63%) 82.85
8 (64%) 82.52
9 (63%) 82.85
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 85.62
1 (10%) 83.90
2 ( 4%) 89.39
3 ( 2%) 85.19
4 ( 2%) 87.97
5 ( 2%) 86.00
6 ( 2%) 92.17
7 ( 2%) 89.38
8 ( 2%) 87.18
9 ( 1%) 90.70
result accuracy by generalization:
1 (22.45%) 92.18
2 (22.96%) 89.87
3 (22.53%) 87.86
4 (15.82%) 76.90
5 (16.24%) 73.99
error cases:
5+2/6 6+2/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 6 7
6+(2-1) 6+(2-11 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 7 None
5/6*3 5/6*8 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 3 8
5*(9-5) 5*(9-1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 40
1+1/6 2+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 3
9*(4*9) 9*(+*9) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 324 None
5*(9*7) 5*(9*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
3*(0*9*8) 3*10*9*8) [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 0 None
4*((8+8)/6) -*((8+8)/6) [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] 12 None
(2+9)/7-2 02+9(/7-2 [2, 2, 5, 2, 2, 7, 5, -1, 7] [2, 2, 5, 2, 2, 7, 5, -1, 7] 0 None
val (Perception Acc=94.45, Head Acc=100.00, Result Acc=85.31)
Epoch time: 1m 49s
------------------------------
Epoch 90/99 (max_len=inf, data=11170)
Train acc: 92.89 (abduce 99.90)
Hit samples:  11159  Ave length:  14.85
Symbols:  16 [(0, 5682), (1, 7187), (2, 6962), (3, 6878), (4, 6720), (5, 6720), (6, 6566), (7, 6685), (8, 6602), (9, 6545), (10, 14886), (11, 14578), (12, 12853), (13, 15204), (14, 24852), (15, 16839)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11159 samples for 100 iterations, 0.9378374628225316, 1 epochs, take 70 sec.
Epoch time: 1m 32s
------------------------------
Epoch 91/99 (max_len=inf, data=11170)
Train acc: 93.34 (abduce 99.90)
Hit samples:  11159  Ave length:  14.86
Symbols:  16 [(0, 5677), (1, 7186), (2, 6956), (3, 6883), (4, 6712), (5, 6718), (6, 6557), (7, 6675), (8, 6616), (9, 6545), (10, 14892), (11, 14593), (12, 12859), (13, 15529), (14, 24116), (15, 17263)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11159 samples for 100 iterations, 0.9356605560481852, 1 epochs, take 70 sec.
Epoch time: 1m 32s
------------------------------
Epoch 92/99 (max_len=inf, data=11170)
Train acc: 92.51 (abduce 99.88)
Hit samples:  11157  Ave length:  14.85
Symbols:  16 [(0, 5704), (1, 7215), (2, 6980), (3, 6878), (4, 6708), (5, 6722), (6, 6560), (7, 6693), (8, 6594), (9, 6524), (10, 14891), (11, 14680), (12, 12861), (13, 16156), (14, 22677), (15, 17882)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11157 samples for 100 iterations, 0.9308432644441093, 1 epochs, take 70 sec.
Epoch time: 1m 33s
------------------------------
Epoch 93/99 (max_len=inf, data=11170)
Train acc: 92.74 (abduce 99.85)
Hit samples:  11153  Ave length:  14.85
Symbols:  16 [(0, 5692), (1, 7231), (2, 6959), (3, 6880), (4, 6718), (5, 6707), (6, 6555), (7, 6683), (8, 6598), (9, 6520), (10, 14866), (11, 14732), (12, 12864), (13, 17148), (14, 21236), (15, 18246)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11153 samples for 100 iterations, 0.9256678842032179, 1 epochs, take 70 sec.
Epoch time: 1m 32s
------------------------------
Epoch 94/99 (max_len=inf, data=11170)
Train acc: 93.20 (abduce 99.91)
Hit samples:  11160  Ave length:  14.86
Symbols:  16 [(0, 5693), (1, 7232), (2, 6971), (3, 6884), (4, 6721), (5, 6707), (6, 6565), (7, 6680), (8, 6605), (9, 6530), (10, 14903), (11, 14767), (12, 12875), (13, 17640), (14, 20432), (15, 18621)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11160 samples for 100 iterations, 0.9238478887508593, 1 epochs, take 70 sec.
              precision    recall  f1-score   support

           0       0.98      1.00      0.99      4016
           1       0.93      0.97      0.95      5142
           2       0.99      1.00      0.99      5321
           3       1.00      0.99      0.99      5241
           4       1.00      0.99      0.99      5279
           5       1.00      0.99      0.99      5383
           6       0.99      1.00      1.00      5427
           7       0.99      1.00      1.00      5462
           8       0.99      1.00      1.00      5453
           9       1.00      1.00      1.00      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      1.00     10734
           *       1.00      1.00      1.00     13491
           /       0.95      1.00      0.97      9876
           (       0.77      0.96      0.86     21081
           )       0.98      0.70      0.81     21081

    accuracy                           0.95    141662
   macro avg       0.97      0.97      0.97    141662
weighted avg       0.95      0.95      0.94    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  352    0    0    0    0    0    1    0    0    0    0    0    0     2     3
2    0    0  374    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  366    0    0    0    0    1    0    0    0    0    0     0     0
4    0    0    0    0  367    0    0    0    0    0    0    1    0    0     0     0
5    0    2    0    0    0  375    2    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  928    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    6   16    0    0    0    0    0    0    0    0    2    2    0   16  1429    14
)    0    8    0    0    0    0    0    0    0    0    0    0    0   20   423  1035
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 96.90
7 ( 4%) 98.69
9 ( 4%) 93.97
11 ( 3%) 94.89
13 ( 4%) 93.06
15 ( 4%) 91.58
17 ( 4%) 95.15
19 ( 4%) 90.20
21 ( 4%) 91.92
23 ( 4%) 90.73
25 ( 4%) 86.00
27 ( 4%) 88.67
29 ( 3%) 87.96
31 ( 3%) 82.74
33 ( 2%) 87.86
35 ( 2%) 80.82
37 ( 2%) 84.62
39 ( 3%) 80.92
41 ( 3%) 79.19
43 ( 2%) 83.33
45 ( 2%) 78.57
47 ( 2%) 83.33
49 ( 2%) 82.39
51 ( 2%) 78.79
53 ( 2%) 82.84
55 ( 2%) 72.27
57 ( 2%) 83.92
59 ( 2%) 65.42
61 ( 1%) 73.44
63 ( 0%) 74.29
65 ( 0%) 66.67
67 ( 0%) 100.00
result accuracy by symbol:
( (91%) 86.34
) (91%) 86.34
* (87%) 86.28
+ (84%) 85.79
- (77%) 85.49
/ (76%) 85.30
0 (52%) 85.23
1 (60%) 84.37
2 (61%) 85.42
3 (62%) 85.44
4 (61%) 84.88
5 (62%) 85.25
6 (62%) 85.27
7 (63%) 85.60
8 (64%) 85.22
9 (63%) 85.34
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 88.67
1 (10%) 86.89
2 ( 4%) 91.92
3 ( 2%) 87.41
4 ( 2%) 89.47
5 ( 2%) 86.00
6 ( 2%) 91.30
7 ( 2%) 89.38
8 ( 2%) 89.74
9 ( 1%) 89.53
result accuracy by generalization:
1 (22.45%) 92.64
2 (22.96%) 91.11
3 (22.53%) 90.04
4 (15.82%) 81.55
5 (16.24%) 76.88
error cases:
5+2/6 6+2/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 6 7
5/6*3 5/6*8 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 3 8
5*(9-5) 5*(9-1) [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 20 40
1+1/6 2+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 3
5+3*4 5+5*4 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 17 25
5*(9*7) 5*19*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
1*(6+2)-6 )*(6+2(-6 [1, 7, 4, 4, 1, 4, 4, -1, 7] [1, 7, 4, 4, 1, 4, 4, -1, 7] 2 None
(6+4)/3/6 (6*4(/3/6 [2, 2, 5, 2, 2, 7, 5, -1, 7] [2, 2, 5, 2, 2, 7, 5, -1, 7] 1 2
3*(0*9*8) 3*10*9*8) [1, -1, 6, 4, 6, 4, 1, 6, 6] [1, -1, 6, 4, 6, 4, 1, 6, 6] 0 None
4*((8+8)/6) -*((8+8)/6) [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] 12 None
val (Perception Acc=94.60, Head Acc=100.00, Result Acc=87.39)
Epoch time: 1m 48s
------------------------------
Epoch 95/99 (max_len=inf, data=11170)
Train acc: 93.69 (abduce 99.90)
Hit samples:  11159  Ave length:  14.85
Symbols:  16 [(0, 5689), (1, 7201), (2, 6979), (3, 6874), (4, 6720), (5, 6717), (6, 6562), (7, 6692), (8, 6593), (9, 6525), (10, 14894), (11, 14885), (12, 12872), (13, 18592), (14, 19688), (15, 18282)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 145), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11159 samples for 100 iterations, 0.9192893554127831, 1 epochs, take 70 sec.
Epoch time: 1m 32s
------------------------------
Epoch 96/99 (max_len=inf, data=11170)
Train acc: 94.00 (abduce 99.94)
Hit samples:  11163  Ave length:  14.86
Symbols:  16 [(0, 5694), (1, 7257), (2, 6983), (3, 6878), (4, 6733), (5, 6716), (6, 6567), (7, 6696), (8, 6609), (9, 6523), (10, 14917), (11, 14823), (12, 12885), (13, 17937), (14, 20518), (15, 18171)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11163 samples for 100 iterations, 0.9226976559156636, 1 epochs, take 71 sec.
Epoch time: 1m 32s
------------------------------
Epoch 97/99 (max_len=inf, data=11170)
Train acc: 92.97 (abduce 99.90)
Hit samples:  11159  Ave length:  14.86
Symbols:  16 [(0, 5701), (1, 7295), (2, 6974), (3, 6877), (4, 6720), (5, 6714), (6, 6560), (7, 6689), (8, 6600), (9, 6536), (10, 14903), (11, 14847), (12, 12873), (13, 18054), (14, 20493), (15, 17937)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 141), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11159 samples for 100 iterations, 0.92220687325439, 1 epochs, take 70 sec.
Epoch time: 1m 32s
------------------------------
Epoch 98/99 (max_len=inf, data=11170)
Train acc: 92.49 (abduce 99.90)
Hit samples:  11159  Ave length:  14.86
Symbols:  16 [(0, 5704), (1, 7267), (2, 6981), (3, 6871), (4, 6717), (5, 6712), (6, 6565), (7, 6687), (8, 6611), (9, 6526), (10, 14913), (11, 14926), (12, 12887), (13, 18246), (14, 20146), (15, 18046)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11159 samples for 100 iterations, 0.9195983233316245, 1 epochs, take 70 sec.
Epoch time: 1m 32s
------------------------------
Epoch 99/99 (max_len=inf, data=11170)
Train acc: 92.12 (abduce 99.90)
Hit samples:  11159  Ave length:  14.86
Symbols:  16 [(0, 5720), (1, 7291), (2, 6982), (3, 6853), (4, 6714), (5, 6724), (6, 6558), (7, 6692), (8, 6604), (9, 6541), (10, 14910), (11, 15115), (12, 12891), (13, 18037), (14, 19668), (15, 18487)]
Head:  [((-1,), 1000), ((1, -1, 1), 1170), ((1, 3, 1, -1, 3), 365), ((1, -1, 3, 1, 3), 113), ((1, -1, 4, 4, 1, 4, 4), 380), ((2, 2, 5, 2, 2, -1, 5), 142), ((1, 3, 1, -1, 5, 3, 5), 92), ((1, 3, 1, -1, 6, 6, 3, 6, 6), 146), ((1, -1, 6, 4, 6, 4, 1, 6, 6), 114), ((1, 7, 4, 4, 1, 4, 4, -1, 7), 105)]
Learn perception with 11159 samples for 100 iterations, 0.9174362284135668, 1 epochs, take 70 sec.
              precision    recall  f1-score   support

           0       0.97      1.00      0.99      4016
           1       0.91      0.98      0.94      5142
           2       0.99      1.00      0.99      5321
           3       1.00      0.99      0.99      5241
           4       0.99      0.99      0.99      5279
           5       1.00      0.99      1.00      5383
           6       0.99      1.00      1.00      5427
           7       1.00      1.00      1.00      5462
           8       0.99      1.00      1.00      5453
           9       0.99      1.00      1.00      5476
           +       1.00      1.00      1.00     13199
           -       0.99      1.00      1.00     10734
           *       1.00      1.00      1.00     13491
           /       0.98      1.00      0.99      9876
           (       0.77      0.96      0.85     21081
           )       0.99      0.69      0.82     21081

    accuracy                           0.95    141662
   macro avg       0.97      0.98      0.97    141662
weighted avg       0.96      0.95      0.95    141662

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  283    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  354    0    0    0    0    0    0    0    0    0    0    0    0     2     2
2    0    0  374    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    1  365    0    0    0    0    1    0    0    0    0    0     0     0
4    0    0    0    0  369    0    0    0    0    0    0    1    0    0     0     0
5    0    0    0    0    0  377    2    0    0    0    0    0    0    0     0     0
6    0    0    0    0    0    0  383    0    0    0    0    0    0    0     0     0
7    0    0    0    0    0    0    0  385    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  384    0    0    0    0    0     0     0
9    0    0    0    0    0    0    0    0    0  386    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  928    0    0    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  756    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  952    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  697     0     0
(    6   25    0    0    2    0    0    0    0    2    0    2    0    8  1435     6
)    2   10    0    0    0    0    0    0    0    0    0    0    0    8   434  1033
result accuracy by length:
1 ( 2%) 100.00
3 ( 2%) 100.00
5 ( 2%) 96.90
7 ( 4%) 99.13
9 ( 4%) 94.47
11 ( 3%) 94.89
13 ( 4%) 89.35
15 ( 4%) 91.09
17 ( 4%) 93.20
19 ( 4%) 86.76
21 ( 4%) 89.39
23 ( 4%) 87.32
25 ( 4%) 81.00
27 ( 4%) 84.24
29 ( 3%) 86.39
31 ( 3%) 77.38
33 ( 2%) 81.43
35 ( 2%) 81.51
37 ( 2%) 82.91
39 ( 3%) 80.26
41 ( 3%) 77.18
43 ( 2%) 77.54
45 ( 2%) 73.21
47 ( 2%) 76.52
49 ( 2%) 77.46
51 ( 2%) 75.00
53 ( 2%) 75.37
55 ( 2%) 67.23
57 ( 2%) 76.22
59 ( 2%) 58.88
61 ( 1%) 71.88
63 ( 0%) 68.57
65 ( 0%) 33.33
67 ( 0%) 100.00
result accuracy by symbol:
( (91%) 82.94
) (91%) 82.94
* (87%) 83.03
+ (84%) 82.30
- (77%) 81.76
/ (76%) 81.60
0 (52%) 81.05
1 (60%) 81.36
2 (61%) 81.66
3 (62%) 81.93
4 (61%) 81.46
5 (62%) 81.97
6 (62%) 81.28
7 (63%) 82.01
8 (64%) 81.66
9 (63%) 81.58
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 100.00
2 ( 0%) 100.00
3 ( 0%) 100.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 100.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 84.86
1 (10%) 83.71
2 ( 4%) 87.37
3 ( 2%) 82.96
4 ( 2%) 87.22
5 ( 2%) 88.00
6 ( 2%) 89.57
7 ( 2%) 89.38
8 ( 2%) 81.20
9 ( 1%) 87.21
result accuracy by generalization:
1 (22.45%) 91.45
2 (22.96%) 88.80
3 (22.53%) 87.14
4 (15.82%) 76.26
5 (16.24%) 72.11
error cases:
5+2/6 6+2/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 6 7
5/(1+9) 5/11+9( [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 1 None
5/6*3 5/6*8 [1, 3, 1, -1, 3] [1, 3, 1, -1, 3] 3 8
1+1/6 2+1/6 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 2 3
5+3*4 5+5*4 [1, -1, 3, 1, 3] [1, -1, 3, 1, 3] 17 25
5*(9*7) 5*(9*71 [1, -1, 4, 4, 1, 4, 4] [1, -1, 4, 4, 1, 4, 4] 315 None
2/4-(8+6) 2/4-18+6) [1, 3, 1, -1, 6, 6, 3, 6, 6] [1, 3, 1, -1, 6, 6, 3, 6, 6] 0 None
(6+4)/3/6 (6*4(/3/6 [2, 2, 5, 2, 2, 7, 5, -1, 7] [2, 2, 5, 2, 2, 7, 5, -1, 7] 1 2
4*((8+8)/6) -*((8+8)/6) [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] [1, -1, 8, 5, 5, 8, 5, 5, 1, 8, 8] 12 None
(2+9)/7-2 02+9(/7-2 [2, 2, 5, 2, 2, 7, 5, -1, 7] [2, 2, 5, 2, 2, 7, 5, -1, 7] 0 None
val (Perception Acc=94.71, Head Acc=100.00, Result Acc=84.33)
Epoch time: 1m 49s
------------------------------
Evaluate on test set...
              precision    recall  f1-score   support

           0       0.98      1.00      0.99     39465
           1       0.91      0.98      0.95     51797
           2       0.98      0.99      0.99     52546
           3       1.00      0.99      0.99     52953
           4       0.99      1.00      1.00     53234
           5       0.99      1.00      0.99     53430
           6       1.00      0.99      0.99     53860
           7       0.99      0.99      0.99     54695
           8       1.00      1.00      1.00     54671
           9       0.99      1.00      0.99     54909
           +       1.00      1.00      1.00    131914
           -       1.00      1.00      1.00    108556
           *       1.00      1.00      1.00    132837
           /       0.98      1.00      0.99     99343
           (       0.78      0.97      0.86    210691
           )       0.99      0.71      0.83    210691

    accuracy                           0.95   1415592
   macro avg       0.97      0.98      0.97   1415592
weighted avg       0.96      0.95      0.95   1415592

     0    1    2    3    4    5    6    7    8    9    +    -    *    /     (     )
0  277    0    0    0    0    0    0    0    0    0    0    0    0    0     0     0
1    0  358    1    0    0    0    0    0    0    0    0    0    0    0     2     1
2    0    0  368    0    0    0    0    0    0    0    0    0    0    0     0     0
3    0    0    0  370    0    1    0    0    1    0    0    0    0    0     0     0
4    0    0    0    0  375    0    0    0    0    0    0    0    0    0     0     0
5    0    0    0    0    0  375    1    0    0    0    0    0    0    0     0     0
6    0    1    2    0    0    0  376    0    0    0    0    0    0    0     0     0
7    0    1    0    0    0    0    0  384    0    0    0    0    0    0     0     0
8    0    0    0    0    0    0    0    0  385    0    0    0    0    0     0     0
9    0    0    0    0    0    0    0    0    0  387    0    0    0    0     0     0
+    0    0    0    0    0    0    0    0    0    0  928    0    1    0     0     0
-    0    0    0    0    0    0    0    0    0    0    0  766    0    0     0     0
*    0    0    0    0    0    0    0    0    0    0    0    0  938    0     0     0
/    0    0    0    0    0    0    0    0    0    0    0    0    0  701     0     0
(    6   20    0    0    0    0    0    0    0    2    2    2    0    7  1439     7
)    0    9    0    0    0    1    0    1    0    0    0    0    0    9   406  1059
result accuracy by length:
1 ( 2%) 99.50
3 ( 2%) 98.12
5 ( 2%) 98.00
7 ( 4%) 96.24
9 ( 4%) 95.17
11 ( 4%) 94.09
13 ( 4%) 92.50
15 ( 4%) 92.09
17 ( 4%) 90.34
19 ( 4%) 90.00
21 ( 4%) 88.37
23 ( 4%) 88.26
25 ( 4%) 86.70
27 ( 4%) 85.35
29 ( 3%) 84.01
31 ( 3%) 84.64
33 ( 2%) 82.39
35 ( 2%) 81.96
37 ( 2%) 80.05
39 ( 2%) 78.41
41 ( 2%) 77.81
43 ( 2%) 79.34
45 ( 2%) 78.79
47 ( 2%) 76.88
49 ( 2%) 76.09
51 ( 2%) 75.17
53 ( 2%) 74.77
55 ( 2%) 71.34
57 ( 2%) 70.88
59 ( 2%) 68.73
61 ( 1%) 70.54
63 ( 0%) 67.57
65 ( 0%) 74.38
67 ( 0%) 58.62
69 ( 0%) 54.55
71 ( 0%) 50.00
result accuracy by symbol:
( (91%) 83.77
) (91%) 83.77
* (87%) 83.60
+ (84%) 83.35
- (78%) 83.00
/ (77%) 82.87
0 (51%) 82.10
1 (60%) 81.75
2 (61%) 82.12
3 (62%) 82.36
4 (62%) 82.54
5 (62%) 82.69
6 (62%) 82.46
7 (63%) 82.68
8 (63%) 82.82
9 (63%) 82.87
result accuracy by digit:
0 ( 0%) 100.00
1 ( 0%) 97.00
2 ( 0%) 100.00
3 ( 0%) 99.00
4 ( 0%) 100.00
5 ( 0%) 100.00
6 ( 0%) 99.00
7 ( 0%) 100.00
8 ( 0%) 100.00
9 ( 0%) 100.00
result accuracy by result:
0 (21%) 87.04
1 (11%) 86.08
2 ( 3%) 85.92
3 ( 3%) 86.22
4 ( 2%) 87.36
5 ( 2%) 87.65
6 ( 2%) 87.19
7 ( 2%) 85.73
8 ( 2%) 86.55
9 ( 2%) 85.69
result accuracy by generalization:
1 (22.84%) 92.29
2 (23.00%) 89.33
3 (22.36%) 87.55
4 (15.84%) 76.01
5 (15.95%) 74.06
error cases:
1 2 [-1] [-1] 1 2
1 5 [-1] [-1] 1 5
1 ( [-1] [-1] 1 None
6 2 [-1] [-1] 6 2
3 9 [-1] [-1] 3 9
6/4 1/4 [1, -1, 1] [1, -1, 1] 2 1
5*3 5*5 [1, -1, 1] [1, -1, 1] 15 25
8*2 8*6 [1, -1, 1] [1, -1, 1] 16 48
7/7 7/1 [1, -1, 1] [1, -1, 1] 1 7
4-1 4-( [1, -1, 1] [1, -1, 1] 3 None
test (Perception Acc=94.93, Head Acc=100.00, Result Acc=85.06)
